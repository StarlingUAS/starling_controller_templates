{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Starling Tutorial \u00b6 Starling Tutorial Introduction What is Starling What Will I learn In This Tutorial The Tutorial Task Scenario How To Use This Tutorial Contents Introduction \u00b6 What is Starling \u00b6 Starling is an end to end, modular, containerised UAV infrastucture designed to facilitate the local development, testing and deployment of Single and Multi-UAV systems from simulation to the Bristol Robotics Lab Flight Arena (and hopefully beyond). It will hopefully allow for a more approachable development workflow to enable more researchers to fly UAVs in a safe, reproducable and controllable manner. This tutorial is intended to demonstrate how to use Starling to develop and deploy a multi-uav controller. What Will I learn In This Tutorial \u00b6 This tutorial aims to bring you from the basics of software development, to starting your own Starling project, to local testing, to flying your developed controller in the real world. Through the development of a multi-UAV controller, you will be taught the fundamentals of Starling, and how to use it. This will include learning about UAV Control and ROS2, why we decided to use Docker and Containerisation, and the use of Kubernetes and Container Orchestration for testing. We will be providing both background discussion as well as hands on example to run. In particular, we follow the Starling development workflow we designed for the development, testing and validation of Starling controllers. The Tutorial Task Scenario \u00b6 You have been asked to prototype a particular scene within a drone display! In this scene a number of drones take off and automatically fly to starting points equidistant around a circle of a given radius. They then start circling around the edge of the circle attempting to stay equidistant to their neighbours. It is determined that the vehicles have not been well tuned and can end up lagging, therefore a centralised server monitors all the vehicles and notifies them if they are lagging behind. How To Use This Tutorial \u00b6 This tutorial is split into a set of sequential sections. Each section builds upon the tools and knowledge from previous tutorials, so it is recommended you follow them in sequence. The tutorials themselves are mostly split between teaching theory, and then applying that theory through running some exercises or commands. It is important that throughout this tutorial, you consider why you are being asked to run a command with those particular arguments. Don't just copy and paste verbatim! As mentioned you will be developing a starling application alongside this tutorial. There are some parts where it will be beneficial for you to have the code open side by side. Contents \u00b6 Getting started Learn Starling dependencies and how to install them ROS2 and UAV Control Learn how UAVs are controlled Learn the theory behind the Robot Operating System Docker and Containersiation Learn what containerisation is and how its used within Starling Learn basic Docker commands to run Starling containers Creating your own Starling project Learning how to use a template to create your own Starling project Simulation and the Digital Double Learn about how UAVs are simulated Learn how to run the BRL digital double simulator Developing the example controller with ROS2 in CPP Exercise: Building a solution to the example scenario Local testing with Docker-Compose Learn how to develop and test your controller against the simulator Multi-UAV flight with Kubernetes for container deployment Learn about why Starling uses Kubernetes for Integration testing Learn how to run the integration testing stack Local Integration testing with KinD Digital Double Learn how to deploy your application for integration testing Flying your controllers in the Flying Arena Learn about the BRL flight arena systems Learn about how to develop and deploy your controller to real vehicles safely Wrapping up and next steps Providing useful links and next steps after completing the tutorial","title":"Starling Tutorial"},{"location":"#starling-tutorial","text":"Starling Tutorial Introduction What is Starling What Will I learn In This Tutorial The Tutorial Task Scenario How To Use This Tutorial Contents","title":"Starling Tutorial"},{"location":"#introduction","text":"","title":"Introduction"},{"location":"#what-is-starling","text":"Starling is an end to end, modular, containerised UAV infrastucture designed to facilitate the local development, testing and deployment of Single and Multi-UAV systems from simulation to the Bristol Robotics Lab Flight Arena (and hopefully beyond). It will hopefully allow for a more approachable development workflow to enable more researchers to fly UAVs in a safe, reproducable and controllable manner. This tutorial is intended to demonstrate how to use Starling to develop and deploy a multi-uav controller.","title":"What is Starling"},{"location":"#what-will-i-learn-in-this-tutorial","text":"This tutorial aims to bring you from the basics of software development, to starting your own Starling project, to local testing, to flying your developed controller in the real world. Through the development of a multi-UAV controller, you will be taught the fundamentals of Starling, and how to use it. This will include learning about UAV Control and ROS2, why we decided to use Docker and Containerisation, and the use of Kubernetes and Container Orchestration for testing. We will be providing both background discussion as well as hands on example to run. In particular, we follow the Starling development workflow we designed for the development, testing and validation of Starling controllers.","title":"What Will I learn In This Tutorial"},{"location":"#the-tutorial-task-scenario","text":"You have been asked to prototype a particular scene within a drone display! In this scene a number of drones take off and automatically fly to starting points equidistant around a circle of a given radius. They then start circling around the edge of the circle attempting to stay equidistant to their neighbours. It is determined that the vehicles have not been well tuned and can end up lagging, therefore a centralised server monitors all the vehicles and notifies them if they are lagging behind.","title":"The Tutorial Task Scenario"},{"location":"#how-to-use-this-tutorial","text":"This tutorial is split into a set of sequential sections. Each section builds upon the tools and knowledge from previous tutorials, so it is recommended you follow them in sequence. The tutorials themselves are mostly split between teaching theory, and then applying that theory through running some exercises or commands. It is important that throughout this tutorial, you consider why you are being asked to run a command with those particular arguments. Don't just copy and paste verbatim! As mentioned you will be developing a starling application alongside this tutorial. There are some parts where it will be beneficial for you to have the code open side by side.","title":"How To Use This Tutorial"},{"location":"#contents","text":"Getting started Learn Starling dependencies and how to install them ROS2 and UAV Control Learn how UAVs are controlled Learn the theory behind the Robot Operating System Docker and Containersiation Learn what containerisation is and how its used within Starling Learn basic Docker commands to run Starling containers Creating your own Starling project Learning how to use a template to create your own Starling project Simulation and the Digital Double Learn about how UAVs are simulated Learn how to run the BRL digital double simulator Developing the example controller with ROS2 in CPP Exercise: Building a solution to the example scenario Local testing with Docker-Compose Learn how to develop and test your controller against the simulator Multi-UAV flight with Kubernetes for container deployment Learn about why Starling uses Kubernetes for Integration testing Learn how to run the integration testing stack Local Integration testing with KinD Digital Double Learn how to deploy your application for integration testing Flying your controllers in the Flying Arena Learn about the BRL flight arena systems Learn about how to develop and deploy your controller to real vehicles safely Wrapping up and next steps Providing useful links and next steps after completing the tutorial","title":"Contents"},{"location":"brl_flight/","text":"Flying your controllers in the Flying Arena \u00b6 Now we reach the final step, running your controllers on the real vehicles. By the end of this tutorial you should hopefully be able to understand how to transition from flying with your KinD integration testing stack to the real world - well more specifically the Bristol Robotics Laboratory flight arena. Flying your controllers in the Flying Arena Bristol Robotics Laboratory Flight Arena Flight Arena Features Flight Arena System Setup Default deployments Preparing your controller for real world deployment Pushing your image to Docker Hub Building and pushing for arm64 Deploying and Developing on real vehicles Clover Procedures Deploying your controllers Next Steps Bristol Robotics Laboratory Flight Arena \u00b6 The Bristol Robotics Lab (BRL) Flight Arena is a large 15.6m x 11.8m x 5m space with a large 10m x 5m x 4m flying volume in the center. Flight Arena Features \u00b6 The space is safe to fly vehicles up to 5kg, and multiple smaller vehicles. In the past we've had projects ranging from high speed flight for autonomous drone racing to flying custom drones for cave inspections. A key feature of the flight arena is the array of ViCon Motion Capture cameras dotted around the gantries. When calibrated, these give mm level accuracy at detecting the position of reflective balls. These balls are placed in a non-symmetric pattern aroound the UAV. This allows us to have excellent positioning information of our drones and is fed directly to the vehicle. For multi-uav work, we have aquired a set of coex clover multirotor UAVs. These UAVs are comprised of a raspberry pi 4B with 2Gb RAM connected to a modified PixRacer Autopilot running PX4. For sensing, they have your standard set of IMU, magnetometer, compass and barometer, as well as a downwards facing range finder, a camera, and a ring of LEDs. These clovers are the ones we aim to do our application tests on. In terms of compute, we have 3 recent desktops and 2 laptop hotdesking spaces, and an arena server. For networking, we rely on a strong wifi hub to transmit to and from any active vehicles. Flight Arena System Setup \u00b6 Currently in the flight arena we have a minature cluster setup using a lightweight variant of kubernetes known as k3s . We opt to use k3s as it provides many of the core features we require from running kubernetes, without beeing needlessly expensive to run on low-powered edge hardware. As shown in the diagram, we run a central k8 server on the arena server. Each of the vehicles is then setup as a node with a name of clover11 to vehicle14. These can be seen by logging onto any of the machines and going to the arena kubernetes dashboard on https://flyingserver.local:13771 . You will need to run starling utils get-dashboard-token to get the access token. Each vehicle is identified by its hostname ( startling_cloverXX ) on the network, as well as by its unique /etc/starling/vehicle.config . This file is created on drone setup and contains a unique system id to talk to the autopilot with and the name of the vehicle. Each of the desktop machines only serve to access the cluster and are not part of the cluster themselves. However due to a quirk of ROS2, each of the desktops can actually natively (and through running a docker container) access the active ROS2 topics. A useful side-affect of running the drones as nodes in a cluster is that they do not need reconfiguring on startup. Once a vehicle is turned on it will automatically attempt to reconnect to the cluster and request its deployed containers. A key element of indoor flight, especially so with multiple vehicles, is safety. It is absolutely paramount that we are always aware of the safety cases and features of anything we fly - hence the need for this entire testing and integration testing stack in the first place. Default deployments \u00b6 Just like in the integration test, by default we have the following deployments Every 'vehicle' has the MAVROS container deployed to it. Every 'clover' (a type of UAV we are using) has the Clover Hardware Container deployed to it. Every 'multirotor' has the User's onboard controller deployed to it. The offboard, gui and safety monitor are restricted to only be deployed on the 'master' node. Preparing your controller for real world deployment \u00b6 Pushing your image to Docker Hub \u00b6 On a deployment, the individual drones are set to query and pull the required images from docker hub. Therefore it is necessary to push a build of your image to docker hub. Note: In the future it will be possible to load to a registry on the local network, but as of writing it is not yet been setup. If you have not yet made a docker hub account, now is the time. Make sure you match the account name that you created your starling project with, otherwise it will be a hassle to change it. Once created, you will also need to login on with your username and password on your local machine. docker login Once you have logged in, you should have the ability to push your built project's image up to Docker Hub. You can try this now with. docker push <docker_hub_username>/<my_image_name> # e.g docker push starling123/starling_template_test Building and pushing for arm64 \u00b6 Unfortunately you cannot actually run the image you just pushed to docker hub on the Raspberry Pis running on the Clovers. This is because they run the arm64 computer architecture, compared to the amd64 architecture you are likely running on your development machine. By default, your machine builds the image which matches your machine. In order to build an arm64 image locally, you will have to cross-compile it. This involves starting up a arm64 emulator (called qemu) and building your image within that environment. Note: You could also just git pull and make the project on a spare rapsberry pi or other arm64 archtected device too. We have usefully set these actions up in your makefile. To initialise the cross-compilation, run: make local-build-setup This might take a minute, as it needs to pull an emulation container and other things. Once finished, you can cross-compile the images for both amd64 and arm64 simultaneously using: make local-build-push Note: The initial build can take a LONG time (from 10 to 30 minutes). Thankfully further builds are mostly cached so they take between 3 to 8 minutes. Note: For heavy onboard or sensor related development, it is recommended to use the VSCode remote development tools to develop inside a container on the raspberry pi. Once complete, you can verify that the container has been pushed by visitng your docker hub account and hopefully seeing it there. Due to the long build times, it is recommended you analyse and verify as much as you can offboard to ensure that you only need to rebuild a minimal number of times. Deploying and Developing on real vehicles \u00b6 Now that the container is ready, all thats left is readying the vehicles. Clover Procedures \u00b6 Ensure the VICON motion capture cameras are on, and connected to the VICON capture application on the dedicated vicon machine. Inspect the vehicle for physical damage, are all the screws in and tightened, are all the wires fixed and out of the way of the blades. Ensure that the correct 14.8v, 4 cell Series batteries are fully charged using the battery tester. Ensure that all the nets are lowered in the flight arena, and that all other people have vacated the flight volume. Place the vehicle within the flight volume, secure the battery to the top of the vehicle using the velcro, and plug in the battery. The vehicle should beep indicating it has power and is turning on. Leave the flight volume to check on vehicle status. At this point you should go to the kubernetes dashboard and double check the status of the containers on the vehicle. If the vehicle has succesfully started, the ring of LEDs should turn solid blue with no blinking. This indicates that the vehicle has initialised and that it is receiving state information from the MAVROS container. A couple of things to be aware of: It can take up to 5 minutes for the vehicle to start up, connect to the network, update its containers and start running. On startup, periodically go to the nodes page and see if has connected (shows green dot). It is possible that one or more of the containers have failed on startup and require restarting. Restart a container simply by deleting it. If a vehicle is stuck on blinking blue light for a while, this indicates that the vehicle monitor cannot find MAVROS. In this instance you should restart the vehicle. To restart the vehicle, there is a push button stuck to the ethernet port. Press this button and count to 10 to shutdown the raspberry pi. Then you can disconnect the battery to either replace, or (count to 3), then plug it back in. You must always be aware of safety. Familiarise yourself with the safety equipment and procedures of the flight arena. In particular what to do in the event of a lipo fire or severe UAV crash. If in doubt, contact your supervisor to arrange for somebody to be there during your testing. Deploying your controllers \u00b6 The procedure for deployment is identical to the integration testing (by design! :-) ). First ensure that the cluster state is correct, you don't have any extra containers or other peoples applications containers running. Verify only the core deployments and daemonsets are applied. Once ready you can deploy your application: starling deploy -f deployment/kubernetes.yaml start Note: As the vehicle pulls directly from docker hub, there is no need for --load . Once deployed, you can verify the state of your deployment on kubernetes dashboard. As a testing procedure, it is always recommended that you verify that your controller displays the correct behaviour for 1 vehicle first, followed by multiple vehicles. It is simpler and easier to keep an eye on if something goes wrong. Note: Verify that the vehicle is showing up on Vicon and is stable. Also verify that the internal positioning is stable and correct by using one of the machines to run ros2 topic echo /vehicle_XX/mavros/local_position/pose . Either run on the lab machine, or start a docker container with docker run -it --rm --net=host uobflightlabstarling/starling-mavros bash , followed by . /opt/ros/foxy/setup.bash to give you access to the ros cli. Once you are happy that the controllers are working as intended, the flight procedure is the following: Announce that you are about to fly. Stand up holding the arena controls with hands ready to either abort or hit the emergency stop button. Press the GO button. (The vehicle will take-off) Verify the start location, Press the GO button. (The vehicle will go to the start location) Verify in the correct state, Press the GO button. (The vehicle will start executing your UserController) If everything works great then you will have two drones flying around in a nice circle. If not, you should make your change, verify in simulation, cross-compile and push to docker hub, then deploy your changes by restarting the deployment with: starling deploy -f deployment/kubernetes.yaml restart To stop or tidy up, turn off the drones and return the batteries to the fireproof bags. Put away the drones onto the shelf and turn off the Vicon cameras and dedicated machine. Turn off the battery charging equipment and then the lights. Next Steps \u00b6 Awesome, now you've flown in real life! By the end of this final tutorial, you should now have an understanding of how real life flight looks like within Starling. In particular you should know how Starling has been setup within the BRL flight arena, how to build and deploy for the clover drones, how to prepare them for flight and finally how to deploy your controllers to it to fly. Join us in the last section for a quick wrap up of the tutorial.","title":"10. Flying your controllers in the Flying Arena"},{"location":"brl_flight/#flying-your-controllers-in-the-flying-arena","text":"Now we reach the final step, running your controllers on the real vehicles. By the end of this tutorial you should hopefully be able to understand how to transition from flying with your KinD integration testing stack to the real world - well more specifically the Bristol Robotics Laboratory flight arena. Flying your controllers in the Flying Arena Bristol Robotics Laboratory Flight Arena Flight Arena Features Flight Arena System Setup Default deployments Preparing your controller for real world deployment Pushing your image to Docker Hub Building and pushing for arm64 Deploying and Developing on real vehicles Clover Procedures Deploying your controllers Next Steps","title":"Flying your controllers in the Flying Arena"},{"location":"brl_flight/#bristol-robotics-laboratory-flight-arena","text":"The Bristol Robotics Lab (BRL) Flight Arena is a large 15.6m x 11.8m x 5m space with a large 10m x 5m x 4m flying volume in the center.","title":"Bristol Robotics Laboratory Flight Arena"},{"location":"brl_flight/#flight-arena-features","text":"The space is safe to fly vehicles up to 5kg, and multiple smaller vehicles. In the past we've had projects ranging from high speed flight for autonomous drone racing to flying custom drones for cave inspections. A key feature of the flight arena is the array of ViCon Motion Capture cameras dotted around the gantries. When calibrated, these give mm level accuracy at detecting the position of reflective balls. These balls are placed in a non-symmetric pattern aroound the UAV. This allows us to have excellent positioning information of our drones and is fed directly to the vehicle. For multi-uav work, we have aquired a set of coex clover multirotor UAVs. These UAVs are comprised of a raspberry pi 4B with 2Gb RAM connected to a modified PixRacer Autopilot running PX4. For sensing, they have your standard set of IMU, magnetometer, compass and barometer, as well as a downwards facing range finder, a camera, and a ring of LEDs. These clovers are the ones we aim to do our application tests on. In terms of compute, we have 3 recent desktops and 2 laptop hotdesking spaces, and an arena server. For networking, we rely on a strong wifi hub to transmit to and from any active vehicles.","title":"Flight Arena Features"},{"location":"brl_flight/#flight-arena-system-setup","text":"Currently in the flight arena we have a minature cluster setup using a lightweight variant of kubernetes known as k3s . We opt to use k3s as it provides many of the core features we require from running kubernetes, without beeing needlessly expensive to run on low-powered edge hardware. As shown in the diagram, we run a central k8 server on the arena server. Each of the vehicles is then setup as a node with a name of clover11 to vehicle14. These can be seen by logging onto any of the machines and going to the arena kubernetes dashboard on https://flyingserver.local:13771 . You will need to run starling utils get-dashboard-token to get the access token. Each vehicle is identified by its hostname ( startling_cloverXX ) on the network, as well as by its unique /etc/starling/vehicle.config . This file is created on drone setup and contains a unique system id to talk to the autopilot with and the name of the vehicle. Each of the desktop machines only serve to access the cluster and are not part of the cluster themselves. However due to a quirk of ROS2, each of the desktops can actually natively (and through running a docker container) access the active ROS2 topics. A useful side-affect of running the drones as nodes in a cluster is that they do not need reconfiguring on startup. Once a vehicle is turned on it will automatically attempt to reconnect to the cluster and request its deployed containers. A key element of indoor flight, especially so with multiple vehicles, is safety. It is absolutely paramount that we are always aware of the safety cases and features of anything we fly - hence the need for this entire testing and integration testing stack in the first place.","title":"Flight Arena System Setup"},{"location":"brl_flight/#default-deployments","text":"Just like in the integration test, by default we have the following deployments Every 'vehicle' has the MAVROS container deployed to it. Every 'clover' (a type of UAV we are using) has the Clover Hardware Container deployed to it. Every 'multirotor' has the User's onboard controller deployed to it. The offboard, gui and safety monitor are restricted to only be deployed on the 'master' node.","title":"Default deployments"},{"location":"brl_flight/#preparing-your-controller-for-real-world-deployment","text":"","title":"Preparing your controller for real world deployment"},{"location":"brl_flight/#pushing-your-image-to-docker-hub","text":"On a deployment, the individual drones are set to query and pull the required images from docker hub. Therefore it is necessary to push a build of your image to docker hub. Note: In the future it will be possible to load to a registry on the local network, but as of writing it is not yet been setup. If you have not yet made a docker hub account, now is the time. Make sure you match the account name that you created your starling project with, otherwise it will be a hassle to change it. Once created, you will also need to login on with your username and password on your local machine. docker login Once you have logged in, you should have the ability to push your built project's image up to Docker Hub. You can try this now with. docker push <docker_hub_username>/<my_image_name> # e.g docker push starling123/starling_template_test","title":"Pushing your image to Docker Hub"},{"location":"brl_flight/#building-and-pushing-for-arm64","text":"Unfortunately you cannot actually run the image you just pushed to docker hub on the Raspberry Pis running on the Clovers. This is because they run the arm64 computer architecture, compared to the amd64 architecture you are likely running on your development machine. By default, your machine builds the image which matches your machine. In order to build an arm64 image locally, you will have to cross-compile it. This involves starting up a arm64 emulator (called qemu) and building your image within that environment. Note: You could also just git pull and make the project on a spare rapsberry pi or other arm64 archtected device too. We have usefully set these actions up in your makefile. To initialise the cross-compilation, run: make local-build-setup This might take a minute, as it needs to pull an emulation container and other things. Once finished, you can cross-compile the images for both amd64 and arm64 simultaneously using: make local-build-push Note: The initial build can take a LONG time (from 10 to 30 minutes). Thankfully further builds are mostly cached so they take between 3 to 8 minutes. Note: For heavy onboard or sensor related development, it is recommended to use the VSCode remote development tools to develop inside a container on the raspberry pi. Once complete, you can verify that the container has been pushed by visitng your docker hub account and hopefully seeing it there. Due to the long build times, it is recommended you analyse and verify as much as you can offboard to ensure that you only need to rebuild a minimal number of times.","title":"Building and pushing for arm64"},{"location":"brl_flight/#deploying-and-developing-on-real-vehicles","text":"Now that the container is ready, all thats left is readying the vehicles.","title":"Deploying and Developing on real vehicles"},{"location":"brl_flight/#clover-procedures","text":"Ensure the VICON motion capture cameras are on, and connected to the VICON capture application on the dedicated vicon machine. Inspect the vehicle for physical damage, are all the screws in and tightened, are all the wires fixed and out of the way of the blades. Ensure that the correct 14.8v, 4 cell Series batteries are fully charged using the battery tester. Ensure that all the nets are lowered in the flight arena, and that all other people have vacated the flight volume. Place the vehicle within the flight volume, secure the battery to the top of the vehicle using the velcro, and plug in the battery. The vehicle should beep indicating it has power and is turning on. Leave the flight volume to check on vehicle status. At this point you should go to the kubernetes dashboard and double check the status of the containers on the vehicle. If the vehicle has succesfully started, the ring of LEDs should turn solid blue with no blinking. This indicates that the vehicle has initialised and that it is receiving state information from the MAVROS container. A couple of things to be aware of: It can take up to 5 minutes for the vehicle to start up, connect to the network, update its containers and start running. On startup, periodically go to the nodes page and see if has connected (shows green dot). It is possible that one or more of the containers have failed on startup and require restarting. Restart a container simply by deleting it. If a vehicle is stuck on blinking blue light for a while, this indicates that the vehicle monitor cannot find MAVROS. In this instance you should restart the vehicle. To restart the vehicle, there is a push button stuck to the ethernet port. Press this button and count to 10 to shutdown the raspberry pi. Then you can disconnect the battery to either replace, or (count to 3), then plug it back in. You must always be aware of safety. Familiarise yourself with the safety equipment and procedures of the flight arena. In particular what to do in the event of a lipo fire or severe UAV crash. If in doubt, contact your supervisor to arrange for somebody to be there during your testing.","title":"Clover Procedures"},{"location":"brl_flight/#deploying-your-controllers","text":"The procedure for deployment is identical to the integration testing (by design! :-) ). First ensure that the cluster state is correct, you don't have any extra containers or other peoples applications containers running. Verify only the core deployments and daemonsets are applied. Once ready you can deploy your application: starling deploy -f deployment/kubernetes.yaml start Note: As the vehicle pulls directly from docker hub, there is no need for --load . Once deployed, you can verify the state of your deployment on kubernetes dashboard. As a testing procedure, it is always recommended that you verify that your controller displays the correct behaviour for 1 vehicle first, followed by multiple vehicles. It is simpler and easier to keep an eye on if something goes wrong. Note: Verify that the vehicle is showing up on Vicon and is stable. Also verify that the internal positioning is stable and correct by using one of the machines to run ros2 topic echo /vehicle_XX/mavros/local_position/pose . Either run on the lab machine, or start a docker container with docker run -it --rm --net=host uobflightlabstarling/starling-mavros bash , followed by . /opt/ros/foxy/setup.bash to give you access to the ros cli. Once you are happy that the controllers are working as intended, the flight procedure is the following: Announce that you are about to fly. Stand up holding the arena controls with hands ready to either abort or hit the emergency stop button. Press the GO button. (The vehicle will take-off) Verify the start location, Press the GO button. (The vehicle will go to the start location) Verify in the correct state, Press the GO button. (The vehicle will start executing your UserController) If everything works great then you will have two drones flying around in a nice circle. If not, you should make your change, verify in simulation, cross-compile and push to docker hub, then deploy your changes by restarting the deployment with: starling deploy -f deployment/kubernetes.yaml restart To stop or tidy up, turn off the drones and return the batteries to the fireproof bags. Put away the drones onto the shelf and turn off the Vicon cameras and dedicated machine. Turn off the battery charging equipment and then the lights.","title":"Deploying your controllers"},{"location":"brl_flight/#next-steps","text":"Awesome, now you've flown in real life! By the end of this final tutorial, you should now have an understanding of how real life flight looks like within Starling. In particular you should know how Starling has been setup within the BRL flight arena, how to build and deploy for the clover drones, how to prepare them for flight and finally how to deploy your controllers to it to fly. Join us in the last section for a quick wrap up of the tutorial.","title":"Next Steps"},{"location":"cpp_example_dev/","text":"Developing the example controller with ROS2 in CPP \u00b6 Finally, the bit you have all been waiting for! In this tutorial, we will take you through how to develop and build the controller for the example scenario. This page is for the CPP controller in particular. By the end, you should have a controller ready for testing. Developing the example controller with ROS2 in CPP Very Very Quick Intro to CPP Overview of the Controller Template Controller Core Functionality Controller Communication with MAVROS Controller User Implemented Functionality A Solution to the Scenario Useful Tips for Implementation Getting the actual current theta Creating and Publishing Messages Angular Velocity and Position Theta to position Sending Vehicle Setpoint Next Steps Very Very Quick Intro to CPP \u00b6 By the time of the launch of this tutorial, we may not have an equivalent tutorial in Python. Therefore we provide a very very very quick intro to the bits of CPP you need to know about for this tutorial. We recommend you check out online tutorials on CPP for a much more complete introduction! So in no particular order: CPP is an Object Orientated-ish Language, so we have the idea of Classes which contain member variables and member functions. We also have the concept of inheritance, where a child class inherits the functionality and variables from its parent class. In ROS2, every rosnode class inherits from the rclcpp (ROS CPP Library) Node class. class UAVController : public rclcpp::Node { public: UAVController(); void reset(); private: std::string vehicle_id = \"vehicle_1\"; } In CPP, it is standard practice to split the declaration of functions and variables from the implementation of those same functions and variables into separate files. Reasons includes space saving, verboseness and other things - look it up. Header files (files with extension .h / .hpp ) contain all of the class and function declarations, like the example shown above. The syntax for a function declaration is <return type> <function_name>(<function arguments>); . The syntax to create a variable is <variable type> variable_name; , and can either be immediately assigned to or assigned later. Note that CPP is typed , which means that all functions and variables must specify what they intend to take as argument, return or be explictly (unlike Python). Source files (files with extension .h / .cpp ) contain the implementation of the class and functions which have been declared in the assocated header file (imported with #include <header.hpp> ). The following shows the implementation of the reset function in the source file, corresponding to the class in the header. Within the implementation, class variables can be used by accessing the this variable. Note that instead of a . , an arrow -> is used. An arrow is needed to access anything which is of a pointer type sth_ptr (the this variable is a pointer to itself). This should be enough for now - read up for much more detail). void UAVController::reset(){ // ... some implementation this->vehicle_id = \"default_vehicle_name\"; } As with most languages, CPP has the standard control flow operations - if , for , while , continue , return , etc that you would see in most other languages. Hopefully you can infer how these and the various other CPP elements work from reading the code! Good luck! :D Overview of the Controller Template \u00b6 Important: Have the code open in your editor of choice and follow along with the explanation. Let's start by examining the CPP onboard controller in more detail. As shown in the creating a starling project tutorial , the CPP onboard controller has the following structure: |-- CMakeLists.txt |-- include | |-- controller.hpp | |-- main.hpp | `-- state.hpp |-- launch | `-- template_cpp_node.launch.xml |-- package.xml `-- src |-- controller.cpp `-- main.cpp We gave an overview there, but we didn't provide any details on what exactly the CPP files are doing! So we now go into more detail. Controller Core Functionality \u00b6 In addition to performing the application, this controller must take care of a number of normal functions before and after executing the actions of the application. This includes the following actions: Ensuring and checking that the vehicle is receiving telemetry Arming and Disarming the Vehicle before and after flight Taking off from the ground and Landing safely Going to the start location of the given task Taking instruction (such as go, abort and estop) and safely reacting to them from users The order and usage of these actions are fairly consistent over a large number of possible applications, so this controller bundles them up as standard functionality available in the main execution of the node. The main.hpp and main.cpp files define a UAVController rosnode class. In this class, after initialisation, a timer is used to run a main operating loop function over and over at a fixed interval (10hz by default). Our controller makes use of a finite state machine model to manage the control flow through the various states mentioned above. This FSM is shown in the diagram below. The Rectangular boxes (apart from the red ones) all depict States of this FSM. Each state requires a number of orange actions to complete or checks to pass before it can move onto the next state. The green states also include live checks for if the vehicle is armed and in the correct mode for offboard flight, as the vehicle will be in the air. The FSM also contains failure states for any of the checks in which the vehicle which go to Stop, and therefore immediately land. The functionality of this state machine is encoded within the stateMachine(Time stamp) function, and is triggered by a Ros Timer running at 10hz ( this->execution_timer ). The States are defined in state.hpp . From an implementation standpoint, since the state machine has to run continuously, any called function cannot internally loop indefinitely and must execute and immediately exit. Traditionally FSMs switch states through the use of a large set of binary variables. In this particular application, this felt very verbose, and so we use boolean returning execution functions as our state machine checks. For example, the Takeoff check calls to see whether this->smTakeoffVehicle(stamp) (main.cpp:246) returns true. case State::TAKEOFF: this->smOffboardArmed(stamp); if(!this->smTakeoffVehicle(stamp)) { RCLCPP_INFO(this->get_logger(), \"Waiting for Takeoff\"); } However, if we look at this function, it itself performs the takeoff procedure to a given height, always returning false, unless the vehicle is at its takeoff location. Controller Communication with MAVROS \u00b6 Now we have the controller architecture in play, how does this controller actually talk to the vehicle? At the bottom of main.hpp you should see a whole bunch of Ros Publishers and Subscribers being declared (note how they are pointers). These pubs and subs are initialised within the class constructor/initialiser in main.cpp:67-97 . In order to detect arming and mode, we subscribe to mavros/state , and in order to get the local cartesian position and orientation of the vehicle, we also get mavros/local_position/pose . These both give us a constant stream of data which we save into variables this->vehicle_state and this->vehicle_local_position . In order to send position commands to the vehicle, we set up a publisher to mavros/setpoint_position/local and use the sendSetpointPositionPose(stamp, geometry_msgs::msg::PoseStamped) function to publish setpoints to the autopilot. The translated MAVLINK commands then tell the drone to go to that location and orientation immediately. Therefore in a number of places, we make use of interpolators to ensure that the vehicle can move from its location to any other at safe velocities and rates. Otherwise, the drone will ramp up to maximum velocity to go to far away locations which can be quite dangerous! Hence the CD3 interpolate library is included by default. Controller User Implemented Functionality \u00b6 In creating this template, it was our intention to make the user developer experience as pleasant as possible. As mentioned, we found that different applications only differed in use case, and still shared the majority of drone functionality. In our state machine then, this corresponds to only executing application based at initialisation and during the execute state. We therefore decided to abstract this out into its own class of UserController within trajectory.hpp and trajectory.cpp . class UserController { public: UserController(UAVController *node); // Reset this controller void reset(); // User Controller Checking If The Start Location is Registered bool smReady(const rclcpp::Time& stamp); // User Controller Execute One Control Loop bool smExecute(const rclcpp::Time& stamp, const rclcpp::Duration& time_elapsed); private: // ROS Helper Functions rclcpp::Logger get_logger(); rclcpp::Time now(); // The ROSnode itself UAVController* node; // User variables ... } The UserController only has 3 functions of reset() , smReady(stamp) and smExecute(stamp, time_elapsed) which correspond with the parts of the State Machine which are important to the user. The other important variable is the node . This class is not a node in itself (a node cannot run another node). This variable is used for storing the main UAVController node, which is passed in during initialisation. It enables us to call useful functions later. So how does UserController fit into the main node? UserController is actually declared in main.hpp:99 and initialised in main.cpp:100 . Doing a ctrl+f and searching for this->user_controller you can see the places where it gets called, and they are as described above. So then, where does the user code go?! The code you write for your own applications goes in two places: New functions and variables to do with your code are declared below the node variable in controller.hpp Implementations of these functions, as well as your implementations of reset() , smReady(stamp) and smExecute(stamp, time_elapsed) should be provided in the gaps available in controller.cpp . Usefully for this example, we have already provided 80% of the implementation, including publishers and subscribers and the implmentation of all the core functions except smExecute(stamp, time_elapsed) which will be discussed below and left as an exercise for the reader. After the next section, have a read through controller.hpp and controller.cpp and try and follow the logic to see if it makes sense. A Solution to the Scenario \u00b6 You have been asked to prototype a particular scene within a drone display! In this scene a number of drones take off and automatically fly to starting points equidistant around a circle of a given radius. They then start circling around the edge of the circle attempting to stay equidistant to their neighbours. It is determined that the vehicles have not been well tuned and can end up lagging, so there exists a centralised server to monitor the vehicles and notify them if they are lagging behind. For the purpose of this tutorial, we have created this particular method of solving the problem, though other ways definitely exist! Unless you are confident in your ability, we ask that you follow along for now :) We take the approach of characterising a vehicle's position solely based on its angle theta, with the following steps: Server sends how many drones are on the network every few seconds and labels drones from 0+ (Uses NotifyVehicles msg) Drones use id to work out starting location around the circle Wait for GO to Takeoff Wait for valid start location and GO to move to start locations Wait for GO to continue Vehicle flies around in a circle During flight, vehicle sends its own theta every second to server (Uses TargetAngle msg) Server responds with angle it should be at right now with respect to other vehicles (Uses TargetAngle msg) A simple brute force algorithm is to imagine each vehicle was correct and calculate ideal locations of all other vehicles. Then return the average of each ideal location for each drone. Drones then proportionally change velocity based on angle disparity. Luckily for you all, the tutorial already implements all of these functions apart from part 5 and 6 which you will need to implement. Within controller.cpp your goal is to fill in steps 5 and 6 into the smExecute function. bool UserController::smExecute(const rclcpp::Time& stamp, const rclcpp::Duration& time_elapsed) { // Get Time Elapsed Since State Change double time_elapsed_sec = time_elapsed.seconds(); // Current Vehicle Location geometry_msgs::msg::PoseStamped current_pos = this->node->vehicle_local_position; /* * * Implement Your Solution Here * */ // State Machine never exists by giving false. return false; } As you're developing, dont forget to run make often to compile and build your code! This will help you catch syntax errors and other bugs as your go. You may also want to try out some of the local testing instructions in the next tutorial and come back and implement other bits. Useful Tips for Implementation \u00b6 We provide some guidelines and tips here for implementing the solution. Remember to have a look through the available variables as they can come in useful. You can access these variables using the this->(myvariable) functions. Getting the actual current theta \u00b6 The algorithm requires sending the vehicle's actual theta to the server for processing. The actual theta of the vehicle has to be calculated from the x,y location of the vehicle with respect to the origin location of the vehicle. Note: many mathematics functions such as atan2(x,y) , sin(x) , cos(x) are available as is in these formats. View spoilers and code double current_theta = atan2(current_pos->pose.position.y - this->origin.y, current_pos->pose.position.x - this->origin.x); Creating and Publishing Messages \u00b6 The server uses the TargetAngle and NotifyVehicle messages to communicate with the vehicle. The vehicle then sends TargetAngle messages back to the server at each execution step. Have a look at the TargetAngle msg inside your custom msgs folder. You can create a message in cpp using the following syntax: target_msgs::msg::TargetAngle msg; msg.vehicle_id = this->node->vehicle_id; ... The msg fields can be filled in by using the msg.<field> = <value> notation. Once you have created the correct message for a particular publisher, you can publish the message using: this->my_publisher->publish(msg); Make sure to check which publisher you should be publishing with. View spoilers and code target_msgs::msg::TargetAngle msg; msg.vehicle_id = this->node->vehicle_id; msg.time = stamp; msg.theta = current_theta; this->notify_angle_pub->publish(msg); Angular Velocity and Position \u00b6 Now we've sent the actual theta information to the server, we should now calculate where the vehicle should go. We are doing this based on the time that has been elapsed and the vehicle velocity to calculate a setpoint based on where the vehicle should be right now. You will first need to calculate the angular velocity to see what angle the vehicle should be currently at. You can then find the actual theta by calculating the number of radians travelled, in addition to the start location of the vehicle. You should set the calculated theta to the this->vehicle_setpoint_theta member variable. Note: You can use the fmod function to do a floating point modulo operation. View spoilers and code // Get Angular (Theta) Velocity double angular_vel = this->vehicle_velocity / circle_radius; // Amount of theta vehicle should have moved w.r.t start location this->vehicle_setpoint_theta = fmod(this->vehicle_start_theta + time_elapsed_sec * angular_vel, 2*M_PI); Theta to position \u00b6 Now you have calculated the setpoint theta, we now need to work out the cartesian (x,y,z) coordinate for the drone to fly to using its internal position control. This can be calculated using trigonometry: $$ x = r \\times cos(\\theta) \\qquad y = r \\times sin(\\theta)$$ x = r \\times cos(\\theta) \\qquad y = r \\times sin(\\theta) But don't forget about \\(z\\) z and yaw too! View spoilers and code // Convert theta to coordinate location double x = this->circle_radius * cos(this->vehicle_setpoint_theta) + this->origin.x; double y = this->circle_radius * sin(this->vehicle_setpoint_theta) + this->origin.y; double z = this->height + this->origin.z; double yaw = this->vehicle_setpoint_theta; Sending Vehicle Setpoint \u00b6 Finally, having calculated the position the vehicle should visit, you can send off the Setpoint position for the vehicle to execute using the node's built in function. // Tell Vehicle to go to coordinate location this->node->sendSetpointPositionCoordinate(stamp, x, y, z, yaw); // Log this using the following function RCLCPP_INFO(this->get_logger(), \"Vehicle going to (%f, %f, %f), theta: %f\", x, y, z, yaw Next Steps \u00b6 Congrats! You have hopefully either begun or completed the implementation of a controller which solves the example problem. You should now have a decent understanding of how the core UAV rosnode controller template is constructed. Have a look at the implementation for the offboard controller and see if you can match its functionality with the algorithm steps shown above. See if you can identify how it connects with the controller you have just written. However, we now need to check its functionality - is it actually working or doing what we expect? We will cover how to perform local development and testing in the next chapter.","title":"6. Developing the example controller with ROS2 in CPP"},{"location":"cpp_example_dev/#developing-the-example-controller-with-ros2-in-cpp","text":"Finally, the bit you have all been waiting for! In this tutorial, we will take you through how to develop and build the controller for the example scenario. This page is for the CPP controller in particular. By the end, you should have a controller ready for testing. Developing the example controller with ROS2 in CPP Very Very Quick Intro to CPP Overview of the Controller Template Controller Core Functionality Controller Communication with MAVROS Controller User Implemented Functionality A Solution to the Scenario Useful Tips for Implementation Getting the actual current theta Creating and Publishing Messages Angular Velocity and Position Theta to position Sending Vehicle Setpoint Next Steps","title":"Developing the example controller with ROS2 in CPP"},{"location":"cpp_example_dev/#very-very-quick-intro-to-cpp","text":"By the time of the launch of this tutorial, we may not have an equivalent tutorial in Python. Therefore we provide a very very very quick intro to the bits of CPP you need to know about for this tutorial. We recommend you check out online tutorials on CPP for a much more complete introduction! So in no particular order: CPP is an Object Orientated-ish Language, so we have the idea of Classes which contain member variables and member functions. We also have the concept of inheritance, where a child class inherits the functionality and variables from its parent class. In ROS2, every rosnode class inherits from the rclcpp (ROS CPP Library) Node class. class UAVController : public rclcpp::Node { public: UAVController(); void reset(); private: std::string vehicle_id = \"vehicle_1\"; } In CPP, it is standard practice to split the declaration of functions and variables from the implementation of those same functions and variables into separate files. Reasons includes space saving, verboseness and other things - look it up. Header files (files with extension .h / .hpp ) contain all of the class and function declarations, like the example shown above. The syntax for a function declaration is <return type> <function_name>(<function arguments>); . The syntax to create a variable is <variable type> variable_name; , and can either be immediately assigned to or assigned later. Note that CPP is typed , which means that all functions and variables must specify what they intend to take as argument, return or be explictly (unlike Python). Source files (files with extension .h / .cpp ) contain the implementation of the class and functions which have been declared in the assocated header file (imported with #include <header.hpp> ). The following shows the implementation of the reset function in the source file, corresponding to the class in the header. Within the implementation, class variables can be used by accessing the this variable. Note that instead of a . , an arrow -> is used. An arrow is needed to access anything which is of a pointer type sth_ptr (the this variable is a pointer to itself). This should be enough for now - read up for much more detail). void UAVController::reset(){ // ... some implementation this->vehicle_id = \"default_vehicle_name\"; } As with most languages, CPP has the standard control flow operations - if , for , while , continue , return , etc that you would see in most other languages. Hopefully you can infer how these and the various other CPP elements work from reading the code! Good luck! :D","title":"Very Very Quick Intro to CPP"},{"location":"cpp_example_dev/#overview-of-the-controller-template","text":"Important: Have the code open in your editor of choice and follow along with the explanation. Let's start by examining the CPP onboard controller in more detail. As shown in the creating a starling project tutorial , the CPP onboard controller has the following structure: |-- CMakeLists.txt |-- include | |-- controller.hpp | |-- main.hpp | `-- state.hpp |-- launch | `-- template_cpp_node.launch.xml |-- package.xml `-- src |-- controller.cpp `-- main.cpp We gave an overview there, but we didn't provide any details on what exactly the CPP files are doing! So we now go into more detail.","title":"Overview of the Controller Template"},{"location":"cpp_example_dev/#controller-core-functionality","text":"In addition to performing the application, this controller must take care of a number of normal functions before and after executing the actions of the application. This includes the following actions: Ensuring and checking that the vehicle is receiving telemetry Arming and Disarming the Vehicle before and after flight Taking off from the ground and Landing safely Going to the start location of the given task Taking instruction (such as go, abort and estop) and safely reacting to them from users The order and usage of these actions are fairly consistent over a large number of possible applications, so this controller bundles them up as standard functionality available in the main execution of the node. The main.hpp and main.cpp files define a UAVController rosnode class. In this class, after initialisation, a timer is used to run a main operating loop function over and over at a fixed interval (10hz by default). Our controller makes use of a finite state machine model to manage the control flow through the various states mentioned above. This FSM is shown in the diagram below. The Rectangular boxes (apart from the red ones) all depict States of this FSM. Each state requires a number of orange actions to complete or checks to pass before it can move onto the next state. The green states also include live checks for if the vehicle is armed and in the correct mode for offboard flight, as the vehicle will be in the air. The FSM also contains failure states for any of the checks in which the vehicle which go to Stop, and therefore immediately land. The functionality of this state machine is encoded within the stateMachine(Time stamp) function, and is triggered by a Ros Timer running at 10hz ( this->execution_timer ). The States are defined in state.hpp . From an implementation standpoint, since the state machine has to run continuously, any called function cannot internally loop indefinitely and must execute and immediately exit. Traditionally FSMs switch states through the use of a large set of binary variables. In this particular application, this felt very verbose, and so we use boolean returning execution functions as our state machine checks. For example, the Takeoff check calls to see whether this->smTakeoffVehicle(stamp) (main.cpp:246) returns true. case State::TAKEOFF: this->smOffboardArmed(stamp); if(!this->smTakeoffVehicle(stamp)) { RCLCPP_INFO(this->get_logger(), \"Waiting for Takeoff\"); } However, if we look at this function, it itself performs the takeoff procedure to a given height, always returning false, unless the vehicle is at its takeoff location.","title":"Controller Core Functionality"},{"location":"cpp_example_dev/#controller-communication-with-mavros","text":"Now we have the controller architecture in play, how does this controller actually talk to the vehicle? At the bottom of main.hpp you should see a whole bunch of Ros Publishers and Subscribers being declared (note how they are pointers). These pubs and subs are initialised within the class constructor/initialiser in main.cpp:67-97 . In order to detect arming and mode, we subscribe to mavros/state , and in order to get the local cartesian position and orientation of the vehicle, we also get mavros/local_position/pose . These both give us a constant stream of data which we save into variables this->vehicle_state and this->vehicle_local_position . In order to send position commands to the vehicle, we set up a publisher to mavros/setpoint_position/local and use the sendSetpointPositionPose(stamp, geometry_msgs::msg::PoseStamped) function to publish setpoints to the autopilot. The translated MAVLINK commands then tell the drone to go to that location and orientation immediately. Therefore in a number of places, we make use of interpolators to ensure that the vehicle can move from its location to any other at safe velocities and rates. Otherwise, the drone will ramp up to maximum velocity to go to far away locations which can be quite dangerous! Hence the CD3 interpolate library is included by default.","title":"Controller Communication with MAVROS"},{"location":"cpp_example_dev/#controller-user-implemented-functionality","text":"In creating this template, it was our intention to make the user developer experience as pleasant as possible. As mentioned, we found that different applications only differed in use case, and still shared the majority of drone functionality. In our state machine then, this corresponds to only executing application based at initialisation and during the execute state. We therefore decided to abstract this out into its own class of UserController within trajectory.hpp and trajectory.cpp . class UserController { public: UserController(UAVController *node); // Reset this controller void reset(); // User Controller Checking If The Start Location is Registered bool smReady(const rclcpp::Time& stamp); // User Controller Execute One Control Loop bool smExecute(const rclcpp::Time& stamp, const rclcpp::Duration& time_elapsed); private: // ROS Helper Functions rclcpp::Logger get_logger(); rclcpp::Time now(); // The ROSnode itself UAVController* node; // User variables ... } The UserController only has 3 functions of reset() , smReady(stamp) and smExecute(stamp, time_elapsed) which correspond with the parts of the State Machine which are important to the user. The other important variable is the node . This class is not a node in itself (a node cannot run another node). This variable is used for storing the main UAVController node, which is passed in during initialisation. It enables us to call useful functions later. So how does UserController fit into the main node? UserController is actually declared in main.hpp:99 and initialised in main.cpp:100 . Doing a ctrl+f and searching for this->user_controller you can see the places where it gets called, and they are as described above. So then, where does the user code go?! The code you write for your own applications goes in two places: New functions and variables to do with your code are declared below the node variable in controller.hpp Implementations of these functions, as well as your implementations of reset() , smReady(stamp) and smExecute(stamp, time_elapsed) should be provided in the gaps available in controller.cpp . Usefully for this example, we have already provided 80% of the implementation, including publishers and subscribers and the implmentation of all the core functions except smExecute(stamp, time_elapsed) which will be discussed below and left as an exercise for the reader. After the next section, have a read through controller.hpp and controller.cpp and try and follow the logic to see if it makes sense.","title":"Controller User Implemented Functionality"},{"location":"cpp_example_dev/#a-solution-to-the-scenario","text":"You have been asked to prototype a particular scene within a drone display! In this scene a number of drones take off and automatically fly to starting points equidistant around a circle of a given radius. They then start circling around the edge of the circle attempting to stay equidistant to their neighbours. It is determined that the vehicles have not been well tuned and can end up lagging, so there exists a centralised server to monitor the vehicles and notify them if they are lagging behind. For the purpose of this tutorial, we have created this particular method of solving the problem, though other ways definitely exist! Unless you are confident in your ability, we ask that you follow along for now :) We take the approach of characterising a vehicle's position solely based on its angle theta, with the following steps: Server sends how many drones are on the network every few seconds and labels drones from 0+ (Uses NotifyVehicles msg) Drones use id to work out starting location around the circle Wait for GO to Takeoff Wait for valid start location and GO to move to start locations Wait for GO to continue Vehicle flies around in a circle During flight, vehicle sends its own theta every second to server (Uses TargetAngle msg) Server responds with angle it should be at right now with respect to other vehicles (Uses TargetAngle msg) A simple brute force algorithm is to imagine each vehicle was correct and calculate ideal locations of all other vehicles. Then return the average of each ideal location for each drone. Drones then proportionally change velocity based on angle disparity. Luckily for you all, the tutorial already implements all of these functions apart from part 5 and 6 which you will need to implement. Within controller.cpp your goal is to fill in steps 5 and 6 into the smExecute function. bool UserController::smExecute(const rclcpp::Time& stamp, const rclcpp::Duration& time_elapsed) { // Get Time Elapsed Since State Change double time_elapsed_sec = time_elapsed.seconds(); // Current Vehicle Location geometry_msgs::msg::PoseStamped current_pos = this->node->vehicle_local_position; /* * * Implement Your Solution Here * */ // State Machine never exists by giving false. return false; } As you're developing, dont forget to run make often to compile and build your code! This will help you catch syntax errors and other bugs as your go. You may also want to try out some of the local testing instructions in the next tutorial and come back and implement other bits.","title":"A Solution to the Scenario"},{"location":"cpp_example_dev/#useful-tips-for-implementation","text":"We provide some guidelines and tips here for implementing the solution. Remember to have a look through the available variables as they can come in useful. You can access these variables using the this->(myvariable) functions.","title":"Useful Tips for Implementation"},{"location":"cpp_example_dev/#getting-the-actual-current-theta","text":"The algorithm requires sending the vehicle's actual theta to the server for processing. The actual theta of the vehicle has to be calculated from the x,y location of the vehicle with respect to the origin location of the vehicle. Note: many mathematics functions such as atan2(x,y) , sin(x) , cos(x) are available as is in these formats. View spoilers and code double current_theta = atan2(current_pos->pose.position.y - this->origin.y, current_pos->pose.position.x - this->origin.x);","title":"Getting the actual current theta"},{"location":"cpp_example_dev/#creating-and-publishing-messages","text":"The server uses the TargetAngle and NotifyVehicle messages to communicate with the vehicle. The vehicle then sends TargetAngle messages back to the server at each execution step. Have a look at the TargetAngle msg inside your custom msgs folder. You can create a message in cpp using the following syntax: target_msgs::msg::TargetAngle msg; msg.vehicle_id = this->node->vehicle_id; ... The msg fields can be filled in by using the msg.<field> = <value> notation. Once you have created the correct message for a particular publisher, you can publish the message using: this->my_publisher->publish(msg); Make sure to check which publisher you should be publishing with. View spoilers and code target_msgs::msg::TargetAngle msg; msg.vehicle_id = this->node->vehicle_id; msg.time = stamp; msg.theta = current_theta; this->notify_angle_pub->publish(msg);","title":"Creating and Publishing Messages"},{"location":"cpp_example_dev/#angular-velocity-and-position","text":"Now we've sent the actual theta information to the server, we should now calculate where the vehicle should go. We are doing this based on the time that has been elapsed and the vehicle velocity to calculate a setpoint based on where the vehicle should be right now. You will first need to calculate the angular velocity to see what angle the vehicle should be currently at. You can then find the actual theta by calculating the number of radians travelled, in addition to the start location of the vehicle. You should set the calculated theta to the this->vehicle_setpoint_theta member variable. Note: You can use the fmod function to do a floating point modulo operation. View spoilers and code // Get Angular (Theta) Velocity double angular_vel = this->vehicle_velocity / circle_radius; // Amount of theta vehicle should have moved w.r.t start location this->vehicle_setpoint_theta = fmod(this->vehicle_start_theta + time_elapsed_sec * angular_vel, 2*M_PI);","title":"Angular Velocity and Position"},{"location":"cpp_example_dev/#theta-to-position","text":"Now you have calculated the setpoint theta, we now need to work out the cartesian (x,y,z) coordinate for the drone to fly to using its internal position control. This can be calculated using trigonometry: $$ x = r \\times cos(\\theta) \\qquad y = r \\times sin(\\theta)$$ x = r \\times cos(\\theta) \\qquad y = r \\times sin(\\theta) But don't forget about \\(z\\) z and yaw too! View spoilers and code // Convert theta to coordinate location double x = this->circle_radius * cos(this->vehicle_setpoint_theta) + this->origin.x; double y = this->circle_radius * sin(this->vehicle_setpoint_theta) + this->origin.y; double z = this->height + this->origin.z; double yaw = this->vehicle_setpoint_theta;","title":"Theta to position"},{"location":"cpp_example_dev/#sending-vehicle-setpoint","text":"Finally, having calculated the position the vehicle should visit, you can send off the Setpoint position for the vehicle to execute using the node's built in function. // Tell Vehicle to go to coordinate location this->node->sendSetpointPositionCoordinate(stamp, x, y, z, yaw); // Log this using the following function RCLCPP_INFO(this->get_logger(), \"Vehicle going to (%f, %f, %f), theta: %f\", x, y, z, yaw","title":"Sending Vehicle Setpoint"},{"location":"cpp_example_dev/#next-steps","text":"Congrats! You have hopefully either begun or completed the implementation of a controller which solves the example problem. You should now have a decent understanding of how the core UAV rosnode controller template is constructed. Have a look at the implementation for the offboard controller and see if you can match its functionality with the algorithm steps shown above. See if you can identify how it connects with the controller you have just written. However, we now need to check its functionality - is it actually working or doing what we expect? We will cover how to perform local development and testing in the next chapter.","title":"Next Steps"},{"location":"creating/","text":"Creating your own Starling Project \u00b6 This tutorial takes you through using the Starling templates repository to generate your own custom Starling application. Creating your own Starling Project Prerequisites Project Structure Planning Generating the base Starling Project Adding Nodes to your project What is in the templates cpp_ros2_node_onboard_template python_ros2_node_offboard_template ros2_msgs_template Dockerfile Running your new project Initialising Git Next Steps Prerequisites \u00b6 In order to complete this tutorial, you will need to install the following. You may have already installed these during Getting Started . The template generation uses the cookiecutter tool for generating custom projects from a template. To install it, run the following: python3 -m pip install --user cookiecutter # or easy_install --user cookiecutter See Cookiecutter Installation for details for different platforms. This will give you access to the cookiecutter command line interface, which is used in this section . We also recommend you sign up for Docker Hub and Github as both are necessary if you wish to fly your controller in the real world. Project Structure Planning \u00b6 Before diving in to creating your project, you first need to decide on the structure of the project. The structure is determined by the application, and the functionality is split between the central server and each vehicle. Let's review our task for this tutorial: In this scene, a number of drones take off and automatically fly to starting points equidistant around a circle of a given radius. They then start circling around the edge of the circle attempting to stay equidistant to their neighbours. It is determined that the vehicles have not been well tuned and can end up lagging, so a centralised server monitors all the vehicles and notifies them if they are lagging behind. A Starling Project is comprised of one or more ROS Nodes which each encompass one piece of functionality. In this project we can identify the following requirements: A node onboard the vehicle which can arm, takeoff, land and fly it in a circle of radius r from a given start location in a safe manner. A node offboard on the central server which receives vehicle locations, finds the ideal locations and then sends that information back to the vehicles. We can see that we may also need to provide a set of custom messages for the communication of specific information between server and vehicle. Therefore, we will need this Starling Project to contain the source code for an onboard node, an offboard node and a set of custom messages. An important task is then to name these beforehand as we need a way to refer to them in the next step. We've used some example names below, but please try to give yours better names :) Offboard node: template_python_node Onboard node: template_cpp_node Custom msgs: template_msgs Generating the base Starling Project \u00b6 The first step is to build your own Starling project. The following will start the process of generating the base Starling project. In your workspace, run the following command. cookiecutter https://github.com/StarlingUAS/starling_controller_templates.git --directory starling_template You will then be prompted to fill in some details. The value in the angle brackets indicate the default value if you choose not to enter anything. Press Enter to go on to the next one. The inputs include the following. Name Description Full Name Your name used for documentaiton Email Your email address used for documentation Short Description A short description of your project added to the documentation and project files Project Name The name you have given to this Starling Project, make sure that you are happy with this as changing the name after fact is a bit of a pain. Github Username (Optional) Your Github username for filling in the README and metadata Docker Username (Optional) Your Docker Hub username which is used for naming the Starling image. Will be used to upload to if you wish to push it online. Docker Image Name The name of the Starling image that this repository produces Docker Image Name Full An autogenerated name based on your username and image name, you can leave as the default unless you really want to change it. By default it is <Docker Username>/<Docker Image Name> Onboard ROS2 Package Name The name of the onboard controller which this containers Dockerfile will run in onboard mode. Offboard ROS2 Package Name The name of the offboard controller which this containers Dockerfile will run in offboard mode. Note: The last two entries should correspond to the node names you came up with in the planning phase. Note: The last two entries are for automatically populating the run.sh script. The run.sh script is the default script your project's Docker container runs on startup. You can leave these two as defaults and edit the run.sh script later. Once complete, the project will be generated into a directory named as project_name . For example, the default project with name starling_controller produces a project with the following structure: starling_controller |-- buildtools |-- docker-bake.hcl |-- deployment |-- docker-compose.yml |-- kubernetes.yaml |-- starling_controller |-- run.sh |-- Dockerfile |-- LICENSE |-- Makefile |-- README.md We have the following folders and files. starling_controller will be populated by user-created ros packages. Anything in this folder is directly copied to the Dockerfile and built. deployment contains a sample docker-compose.yml file which runs a default simulation stack, and a sample Kubernetes file for deployment, both will need to be edited to run properly. buildtools contains the specification that Docker uses to build the container. It contains the naming for the Docker image. Dockerfile specifies the build steps for this project. It already specifies the installation of a number of dependencies, including the libInterpolate interpolation library. Once generated, the Makefile can be used to build and run commands: cd <Your Application Name> # Go into the your new Starling application directory make # Will build the project make run # Will build and run the container make run_bash # Will build and run the container, putting you in a bash shell inside it. make help # Shows the help screen This should successfuly build your project container which you can try and run or inspect. Currently it has no functionality so nothing can happen. Have a look inside the container using make run_bash . Note On Windows you can either use WSL to run the make commands. Alternatively, check out this link for other solutions. Adding Nodes to your project \u00b6 The generated project has no functionality right now. This repository contains other templates which will generate rosnodes for you. In particular cpp_ros2_node_onboard_template : Generates a ROS2 node, designed for running onboard the vehicle written in CPP. python_ros2_node_offboard_template : Generates a ROS2 node, designed for running offboard (central server) written in Python ros2_msgs_template : Generates a ROS2 msgs package which can be used by any ROS2 package within this container. These nodes can be added to your project using the following cookiecutter commands. Note that the packages should be generated in the starling_project_name directory of the base Starling project. Each of these commands are single line commands. Navigate into <your project name>/<your project name> e.g. starling_controller/starling_controller (by default this should only contain the file run.sh and run the following) # CPP Onboard cookiecutter https://github.com/StarlingUAS/starling_controller_templates.git --directory cpp_ros2_node_onboard_template # Python Offboard cookiecutter https://github.com/StarlingUAS/starling_controller_templates.git --directory python_ros2_node_offboard_template # Messages cookiecutter https://github.com/StarlingUAS/starling_controller_templates.git --directory ros2_msgs_template Note the --directory argument points cookiecutter to the correct template; the -o argument specifies the output directory, which in our case should be inside the created Starling project. Similar to the base project generation, these commands will ask you a number of questions during the generation. Most importantly, it will ask what the package_name is which will become the name of that particular node package. Name Default Description full_name starling_user Your name used for documentation email starling.user@starling.co.uk Your email address used for documentation year 2022 The year of creation for documentation package_name template_node The name of this ROS2 Node, make sure this is correct and note it down . It should match the ones given in the initial Starling setup short_description ROS2 node template A short description of the functionality of this node for documentation and project files custom_ros2_msgs_name template_msgs Important! The name of the custom msgs package name you added as part of this Starling project. The name must match exactly otherwise the default functionality will fail! Note convention for msg packages is to have a package name of format <mymessages>_msgs , e.g. circle_experiment_msgs . Note For those familiar with ROS1, it is ROS2 convention to keep messages in a separate package to the ros nodes themselves. This should give you a file tree that looks something like the following (of course with your package names instead) starling_controller |-- buildtools |-- docker-bake.hcl |-- deployment |-- docker-compose.yml |-- kubernetes.yaml |-- starling_controller |-- template_onboard_controller |-- ... |-- template_offboard_controller |-- ... |-- template_msgs |-- ... |-- run.sh |-- Dockerfile |-- LICENSE |-- Makefile |-- README.md The nodes can be run standalone for your own projects, one at a time, or whenever you need a new node within your project. Once these packages have been placed within the correct directory inside the Starling project, you can simply run make to check that they successfully build. What is in the templates \u00b6 The set of node templates above should create you a project which runs the example scenario specifically developed for the purpose of this tutorial. This example has been designed to show the development of an onboard and an offboard container, as well as demonstrate communication between the two containers. The scenario is as follows: We have \\(n\\) n drones which we would like to fly equidistant around a circle of fixed radius at a initial velocity. A central server will send each drone an id \\(i<n\\) i<n to determine its start location around the circle. Once received the drones will start flying around the circle and send its current position to the server. The server collates the drones information to determine if any of the drones are lagging or ahead of where they should be. This ideal position is sent back to each drone. The drone adjusts its velocity to try and match with the ideal. We can now quickly run through what is in each of the ros node templates. Note: More detail about the actual functionality within these nodes will be in this tutorial section cpp_ros2_node_onboard_template \u00b6 |-- CMakeLists.txt |-- include | |-- controller.hpp | |-- main.hpp | `-- state.hpp |-- launch | `-- template_cpp_node.launch.xml |-- package.xml `-- src |-- controller.cpp `-- main.cpp This node runs onboard the vehicle and interfaces with MAVROS. It contains a state machine with functionality to arm, takeoff, land, loiter and takes care of safety functionality. CMakeLists.txt : contains the instructions to build this rosnode. This includes specifying dependencies and extra libraries (e.g. messages such as geometry_msgs or external dependencies). It also specifies the name of the binary containing all of your functionality. By default this is controller . include and src : In CPP, your code files are split into header files (specifying object definitions) and source files (specifying object functionality), these are stored here launch : contains a ROS launch file. We use XML notation to describe how your rosnode gets launched, including extra parameters or other changes you want to make at runtime instead of buildtime. This is what gets run to run your rosnode package.xml : ROS2 Metadata file specifying ros2 dependencies of your project. As a brief overview of the code files: main.hpp and main.cpp : Contains the program entrypoint function and the core of the ros node. It contains all of the core functionality to fly a vehicle as well as the state machine. It includes the user controller specified in controller.hpp to be expected to run during the execution phase of the state machine. controller.hpp and controller.cpp : For the majority of simple applications, a user should only need to provide their own version of these files. The controller contains an initialisation and loop function which a user can fill in. state.hpp : A header only file containing the states of the state machine. python_ros2_node_offboard_template \u00b6 |-- package.xml |-- resource | `-- template_python_node |-- setup.cfg |-- setup.py |-- template_python_node | |-- __init__.py | `-- main.py `-- test |-- test_copyright.py |-- test_flake8.py `-- test_pep257.py This node runs offboard on the central server. It is designed to run on its own with no external dependency on anything outside of the application. package.xml : ROS2 Metadata file specifying ros2 dependencies of your project. resource : A Python ros package special folder, do not touch setup.cfg : Configuration file specifying where key resources are setup.py : The Python equivalent of CMakeLists.txt and contains the instructions to build this rosnode. It specifies which resources are copied over and available to the rosnode at runtime. Also specifies the name of the binary, and which function it is intended to run. By default this is controller <your rosnode name> e.g. template_python_node : The source directory for your python files. test : A number of testing utilities which can be run with pytest. Currently not used. A brief overview of code files: main.py : Contains a ros node which uses a timer to repeat poll the current state of vehicles on the network at given intervals. It then performs the calculation of ideal vehicle location and sends that to the vehicles. ros2_msgs_template \u00b6 |-- CMakeLists.txt |-- msg | |-- NotifyVehicles.msg | `-- TargetAngle.msg `-- package.xml This node is purely for specifying and building the custom ros messages in our application. Any application which uses these messages need a compiled version of this node. CMakeLists.txt : contains the instructions to build the messages. Any extra messages or services need to be added to the CMakeLists. msg : A list of specified custom messages. package.xml : ROS2 Metadata file specifying ros2 dependencies of your project. Dockerfile \u00b6 As mentioned in the previous tutorial , a Dockerfile is used as a recipe to build your controller Docker container. The Dockerfile in this template contains the command line instructions to build your controller. By default, it will install a number of useful libraries for compatibility. If you need any new libraries, you will have to add their installation here! It then essentially copies in all of the rosnodes specified within the project name directory and runs them through the standard ROS2 build tool named colcon . It also copies over the run.sh file which the Dockerfile will run on container startup. Therefore the run.sh should have the instructions for running your applications. Thankfully, you do not need to run docker build automatically as we have set up a special build system which is wrapped up inside the Makefile . Running your new project \u00b6 With your project now constructed, you can now re-run your container with the same make commands as earlier. cd <Your Application Name> # Go into the your new Starling application directory make run # Will build and run the container This will build a container called <Docker Username>/<Docker Image Name> with tag latest e.g. myname/starling_template:latest This will start the onboard controller by default, but it will start complaining that it hasn't received any state or position messages for initialisation. This is normal for now! If you want to start the offboard controller, you can add the extra option ENV=\"-e OFFBOARD=true\" to the make command like so make run ENV=\"-e OFFBOARD=true\" . It will then start trying to identify the number of vehicles on the network, but of course it cannot find any! You can have a look inside both containers using make run_bash . Initialising Git \u00b6 Optionally, at this point you can set up version control on your project in order to save your progress. To initialise git and create your first commit, go to the root of your project and run: git init git add -A git commit -m \"Initial Commit\" If you want to push this code onto github, you can follow this tutorial . In short, create an empty Github repository of the same name in your Github account, and change the remote locally: git remote add origin <remote repository URL> git remote -v git push origin master Next Steps \u00b6 Congratulations, you now have your own Starling application! It doesn't have any functionality yet but before we get to adding some, it's important to understand how you run the simulation for you to test your controller against!","title":"4. Creating your own Starling project"},{"location":"creating/#creating-your-own-starling-project","text":"This tutorial takes you through using the Starling templates repository to generate your own custom Starling application. Creating your own Starling Project Prerequisites Project Structure Planning Generating the base Starling Project Adding Nodes to your project What is in the templates cpp_ros2_node_onboard_template python_ros2_node_offboard_template ros2_msgs_template Dockerfile Running your new project Initialising Git Next Steps","title":"Creating your own Starling Project"},{"location":"creating/#prerequisites","text":"In order to complete this tutorial, you will need to install the following. You may have already installed these during Getting Started . The template generation uses the cookiecutter tool for generating custom projects from a template. To install it, run the following: python3 -m pip install --user cookiecutter # or easy_install --user cookiecutter See Cookiecutter Installation for details for different platforms. This will give you access to the cookiecutter command line interface, which is used in this section . We also recommend you sign up for Docker Hub and Github as both are necessary if you wish to fly your controller in the real world.","title":"Prerequisites"},{"location":"creating/#project-structure-planning","text":"Before diving in to creating your project, you first need to decide on the structure of the project. The structure is determined by the application, and the functionality is split between the central server and each vehicle. Let's review our task for this tutorial: In this scene, a number of drones take off and automatically fly to starting points equidistant around a circle of a given radius. They then start circling around the edge of the circle attempting to stay equidistant to their neighbours. It is determined that the vehicles have not been well tuned and can end up lagging, so a centralised server monitors all the vehicles and notifies them if they are lagging behind. A Starling Project is comprised of one or more ROS Nodes which each encompass one piece of functionality. In this project we can identify the following requirements: A node onboard the vehicle which can arm, takeoff, land and fly it in a circle of radius r from a given start location in a safe manner. A node offboard on the central server which receives vehicle locations, finds the ideal locations and then sends that information back to the vehicles. We can see that we may also need to provide a set of custom messages for the communication of specific information between server and vehicle. Therefore, we will need this Starling Project to contain the source code for an onboard node, an offboard node and a set of custom messages. An important task is then to name these beforehand as we need a way to refer to them in the next step. We've used some example names below, but please try to give yours better names :) Offboard node: template_python_node Onboard node: template_cpp_node Custom msgs: template_msgs","title":"Project Structure Planning"},{"location":"creating/#generating-the-base-starling-project","text":"The first step is to build your own Starling project. The following will start the process of generating the base Starling project. In your workspace, run the following command. cookiecutter https://github.com/StarlingUAS/starling_controller_templates.git --directory starling_template You will then be prompted to fill in some details. The value in the angle brackets indicate the default value if you choose not to enter anything. Press Enter to go on to the next one. The inputs include the following. Name Description Full Name Your name used for documentaiton Email Your email address used for documentation Short Description A short description of your project added to the documentation and project files Project Name The name you have given to this Starling Project, make sure that you are happy with this as changing the name after fact is a bit of a pain. Github Username (Optional) Your Github username for filling in the README and metadata Docker Username (Optional) Your Docker Hub username which is used for naming the Starling image. Will be used to upload to if you wish to push it online. Docker Image Name The name of the Starling image that this repository produces Docker Image Name Full An autogenerated name based on your username and image name, you can leave as the default unless you really want to change it. By default it is <Docker Username>/<Docker Image Name> Onboard ROS2 Package Name The name of the onboard controller which this containers Dockerfile will run in onboard mode. Offboard ROS2 Package Name The name of the offboard controller which this containers Dockerfile will run in offboard mode. Note: The last two entries should correspond to the node names you came up with in the planning phase. Note: The last two entries are for automatically populating the run.sh script. The run.sh script is the default script your project's Docker container runs on startup. You can leave these two as defaults and edit the run.sh script later. Once complete, the project will be generated into a directory named as project_name . For example, the default project with name starling_controller produces a project with the following structure: starling_controller |-- buildtools |-- docker-bake.hcl |-- deployment |-- docker-compose.yml |-- kubernetes.yaml |-- starling_controller |-- run.sh |-- Dockerfile |-- LICENSE |-- Makefile |-- README.md We have the following folders and files. starling_controller will be populated by user-created ros packages. Anything in this folder is directly copied to the Dockerfile and built. deployment contains a sample docker-compose.yml file which runs a default simulation stack, and a sample Kubernetes file for deployment, both will need to be edited to run properly. buildtools contains the specification that Docker uses to build the container. It contains the naming for the Docker image. Dockerfile specifies the build steps for this project. It already specifies the installation of a number of dependencies, including the libInterpolate interpolation library. Once generated, the Makefile can be used to build and run commands: cd <Your Application Name> # Go into the your new Starling application directory make # Will build the project make run # Will build and run the container make run_bash # Will build and run the container, putting you in a bash shell inside it. make help # Shows the help screen This should successfuly build your project container which you can try and run or inspect. Currently it has no functionality so nothing can happen. Have a look inside the container using make run_bash . Note On Windows you can either use WSL to run the make commands. Alternatively, check out this link for other solutions.","title":"Generating the base Starling Project"},{"location":"creating/#adding-nodes-to-your-project","text":"The generated project has no functionality right now. This repository contains other templates which will generate rosnodes for you. In particular cpp_ros2_node_onboard_template : Generates a ROS2 node, designed for running onboard the vehicle written in CPP. python_ros2_node_offboard_template : Generates a ROS2 node, designed for running offboard (central server) written in Python ros2_msgs_template : Generates a ROS2 msgs package which can be used by any ROS2 package within this container. These nodes can be added to your project using the following cookiecutter commands. Note that the packages should be generated in the starling_project_name directory of the base Starling project. Each of these commands are single line commands. Navigate into <your project name>/<your project name> e.g. starling_controller/starling_controller (by default this should only contain the file run.sh and run the following) # CPP Onboard cookiecutter https://github.com/StarlingUAS/starling_controller_templates.git --directory cpp_ros2_node_onboard_template # Python Offboard cookiecutter https://github.com/StarlingUAS/starling_controller_templates.git --directory python_ros2_node_offboard_template # Messages cookiecutter https://github.com/StarlingUAS/starling_controller_templates.git --directory ros2_msgs_template Note the --directory argument points cookiecutter to the correct template; the -o argument specifies the output directory, which in our case should be inside the created Starling project. Similar to the base project generation, these commands will ask you a number of questions during the generation. Most importantly, it will ask what the package_name is which will become the name of that particular node package. Name Default Description full_name starling_user Your name used for documentation email starling.user@starling.co.uk Your email address used for documentation year 2022 The year of creation for documentation package_name template_node The name of this ROS2 Node, make sure this is correct and note it down . It should match the ones given in the initial Starling setup short_description ROS2 node template A short description of the functionality of this node for documentation and project files custom_ros2_msgs_name template_msgs Important! The name of the custom msgs package name you added as part of this Starling project. The name must match exactly otherwise the default functionality will fail! Note convention for msg packages is to have a package name of format <mymessages>_msgs , e.g. circle_experiment_msgs . Note For those familiar with ROS1, it is ROS2 convention to keep messages in a separate package to the ros nodes themselves. This should give you a file tree that looks something like the following (of course with your package names instead) starling_controller |-- buildtools |-- docker-bake.hcl |-- deployment |-- docker-compose.yml |-- kubernetes.yaml |-- starling_controller |-- template_onboard_controller |-- ... |-- template_offboard_controller |-- ... |-- template_msgs |-- ... |-- run.sh |-- Dockerfile |-- LICENSE |-- Makefile |-- README.md The nodes can be run standalone for your own projects, one at a time, or whenever you need a new node within your project. Once these packages have been placed within the correct directory inside the Starling project, you can simply run make to check that they successfully build.","title":"Adding Nodes to your project"},{"location":"creating/#what-is-in-the-templates","text":"The set of node templates above should create you a project which runs the example scenario specifically developed for the purpose of this tutorial. This example has been designed to show the development of an onboard and an offboard container, as well as demonstrate communication between the two containers. The scenario is as follows: We have \\(n\\) n drones which we would like to fly equidistant around a circle of fixed radius at a initial velocity. A central server will send each drone an id \\(i<n\\) i<n to determine its start location around the circle. Once received the drones will start flying around the circle and send its current position to the server. The server collates the drones information to determine if any of the drones are lagging or ahead of where they should be. This ideal position is sent back to each drone. The drone adjusts its velocity to try and match with the ideal. We can now quickly run through what is in each of the ros node templates. Note: More detail about the actual functionality within these nodes will be in this tutorial section","title":"What is in the templates"},{"location":"creating/#cpp_ros2_node_onboard_template","text":"|-- CMakeLists.txt |-- include | |-- controller.hpp | |-- main.hpp | `-- state.hpp |-- launch | `-- template_cpp_node.launch.xml |-- package.xml `-- src |-- controller.cpp `-- main.cpp This node runs onboard the vehicle and interfaces with MAVROS. It contains a state machine with functionality to arm, takeoff, land, loiter and takes care of safety functionality. CMakeLists.txt : contains the instructions to build this rosnode. This includes specifying dependencies and extra libraries (e.g. messages such as geometry_msgs or external dependencies). It also specifies the name of the binary containing all of your functionality. By default this is controller . include and src : In CPP, your code files are split into header files (specifying object definitions) and source files (specifying object functionality), these are stored here launch : contains a ROS launch file. We use XML notation to describe how your rosnode gets launched, including extra parameters or other changes you want to make at runtime instead of buildtime. This is what gets run to run your rosnode package.xml : ROS2 Metadata file specifying ros2 dependencies of your project. As a brief overview of the code files: main.hpp and main.cpp : Contains the program entrypoint function and the core of the ros node. It contains all of the core functionality to fly a vehicle as well as the state machine. It includes the user controller specified in controller.hpp to be expected to run during the execution phase of the state machine. controller.hpp and controller.cpp : For the majority of simple applications, a user should only need to provide their own version of these files. The controller contains an initialisation and loop function which a user can fill in. state.hpp : A header only file containing the states of the state machine.","title":"cpp_ros2_node_onboard_template"},{"location":"creating/#python_ros2_node_offboard_template","text":"|-- package.xml |-- resource | `-- template_python_node |-- setup.cfg |-- setup.py |-- template_python_node | |-- __init__.py | `-- main.py `-- test |-- test_copyright.py |-- test_flake8.py `-- test_pep257.py This node runs offboard on the central server. It is designed to run on its own with no external dependency on anything outside of the application. package.xml : ROS2 Metadata file specifying ros2 dependencies of your project. resource : A Python ros package special folder, do not touch setup.cfg : Configuration file specifying where key resources are setup.py : The Python equivalent of CMakeLists.txt and contains the instructions to build this rosnode. It specifies which resources are copied over and available to the rosnode at runtime. Also specifies the name of the binary, and which function it is intended to run. By default this is controller <your rosnode name> e.g. template_python_node : The source directory for your python files. test : A number of testing utilities which can be run with pytest. Currently not used. A brief overview of code files: main.py : Contains a ros node which uses a timer to repeat poll the current state of vehicles on the network at given intervals. It then performs the calculation of ideal vehicle location and sends that to the vehicles.","title":"python_ros2_node_offboard_template"},{"location":"creating/#ros2_msgs_template","text":"|-- CMakeLists.txt |-- msg | |-- NotifyVehicles.msg | `-- TargetAngle.msg `-- package.xml This node is purely for specifying and building the custom ros messages in our application. Any application which uses these messages need a compiled version of this node. CMakeLists.txt : contains the instructions to build the messages. Any extra messages or services need to be added to the CMakeLists. msg : A list of specified custom messages. package.xml : ROS2 Metadata file specifying ros2 dependencies of your project.","title":"ros2_msgs_template"},{"location":"creating/#dockerfile","text":"As mentioned in the previous tutorial , a Dockerfile is used as a recipe to build your controller Docker container. The Dockerfile in this template contains the command line instructions to build your controller. By default, it will install a number of useful libraries for compatibility. If you need any new libraries, you will have to add their installation here! It then essentially copies in all of the rosnodes specified within the project name directory and runs them through the standard ROS2 build tool named colcon . It also copies over the run.sh file which the Dockerfile will run on container startup. Therefore the run.sh should have the instructions for running your applications. Thankfully, you do not need to run docker build automatically as we have set up a special build system which is wrapped up inside the Makefile .","title":"Dockerfile"},{"location":"creating/#running-your-new-project","text":"With your project now constructed, you can now re-run your container with the same make commands as earlier. cd <Your Application Name> # Go into the your new Starling application directory make run # Will build and run the container This will build a container called <Docker Username>/<Docker Image Name> with tag latest e.g. myname/starling_template:latest This will start the onboard controller by default, but it will start complaining that it hasn't received any state or position messages for initialisation. This is normal for now! If you want to start the offboard controller, you can add the extra option ENV=\"-e OFFBOARD=true\" to the make command like so make run ENV=\"-e OFFBOARD=true\" . It will then start trying to identify the number of vehicles on the network, but of course it cannot find any! You can have a look inside both containers using make run_bash .","title":"Running your new project"},{"location":"creating/#initialising-git","text":"Optionally, at this point you can set up version control on your project in order to save your progress. To initialise git and create your first commit, go to the root of your project and run: git init git add -A git commit -m \"Initial Commit\" If you want to push this code onto github, you can follow this tutorial . In short, create an empty Github repository of the same name in your Github account, and change the remote locally: git remote add origin <remote repository URL> git remote -v git push origin master","title":"Initialising Git"},{"location":"creating/#next-steps","text":"Congratulations, you now have your own Starling application! It doesn't have any functionality yet but before we get to adding some, it's important to understand how you run the simulation for you to test your controller against!","title":"Next Steps"},{"location":"docker/","text":"Docker and Containerisation \u00b6 This tutorial gives a brief introduction to a key element of Starling - containerisation. By the end you will hopefully have an idea of what containerisation is, what docker is, how to use it, and how we use it within Starling. This is adapted from the Duckietown Docker Docs , Docker Docs tutorial , and a number of other resources. Docker and Containerisation Introduction What is Containerisation and Docker Docker Concepts in more detail Starling Container Ecosystem Using Docker with Starling Getting and Running Containers Creating Containers Layer Caching Inspecting a container Starling Mavros Next Steps Introduction \u00b6 What is Containerisation and Docker \u00b6 It would be nice to give a computer - any computer with an internet connection - a short string of ASCII characters (say via a keyboard), press enter, and return to see some program running. Forget about where the program was built or what software you happened to be running at the time (this can be checked, and we can fetch the necessary dependencies). Sounds simple, right? In fact, this is an engineering task that has taken thousands of the world\u2019s brightest developers many decades to implement. Thanks to the magic of container technology we now can run any Linux program on almost any networked device on the planet, as is. All of the environment preparation, installation and configuration steps can be automated from start to finish. Depending on how much network bandwidth you have, it might take a while, but that\u2019s all right. All you need to do is type the string correctly. Docker is one very widely used example of containerisation technology, and the one we make use of in Starling. They provide a large number of tools and programs to help us contain, develop, test and deploy our containers to the real world. If you followed the getting started , you should hopefully have done the full docker install. If not, you can run the following command from a linux command line to install basic docker. curl -sSL https://get.docker.com/ | sh Docker Concepts in more detail \u00b6 Adapted from Docker Resources A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another. A Docker container image is a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings. Container images become containers at runtime and in the case of Docker containers \u2013 images become containers when they run on Docker Engine. Available for both Linux and Windows-based applications, containerized software will always run the same, regardless of the infrastructure. Containers isolate software from its environment and ensure that it works uniformly despite differences for instance between development and staging. Containers are Standard (can run anywhere), Lightweight (Share low level machine system and not the whole Operating System) and Secure (Each application is as isolated as possible). For us this also translates to providing Reproduceable and Reusable systems. On the left, Containers are an abstraction at the app layer that packages code and dependencies together. Multiple containers can run on the same machine and share the OS kernel with other containers, each running as isolated processes in user space. Containers take up less space than VMs (container images are typically tens of MBs in size), can handle more applications and require fewer VMs and Operating systems. On the right, Virtual machines (VMs) are an abstraction of physical hardware turning one server into many servers. The hypervisor allows multiple VMs to run on a single machine. Each VM includes a full copy of an operating system, the application, necessary binaries and libraries \u2013 taking up tens of GBs. VMs can also be slow to boot. Starling Container Ecosystem \u00b6 The purpose of Starling is to allow you to quickly and easily install and run a UAV simulation within a simulated environment, so that you can test your developed controllers against a semi-realistic scenario, to then test in the real world Therefore Starling is a set of pre-built programs/executables, some of which are pre-configured for the following: Running a Physics Simulation with Visualisation Running the Drone autopilot control software locally (a.k.a Software In The Loop or SITL) Running the interface between Mavlink and other protocols such as the Robot Operating System (ROS) And many others... These pre-built containers are all available in the StarlingUAS repository on github and on Docker Hub. Together these containers form a modular ecosystem of drone systems which can be composed together to develop software for real drones. Any controllers developed via the simulator can be directly ported to run on a real drone. Using Docker with Starling \u00b6 Getting and Running Containers \u00b6 Every docker container is registered to a developer or organisation. In Starling, our docker organisation is known as uobflightlabstarling . Within our organisation, we have a large number of Docker containers available. These Docker containers live inside container registries (such as DockerHub), which are servers that host Docker images. A Docker image is one particular version or snapshot of a container and is basically a filesystem snapshot - a single file that contains everything you need to run our container. You can manually fetch one of our core containers called starling-mavros from docker hub using: docker pull uobflightlabstarling/starling-mavros You can also try and pull one of our simulation containers: docker pull uobflightlabstarling/starling-sim-iris-px4-flightarena:latest This might take a few minutes to download depending on internet connection (some containers like the simulation can be quite big!). Once downloaded, to see a list of Docker images on your machine, run: docker images Every image has an image ID, a name and a tag REPOSITORY TAG IMAGE ID CREATED SIZE uobflightlabstarling/starling-sim-iris-px4-flightarena latest 62d7f96637cf 3 weeks ago 5.97GB uobflightlabstarling/starling-mavros latest b70812c16731 5 months ago 2.06GB To run a Docker container, type the repository name, like so: docker run uobflightlabstarling/starling-mavros # Or with the tag if you want to run a specific tag (version) of that container docker run uobflightlabstarling/starling-mavros:latest In another terminal, you can see what is currently running using docker ps : CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4fd1e0948f23 uobflightlabstarling/starling-mavros \"/ros_entrypoint.sh \u2026\" 46 seconds ago Up 45 seconds vigilant_nobel Note how your the running container has a container ID , a base image you ran, and at the end, a funny name vigilant_noble . This funny name is an alias for the container ID. To stop the container, simply press ctrl+c in the terminal which you ran docker run . As a second example, you can similarly try and run the simulator, this time also specifying a port mapping to let you see the simulator in your web-browser. docker run -p 8080:8080 uobflightlabstarling/starling-sim-iris-px4-flightarena Then you can navigate to localhost:8080 in your web browser to see the simulator. You should hopefully see something like the following: You can use the cursor to move around the environment, we will be coming back to the simulator in a later section . To stop the simulator, you can try and use ctrl+c , but sometimes this doenst work. Another way is to first get the container ID or name like before docker ps : CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6a4bd538118c uobflightlabstarling/starling-sim-iris-px4-flightarena \"/entrypoint.sh ros2\u2026\" 2 minutes ago Up 2 minutes 7681/tcp, 11345/tcp, 0.0.0.0:8080->8080/tcp trusting_diffie See how the name is trusting_diffie with ID 6a4bd538118c . You can then explicitly stop the container by running (it can sometimes take a minute). docker stop trusting_diffie # or docker stop 6a4bd538118c Dont forget to also remove the container afterwards docker rm trusting_diffie # or docker rm 6a4bd538118c Creating Containers \u00b6 To create a Docker image we write a recipe, called a Dockerfile . A Dockerfile is a text file that specifies the commands required to create a Docker image, typically by modifying an existing container image using a scripting interface. They also have special keywords (which are always CAPITALIZED), like FROM , RUN , ENTRYPOINT and so on. For example, create a file called Dockerfile with the following content: FROM ros:foxy # Defines the base image RUN touch new_file1 # new_file1 will be part of our snapshot CMD ls -l # Default command to be run when the container is started Now, to build the image we can simply run: docker build -t your/duck:v3 . # Where '.' is the directory containing your Dockerfile You should see something like: Sending build context to Docker daemon 2.048kB Step 1/3 : FROM uobflightlabstarling/starling-mavros --- ea2f90g8de9e Step 2/3 : RUN touch new_file1 --- e3b75gt9zyc4 Step 3/3 : CMD ls -l --- Running in 14f834yud59 Removing intermediate container 14f834yud59 --- 05a3bd381fc2 Successfully built 05a3bd381fc2 Successfully tagged your/duck:v3 Now run the command docker images in your terminal, and you should see an image called your/duck with tag v3: docker images REPOSITORY TAG IMAGE ID CREATED SIZE your/duck v3 ea2f90g8de9e 1 minute ago 2.06GB uobflightlabstarling/starling-sim-iris-px4-flightarena latest 62d7f96637cf 3 weeks ago 5.97GB uobflightlabstarling/starling-mavros latest b70812c16731 5 months ago 2.06GB This procedure is identical to the snapshot method we performed earlier, but the result is much cleaner. Now, instead of needing to carry around a 2.06GB BLOB, we can just store the 4KB text file and rest assured that all our important setup commands are contained within. Similar to before, we can simply run: docker run -it your/duck:v3 total 0 -rw-r--r-- 1 root root 0 May 21 21:35 new_file1 Notice that as soon as we run the container, Docker will execute the ls -l command as specified by the Dockerfile, revealing new_file1 was stored in the image. However we can still override ls -l by passing a command line argument: docker run -it your/duck:v3 [custom command] In the next tutorial, we will go into more detail in how these Dockerfiles are constructed for us. Layer Caching \u00b6 An important concept in Docker is the layers . In the previous section you may think that every time we build, we end up having to copy over the entire parent container. e.g. your/duck:v3 takes up another 2Gb of storage space! In actual fact, it (thankfully) does not, because under the hood the executable does not exist as one giant individible binary. It is in fact split into multiple independnet layers which can be shared in between images! Essentially each RUN line in your Dockerfile is compiled into a new layer placed upon the previous layers. This is helpful as if you try to build your container again, unless you change something, those previous layers are cached by Docker to be used instead of rebuilding the entire thing from scratch! Inspecting a container \u00b6 One of the downsides of containers is that manipulating files and inspecting their state is not as simple. Previously, you could just browser through your own file system and check things. Now that a container has its own file system, its not as clear how you could check things have been set up correctly, or test run commands manually or similar. There are a number of different ways, but the simplest way is to exec into a running container. As an example, you can run starling-mavros again in one terminal. docker run uobflightlabstarling/starling-mavros In another terminal, identify the container ID or name by using docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 81b7dfb6c443 uobflightlabstarling/starling-mavros \"/ros_entrypoint.sh \u2026\" 3 seconds ago Up 2 seconds angry_yalow Note: The IDs have changed from the previous time we ran this container. Sometimes you want containers to persist, or do not want to delete them for testing and such. We can then use the ID of 81b7dfb6c443 or its name angry_yalow to exec into a container to run a command: docker exec -it angry_yalow [command] For example, in most cases it will be most useful to open up a bash terminal to inspect contents: docker exec -it angry_yalow bash root@81b7dfb6c443:/ros_ws# This opens up a terminal inside the container for you to navigate around and inspect things as you wish, in a similar manner to if you SSH'd into another machine. Note: Use the cat command to view the contents of files. Note: These containers have almost no tools to keep them slim. If you want to edit things, you will need to download a command line file editor. Run apt-get update then install an editor like nano with apt-get install nano . Starling Mavros \u00b6 Finally, we bring in ros2 and uav control from the previous tutorial . In Starling, there exists a core container called starling-mavros which facilitates the communication between the user application and the UAV autopilot in simulation or reality. This container, which you have hopefully run above, uses a Mavros node to translate between ROS2 for the user, and MAVLINK for the autopilot. We give examples of its use later on. Next Steps \u00b6 Hopefully you now have a decent understanding of what containerisation is and its purpose within Starling. You have also had a go at using the Docker command line tool to pull, run, build and inspect Starling containers going forward. With all that, we are now at a point where you can start creating your own containers to use!","title":"3. Docker and Containerisation"},{"location":"docker/#docker-and-containerisation","text":"This tutorial gives a brief introduction to a key element of Starling - containerisation. By the end you will hopefully have an idea of what containerisation is, what docker is, how to use it, and how we use it within Starling. This is adapted from the Duckietown Docker Docs , Docker Docs tutorial , and a number of other resources. Docker and Containerisation Introduction What is Containerisation and Docker Docker Concepts in more detail Starling Container Ecosystem Using Docker with Starling Getting and Running Containers Creating Containers Layer Caching Inspecting a container Starling Mavros Next Steps","title":"Docker and Containerisation"},{"location":"docker/#introduction","text":"","title":"Introduction"},{"location":"docker/#what-is-containerisation-and-docker","text":"It would be nice to give a computer - any computer with an internet connection - a short string of ASCII characters (say via a keyboard), press enter, and return to see some program running. Forget about where the program was built or what software you happened to be running at the time (this can be checked, and we can fetch the necessary dependencies). Sounds simple, right? In fact, this is an engineering task that has taken thousands of the world\u2019s brightest developers many decades to implement. Thanks to the magic of container technology we now can run any Linux program on almost any networked device on the planet, as is. All of the environment preparation, installation and configuration steps can be automated from start to finish. Depending on how much network bandwidth you have, it might take a while, but that\u2019s all right. All you need to do is type the string correctly. Docker is one very widely used example of containerisation technology, and the one we make use of in Starling. They provide a large number of tools and programs to help us contain, develop, test and deploy our containers to the real world. If you followed the getting started , you should hopefully have done the full docker install. If not, you can run the following command from a linux command line to install basic docker. curl -sSL https://get.docker.com/ | sh","title":"What is Containerisation and Docker"},{"location":"docker/#docker-concepts-in-more-detail","text":"Adapted from Docker Resources A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another. A Docker container image is a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings. Container images become containers at runtime and in the case of Docker containers \u2013 images become containers when they run on Docker Engine. Available for both Linux and Windows-based applications, containerized software will always run the same, regardless of the infrastructure. Containers isolate software from its environment and ensure that it works uniformly despite differences for instance between development and staging. Containers are Standard (can run anywhere), Lightweight (Share low level machine system and not the whole Operating System) and Secure (Each application is as isolated as possible). For us this also translates to providing Reproduceable and Reusable systems. On the left, Containers are an abstraction at the app layer that packages code and dependencies together. Multiple containers can run on the same machine and share the OS kernel with other containers, each running as isolated processes in user space. Containers take up less space than VMs (container images are typically tens of MBs in size), can handle more applications and require fewer VMs and Operating systems. On the right, Virtual machines (VMs) are an abstraction of physical hardware turning one server into many servers. The hypervisor allows multiple VMs to run on a single machine. Each VM includes a full copy of an operating system, the application, necessary binaries and libraries \u2013 taking up tens of GBs. VMs can also be slow to boot.","title":"Docker Concepts in more detail"},{"location":"docker/#starling-container-ecosystem","text":"The purpose of Starling is to allow you to quickly and easily install and run a UAV simulation within a simulated environment, so that you can test your developed controllers against a semi-realistic scenario, to then test in the real world Therefore Starling is a set of pre-built programs/executables, some of which are pre-configured for the following: Running a Physics Simulation with Visualisation Running the Drone autopilot control software locally (a.k.a Software In The Loop or SITL) Running the interface between Mavlink and other protocols such as the Robot Operating System (ROS) And many others... These pre-built containers are all available in the StarlingUAS repository on github and on Docker Hub. Together these containers form a modular ecosystem of drone systems which can be composed together to develop software for real drones. Any controllers developed via the simulator can be directly ported to run on a real drone.","title":"Starling Container Ecosystem"},{"location":"docker/#using-docker-with-starling","text":"","title":"Using Docker with Starling"},{"location":"docker/#getting-and-running-containers","text":"Every docker container is registered to a developer or organisation. In Starling, our docker organisation is known as uobflightlabstarling . Within our organisation, we have a large number of Docker containers available. These Docker containers live inside container registries (such as DockerHub), which are servers that host Docker images. A Docker image is one particular version or snapshot of a container and is basically a filesystem snapshot - a single file that contains everything you need to run our container. You can manually fetch one of our core containers called starling-mavros from docker hub using: docker pull uobflightlabstarling/starling-mavros You can also try and pull one of our simulation containers: docker pull uobflightlabstarling/starling-sim-iris-px4-flightarena:latest This might take a few minutes to download depending on internet connection (some containers like the simulation can be quite big!). Once downloaded, to see a list of Docker images on your machine, run: docker images Every image has an image ID, a name and a tag REPOSITORY TAG IMAGE ID CREATED SIZE uobflightlabstarling/starling-sim-iris-px4-flightarena latest 62d7f96637cf 3 weeks ago 5.97GB uobflightlabstarling/starling-mavros latest b70812c16731 5 months ago 2.06GB To run a Docker container, type the repository name, like so: docker run uobflightlabstarling/starling-mavros # Or with the tag if you want to run a specific tag (version) of that container docker run uobflightlabstarling/starling-mavros:latest In another terminal, you can see what is currently running using docker ps : CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4fd1e0948f23 uobflightlabstarling/starling-mavros \"/ros_entrypoint.sh \u2026\" 46 seconds ago Up 45 seconds vigilant_nobel Note how your the running container has a container ID , a base image you ran, and at the end, a funny name vigilant_noble . This funny name is an alias for the container ID. To stop the container, simply press ctrl+c in the terminal which you ran docker run . As a second example, you can similarly try and run the simulator, this time also specifying a port mapping to let you see the simulator in your web-browser. docker run -p 8080:8080 uobflightlabstarling/starling-sim-iris-px4-flightarena Then you can navigate to localhost:8080 in your web browser to see the simulator. You should hopefully see something like the following: You can use the cursor to move around the environment, we will be coming back to the simulator in a later section . To stop the simulator, you can try and use ctrl+c , but sometimes this doenst work. Another way is to first get the container ID or name like before docker ps : CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6a4bd538118c uobflightlabstarling/starling-sim-iris-px4-flightarena \"/entrypoint.sh ros2\u2026\" 2 minutes ago Up 2 minutes 7681/tcp, 11345/tcp, 0.0.0.0:8080->8080/tcp trusting_diffie See how the name is trusting_diffie with ID 6a4bd538118c . You can then explicitly stop the container by running (it can sometimes take a minute). docker stop trusting_diffie # or docker stop 6a4bd538118c Dont forget to also remove the container afterwards docker rm trusting_diffie # or docker rm 6a4bd538118c","title":"Getting and Running Containers"},{"location":"docker/#creating-containers","text":"To create a Docker image we write a recipe, called a Dockerfile . A Dockerfile is a text file that specifies the commands required to create a Docker image, typically by modifying an existing container image using a scripting interface. They also have special keywords (which are always CAPITALIZED), like FROM , RUN , ENTRYPOINT and so on. For example, create a file called Dockerfile with the following content: FROM ros:foxy # Defines the base image RUN touch new_file1 # new_file1 will be part of our snapshot CMD ls -l # Default command to be run when the container is started Now, to build the image we can simply run: docker build -t your/duck:v3 . # Where '.' is the directory containing your Dockerfile You should see something like: Sending build context to Docker daemon 2.048kB Step 1/3 : FROM uobflightlabstarling/starling-mavros --- ea2f90g8de9e Step 2/3 : RUN touch new_file1 --- e3b75gt9zyc4 Step 3/3 : CMD ls -l --- Running in 14f834yud59 Removing intermediate container 14f834yud59 --- 05a3bd381fc2 Successfully built 05a3bd381fc2 Successfully tagged your/duck:v3 Now run the command docker images in your terminal, and you should see an image called your/duck with tag v3: docker images REPOSITORY TAG IMAGE ID CREATED SIZE your/duck v3 ea2f90g8de9e 1 minute ago 2.06GB uobflightlabstarling/starling-sim-iris-px4-flightarena latest 62d7f96637cf 3 weeks ago 5.97GB uobflightlabstarling/starling-mavros latest b70812c16731 5 months ago 2.06GB This procedure is identical to the snapshot method we performed earlier, but the result is much cleaner. Now, instead of needing to carry around a 2.06GB BLOB, we can just store the 4KB text file and rest assured that all our important setup commands are contained within. Similar to before, we can simply run: docker run -it your/duck:v3 total 0 -rw-r--r-- 1 root root 0 May 21 21:35 new_file1 Notice that as soon as we run the container, Docker will execute the ls -l command as specified by the Dockerfile, revealing new_file1 was stored in the image. However we can still override ls -l by passing a command line argument: docker run -it your/duck:v3 [custom command] In the next tutorial, we will go into more detail in how these Dockerfiles are constructed for us.","title":"Creating Containers"},{"location":"docker/#layer-caching","text":"An important concept in Docker is the layers . In the previous section you may think that every time we build, we end up having to copy over the entire parent container. e.g. your/duck:v3 takes up another 2Gb of storage space! In actual fact, it (thankfully) does not, because under the hood the executable does not exist as one giant individible binary. It is in fact split into multiple independnet layers which can be shared in between images! Essentially each RUN line in your Dockerfile is compiled into a new layer placed upon the previous layers. This is helpful as if you try to build your container again, unless you change something, those previous layers are cached by Docker to be used instead of rebuilding the entire thing from scratch!","title":"Layer Caching"},{"location":"docker/#inspecting-a-container","text":"One of the downsides of containers is that manipulating files and inspecting their state is not as simple. Previously, you could just browser through your own file system and check things. Now that a container has its own file system, its not as clear how you could check things have been set up correctly, or test run commands manually or similar. There are a number of different ways, but the simplest way is to exec into a running container. As an example, you can run starling-mavros again in one terminal. docker run uobflightlabstarling/starling-mavros In another terminal, identify the container ID or name by using docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 81b7dfb6c443 uobflightlabstarling/starling-mavros \"/ros_entrypoint.sh \u2026\" 3 seconds ago Up 2 seconds angry_yalow Note: The IDs have changed from the previous time we ran this container. Sometimes you want containers to persist, or do not want to delete them for testing and such. We can then use the ID of 81b7dfb6c443 or its name angry_yalow to exec into a container to run a command: docker exec -it angry_yalow [command] For example, in most cases it will be most useful to open up a bash terminal to inspect contents: docker exec -it angry_yalow bash root@81b7dfb6c443:/ros_ws# This opens up a terminal inside the container for you to navigate around and inspect things as you wish, in a similar manner to if you SSH'd into another machine. Note: Use the cat command to view the contents of files. Note: These containers have almost no tools to keep them slim. If you want to edit things, you will need to download a command line file editor. Run apt-get update then install an editor like nano with apt-get install nano .","title":"Inspecting a container"},{"location":"docker/#starling-mavros","text":"Finally, we bring in ros2 and uav control from the previous tutorial . In Starling, there exists a core container called starling-mavros which facilitates the communication between the user application and the UAV autopilot in simulation or reality. This container, which you have hopefully run above, uses a Mavros node to translate between ROS2 for the user, and MAVLINK for the autopilot. We give examples of its use later on.","title":"Starling Mavros"},{"location":"docker/#next-steps","text":"Hopefully you now have a decent understanding of what containerisation is and its purpose within Starling. You have also had a go at using the Docker command line tool to pull, run, build and inspect Starling containers going forward. With all that, we are now at a point where you can start creating your own containers to use!","title":"Next Steps"},{"location":"getting_started/","text":"Getting Started \u00b6 This first tutorial takes you through setting up your machine to be able to run Starling in order to follow the rest of the tutorial. Getting Started Preamble Prerequisites Git and Docker Murmuration - Starling Command Line Interface Cookiecutter Useful Programs Next Steps Preamble \u00b6 For this tutorial, it will be assumed that you have a functional understanding of the Linux, Mac or Windows interface. This includes use of the command line and terminal applications on linux or Mac, and powershell or Windows Subsystem for Linux (WSL) on windows. If you do not feel comfortable with either of these, it is recommended you have a read of this tutorial first, which covers some of the set up shown here in much more detail. Prerequisites \u00b6 Git and Docker \u00b6 You will need to install git to access the software and Docker to run it. These are both supported on Windows, Mac and Linux. The Docker Desktop application should also be suitable. Linux users, please verify that the docker-compose tool is installed by running docker-compose --version . If it fails, install using sudo apt-get install docker-compose-plugin . see here . Windows users, it is highly recommended that you also install the Windows Subsystem for Linux (WSL) and use that as the backend for your Docker installations. see here for instructions It is also recommended that you sign up for a Github account and a Docker Hub account. Murmuration - Starling Command Line Interface \u00b6 You will need to download the Murmuration repository which contains a useful command line interface (cli). This will hopefully abstract away the need to remember all of the different commands. To install, first go to your work directory. Then run the following to clone the repository and go to the Murmuration directory git clone https://github.com/StarlingUAS/Murmuration.git # clones locally cd Murmuration In the bin directory of the repository, there is the core CLI script named starling . starling includes a further installation script to help install further requirements. This installation script will need to be run using root. Run: sudo starling install # or if you have not added starling to path and are in the Murmuration directory. sudo ./bin/starling install If running within Murmuration, swap starling for ./bin/starling . However for convenience, you may want to create a PATH variable for starling so you can run starling from anywhere. Do this by adding the line export PATH=<Path to murmuration>/bin:$PATH to your ~/.bashrc file. This lets bash know where to find the executable for starling . Run source ~/.bashrc to refresh your current bash environment and load this new variable. You will now have available the Starling CLI. It incorporates the most used functions of running Starling UAV systems. You can see the available commands by running: > starling help starling Starling CLI Usage: starling [command] Commands: deploy Starts Starling Server install Installs Base Starling Dependencies simulator Starts Starling Server start Starts Starling Server status Starts Starling Server stop Stops Starling Server utils Utility functions * Help Cookiecutter \u00b6 Prerequisites: You need to have installed Python. The template generation uses the cookiecutter tool for generating custom projects from a template. Then to install cookiecutter, run the following: python3 -m pip install --user cookiecutter # or easy_install --user cookiecutter See cookiecutter installation for further details on different platforms. This will give you access to the cookiecutter command line interface. Useful Programs \u00b6 We highly recommend Visual Studio Code as your editing environment as it has a number of nice features, extensions and allows easy access to terminal windows. Once installed, you can open VS Code on any directory via the terminal by running code <my directory> , or code . if you are already in the directory. Next Steps \u00b6 This should give you all the tools to be able to run the tutorials. Next, we'll be introducing you to the core technologies of Starling. This will give you enough background to start creating your own controllers!","title":"1. Getting Started "},{"location":"getting_started/#getting-started","text":"This first tutorial takes you through setting up your machine to be able to run Starling in order to follow the rest of the tutorial. Getting Started Preamble Prerequisites Git and Docker Murmuration - Starling Command Line Interface Cookiecutter Useful Programs Next Steps","title":"Getting Started"},{"location":"getting_started/#preamble","text":"For this tutorial, it will be assumed that you have a functional understanding of the Linux, Mac or Windows interface. This includes use of the command line and terminal applications on linux or Mac, and powershell or Windows Subsystem for Linux (WSL) on windows. If you do not feel comfortable with either of these, it is recommended you have a read of this tutorial first, which covers some of the set up shown here in much more detail.","title":"Preamble"},{"location":"getting_started/#prerequisites","text":"","title":"Prerequisites"},{"location":"getting_started/#git-and-docker","text":"You will need to install git to access the software and Docker to run it. These are both supported on Windows, Mac and Linux. The Docker Desktop application should also be suitable. Linux users, please verify that the docker-compose tool is installed by running docker-compose --version . If it fails, install using sudo apt-get install docker-compose-plugin . see here . Windows users, it is highly recommended that you also install the Windows Subsystem for Linux (WSL) and use that as the backend for your Docker installations. see here for instructions It is also recommended that you sign up for a Github account and a Docker Hub account.","title":"Git and Docker"},{"location":"getting_started/#murmuration-starling-command-line-interface","text":"You will need to download the Murmuration repository which contains a useful command line interface (cli). This will hopefully abstract away the need to remember all of the different commands. To install, first go to your work directory. Then run the following to clone the repository and go to the Murmuration directory git clone https://github.com/StarlingUAS/Murmuration.git # clones locally cd Murmuration In the bin directory of the repository, there is the core CLI script named starling . starling includes a further installation script to help install further requirements. This installation script will need to be run using root. Run: sudo starling install # or if you have not added starling to path and are in the Murmuration directory. sudo ./bin/starling install If running within Murmuration, swap starling for ./bin/starling . However for convenience, you may want to create a PATH variable for starling so you can run starling from anywhere. Do this by adding the line export PATH=<Path to murmuration>/bin:$PATH to your ~/.bashrc file. This lets bash know where to find the executable for starling . Run source ~/.bashrc to refresh your current bash environment and load this new variable. You will now have available the Starling CLI. It incorporates the most used functions of running Starling UAV systems. You can see the available commands by running: > starling help starling Starling CLI Usage: starling [command] Commands: deploy Starts Starling Server install Installs Base Starling Dependencies simulator Starts Starling Server start Starts Starling Server status Starts Starling Server stop Stops Starling Server utils Utility functions * Help","title":"Murmuration - Starling Command Line Interface"},{"location":"getting_started/#cookiecutter","text":"Prerequisites: You need to have installed Python. The template generation uses the cookiecutter tool for generating custom projects from a template. Then to install cookiecutter, run the following: python3 -m pip install --user cookiecutter # or easy_install --user cookiecutter See cookiecutter installation for further details on different platforms. This will give you access to the cookiecutter command line interface.","title":"Cookiecutter"},{"location":"getting_started/#useful-programs","text":"We highly recommend Visual Studio Code as your editing environment as it has a number of nice features, extensions and allows easy access to terminal windows. Once installed, you can open VS Code on any directory via the terminal by running code <my directory> , or code . if you are already in the directory.","title":"Useful Programs"},{"location":"getting_started/#next-steps","text":"This should give you all the tools to be able to run the tutorials. Next, we'll be introducing you to the core technologies of Starling. This will give you enough background to start creating your own controllers!","title":"Next Steps"},{"location":"multiuav_kubernetes/","text":"Multi-UAV flight with Kubernetes for container deployment \u00b6 In this tutorial, we will introduce the idea of container deployment and why that fits into the goals of what Starling is trying to achieve. We will then show how to run the multi-drone cluster simulation environment for multi-drone local development and testing. Now, I know what you might not be thinking at this point- \"Oh yay, another layer of complexity to learn... grumble grumble\" - but hold up! Container development is key to what sets Starling apart from other frameworks so it is important for you to understand how this works. Multi-UAV flight with Kubernetes for container deployment Kubernetes, Multi-UAV Flight and Integration Testing Multi-UAV Flight Container Orchestration and Kubernetes Integration Testing with KinD Running the Multi-UAV Integration Testing Stack Installing KinD Running the Multi-Drone Cluster Monitoring the cluster Restarting on Stopping the Simulator Next Steps Kubernetes, Multi-UAV Flight and Integration Testing \u00b6 It certainly is possible to conduct multi-UAV simulation testing with the Docker and Docker-Compose tools we already have (in fact we have a number here ), but this runs into a problem: how do we transition from running our developed controller against a simulation, to developing, validating and testing a controller which will be deployed on real hardware? Quick answer - we use container deployment to provide us not only with a physical representation of the BRL, but also a full software simulation of the systems we use in the BRL. Multi-UAV Flight \u00b6 A major problem with multi-UAV flight is scalability. Traditionally in drone applications, single vehicles are often flown by wire using a telemetry link from a ground computer or companion computer. This involved the manual configuration of networks and ports between different parts, as well as the manual loading of software onto the drones. On top of pinning the drone hardware to a particular application, repeating this process for multiple drones is both tedious and inefficient. If vehicles could automatically set up their own environment, networking and ports, and accept software deployments, we could mitigate many of the above problems. That's where Starling comes in! This whole approach is drawn from the observation that a modern drone is simply flying compute, and therefore a group of drones are analogous to a computation cluster. Compute clusters also have to deal with networking, software deployment, scalability and so on - and they have tools and systems to do this. In Starling, we apply similar tools to aid us in Multi-UAV flight. Container Orchestration and Kubernetes \u00b6 In a compute cluster, we often want to deploy our applications (preferably containerised) and run them on a specific dedicated machine. This could be because the application needs a GPU, or requires lots of storage or perhaps it doesnt need any of those and just need CPU time. Regardless, the container orchestrator is the one in charge of ensuring that applications are deployed to where they need to be. In Starling, we make use of the popular Kubernetes open source orchestrator. It is Kubernetes (aka K8) job to deploy one or more groups of containers (a.k.a Pods ) to one or more drones (a.k.a compute Nodes ) within its cluster. Through doing this, it also manages the inter-vehicle network, scaling to more vehicles, vehicle failure and recovery, automatic connection on startup and many other features. The below diagram shows this in action with the deployment of multiple containers on different vehicles, as well as other containers on the main cluster server machine offboard the vehicles. By default we have the following deployment 'rules' in place: Every 'vehicle' has the MAVROS container deployed to it. Every 'clover' (a type of UAV we are using) has the Clover Hardware Container deployed to it. Every 'multirotor' has the User's onboard controller deployed to it. The offboard, GUI and safety monitor are restricted to only be deployed on the 'master' node. These deployment rules are applied through the use of Kubernetes configuration files which we will detail in the next tutorial. There exists a well known NASA Mantra of `Test Like You Fly' . Therefore we have good reason to not just use Docker-Compose for all our testing: Docker-Compose is designed for running containers locally on one machine and has no capability for deployment, so it cannot be used on real vehicles. Kubernetes adds an extra layer of complexity which needs to be tested before deploying into the real world. Integration Testing with KinD \u00b6 Wrapping back round to testing your own controllers... how can we do reasonable integration testing if we need a compute cluster with multiple nodes? This is where containerisation comes back to the rescue! Specifically, we use the Kubernetes in Docker (KinD) to do ... Docker inside Docker testing! Recall that a container simply encapsulates other programs. There is nothing stopping you from running more containers inside the existing container. KinD leverages this by spinning up a container for each simulated node in your cluster. These nodes are automatically connected together as if they were a compute cluster on real hardware. KinD therefore has two types of container: a control plane and a worker. The control plane is the K8 server, and the workers are the nodes. Starling wraps KinD with automatic functionality which labels workers as UAVs, allowing existing deployments to function identically to the real world. The only addition is that in place of the real world, we have our Gazebo digital double simulator instead. Crucially, the user interface between K8s on KinD is identical to that on the real vehicles. This means you can easily run deployments and networking as if you were in the real world. Voila! Integration testing! Running the Multi-UAV Integration Testing Stack \u00b6 Prerequisites: Getting Started Installing KinD \u00b6 If you have got this far, you will also need to install the kind utility. This can be done through the starling CLI: starling install kind Running the Multi-Drone Cluster \u00b6 Start a cluster of 2 drones by running the following: starling start kind -n 2 Once the cluster has started, we can start the general UAV simulator. IMPORTANT : The simulator can potentially be resource heavy to run, w.r.t both CPU usage and RAM. Before going further, please ensure you have enough space on your primary drive (at least 30Gb to be safe - check your C drive on Windows). This is especially important if running multiple vehicles. We do not recommend you run more than 6 vehicles at a time. IMPORTANT : On windows machines running WSL2, it has been noted that machines with 16GB RAM can potentially slow down or run out of memory. This is due to WSL2 taking up slightly too much memory. It is recommended that you reduce the amount of memory from 8Gb to 6 or 7Gb. In particular by modifying your .wslconfig file. See this guide First, we should load or download the required simulation containers locally. We need to run the load command as we want to load the local container images into the KinD container. This saves the KinD containers from having to download the containers themselves during runtime. This is achieved by starting a local container registry (just like Docker Hub), loading our containers into there, and getting the KinD containers to look there first when looking for containers. This command can take as long as 30 minutes depending on your internet connection. It goes through the deployment files and downloads a couple of large containers e.g. the gazebo and sitl containers. If the container doesn't already exist locally, it will attempt to download it from Docker Hub Note: The --brl option automatically loads up the BRL flight arena simulated doubles starling simulator load --brl Once loading completes, you can then start the simulator using the start command: starling simulator start --brl # or both load and start at once starling simulator start --brl --load This should print the following output: Starting simulator Converting to use local registry at localhost:5001 deployment.apps/gazebo-v1 created Converting to use local registry at localhost:5001 daemonset.apps/starling-px4-sitl-daemon created Converting to use local registry at localhost:5001 daemonset.apps/starling-mavros-daemon created With any luck, this should again open up the simulator on localhost:8080 (the page will be empty as the UI has not been started though). Monitoring the cluster \u00b6 A dashboard can be started to monitor the state of your current cluster. starling start dashboard This will start up the Kubernetes dashboard . To access the dashboard, open up a browser and go to http://localhost:31771. Note the browser may grumble about the security but it is safe to access! Please click 'Advanced Options' and 'Continue to website' to proceed. The above command should show something like the following: The Dashboard is available at https://localhost:31771 You will need the dashboard token, to access it. Copy and paste the token from below -----BEGIN DASHBOARD TOKEN----- <LONG TOKEN> -----END DASHBOARD TOKEN----- Note: your browser may not like the self signed ssl certificate, ignore and continue for now To get the token yourself run: kubectl -n kubernetes-dashboard describe secret admin-user-token You will need the <LONG TOKEN> to log in. Copy and paste it into the Dashboard token. To get the access token again, run: starling utils get-dashboard-token For a more specific tutorial on the dashboard go to this page in the starling docs ! This web dashboard shows the status of everything in the simulated cluster. It may look overwhelming, but in this tutorial, you'll only need to interact with a few of the elements. Opening the dashboard takes you firstly to the Workloads page. This gives you an overview of everything that is running. If it's green, you're all good! You can see the nodes in the cluster by scrolling down on the left sidebar and clicking Nodes . Here we see the server (control plane) and 2 drones (workers). On the right sidebar the pods button brings you to a list of all the groups of containers (pods) currently running on the cluster. We can see 1 Gazebo pod, 2 px4 and 2 mavros, representing two drones and a simulator. Finally, you can click on any one of the pods to access that container's logs, as well as exec into them if you want to run stuff. Navigate and have a look at the running pods. See if you recognise some of the printouts from when you just ran docker-compose . Note: The dashboard is definitely overspecified for our needs, but it already existed and was a good resource. We have a upcoming project to building a similar, more customised replacement which better suits our needs. Finally, for very quick diagnostics, you can also monitor the system using: $ starling status # or to continually watch $ starling status --watch Number of vehicles: 2 Nodes: NAME STATUS ROLES AGE VERSION starling-cluster-control-plane Ready control-plane,master 38m v1.21.1 starling-cluster-worker Ready <none> 38m v1.21.1 starling-cluster-worker2 Ready <none> 38m v1.21.1 Pods: NAME READY STATUS RESTARTS AGE gazebo-v1-59d58485d8-pnt2g 1/1 Running 0 25m starling-mavros-daemon-cqjhr 1/1 Running 0 25m starling-mavros-daemon-nmptj 1/1 Running 0 25m starling-px4-sitl-daemon-fllq5 1/1 Running 0 25m starling-px4-sitl-daemon-gfxqs 1/1 Running 0 25m Deployments: NAME READY UP-TO-DATE AVAILABLE AGE gazebo-v1 1/1 1 1 25m StatefulSets: No resources found in default namespace. DaemonSets NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE starling-mavros-daemon 2 2 2 2 2 starling.dev/type=vehicle 25m starling-px4-sitl-daemon 2 2 2 2 2 starling.dev/type=vehicle 25m Restarting on Stopping the Simulator \u00b6 To recap, there are two parts to our Starling integration test simulator. There is the cluster, and then there is our UAV simulation running within the cluster. If the UAV simulation seems broken or you have put it in an unrecoverable state, you can restart the UAV simulation without deleting the cluster by running the restart command on the simulator: starling simulator restart --brl Note: This will stop the simulator by deleting all deployments within the cluster, and then restart. You can remove all deployments using starling simulator stop . Note: Don't forget to include the --brl so it knows what to start up again. If you have finished testing for the day, something fundamental to the cluster has gone wrong (e.g. failed to connect to ports, networking etc), or you wish to change the number of drones in your cluster, you can stop and delete the cluster and everything in it by running: starling stop kind Note: This will remove all of the loaded internal images again, so you will need to load them in next time you start the cluster (alternatively, you can keep them by adding the argument --keep_registry ). Note: You will have to start everything up again after restarting - the dashboard, loading images, starting the brl simulator. Next Steps \u00b6 Good job on getting to the end! This is one of the denser sections in this tutorial. Hopefully you now have a basic understanding on why Starling goes to the complexity of using Kubernetes and the benefits it can bring. In addition, you have learnt what KinD is, and why and how we use it in conjunction with the Starling CLI for integration testing. Now you know how the integration test stack can be run, it's time to get your controllers in and see how they work with multiple vehicles!","title":"8. Multi-UAV flight with Kubernetes for container deployment"},{"location":"multiuav_kubernetes/#multi-uav-flight-with-kubernetes-for-container-deployment","text":"In this tutorial, we will introduce the idea of container deployment and why that fits into the goals of what Starling is trying to achieve. We will then show how to run the multi-drone cluster simulation environment for multi-drone local development and testing. Now, I know what you might not be thinking at this point- \"Oh yay, another layer of complexity to learn... grumble grumble\" - but hold up! Container development is key to what sets Starling apart from other frameworks so it is important for you to understand how this works. Multi-UAV flight with Kubernetes for container deployment Kubernetes, Multi-UAV Flight and Integration Testing Multi-UAV Flight Container Orchestration and Kubernetes Integration Testing with KinD Running the Multi-UAV Integration Testing Stack Installing KinD Running the Multi-Drone Cluster Monitoring the cluster Restarting on Stopping the Simulator Next Steps","title":"Multi-UAV flight with Kubernetes for container deployment"},{"location":"multiuav_kubernetes/#kubernetes-multi-uav-flight-and-integration-testing","text":"It certainly is possible to conduct multi-UAV simulation testing with the Docker and Docker-Compose tools we already have (in fact we have a number here ), but this runs into a problem: how do we transition from running our developed controller against a simulation, to developing, validating and testing a controller which will be deployed on real hardware? Quick answer - we use container deployment to provide us not only with a physical representation of the BRL, but also a full software simulation of the systems we use in the BRL.","title":"Kubernetes, Multi-UAV Flight and Integration Testing"},{"location":"multiuav_kubernetes/#multi-uav-flight","text":"A major problem with multi-UAV flight is scalability. Traditionally in drone applications, single vehicles are often flown by wire using a telemetry link from a ground computer or companion computer. This involved the manual configuration of networks and ports between different parts, as well as the manual loading of software onto the drones. On top of pinning the drone hardware to a particular application, repeating this process for multiple drones is both tedious and inefficient. If vehicles could automatically set up their own environment, networking and ports, and accept software deployments, we could mitigate many of the above problems. That's where Starling comes in! This whole approach is drawn from the observation that a modern drone is simply flying compute, and therefore a group of drones are analogous to a computation cluster. Compute clusters also have to deal with networking, software deployment, scalability and so on - and they have tools and systems to do this. In Starling, we apply similar tools to aid us in Multi-UAV flight.","title":"Multi-UAV Flight"},{"location":"multiuav_kubernetes/#container-orchestration-and-kubernetes","text":"In a compute cluster, we often want to deploy our applications (preferably containerised) and run them on a specific dedicated machine. This could be because the application needs a GPU, or requires lots of storage or perhaps it doesnt need any of those and just need CPU time. Regardless, the container orchestrator is the one in charge of ensuring that applications are deployed to where they need to be. In Starling, we make use of the popular Kubernetes open source orchestrator. It is Kubernetes (aka K8) job to deploy one or more groups of containers (a.k.a Pods ) to one or more drones (a.k.a compute Nodes ) within its cluster. Through doing this, it also manages the inter-vehicle network, scaling to more vehicles, vehicle failure and recovery, automatic connection on startup and many other features. The below diagram shows this in action with the deployment of multiple containers on different vehicles, as well as other containers on the main cluster server machine offboard the vehicles. By default we have the following deployment 'rules' in place: Every 'vehicle' has the MAVROS container deployed to it. Every 'clover' (a type of UAV we are using) has the Clover Hardware Container deployed to it. Every 'multirotor' has the User's onboard controller deployed to it. The offboard, GUI and safety monitor are restricted to only be deployed on the 'master' node. These deployment rules are applied through the use of Kubernetes configuration files which we will detail in the next tutorial. There exists a well known NASA Mantra of `Test Like You Fly' . Therefore we have good reason to not just use Docker-Compose for all our testing: Docker-Compose is designed for running containers locally on one machine and has no capability for deployment, so it cannot be used on real vehicles. Kubernetes adds an extra layer of complexity which needs to be tested before deploying into the real world.","title":"Container Orchestration and Kubernetes"},{"location":"multiuav_kubernetes/#integration-testing-with-kind","text":"Wrapping back round to testing your own controllers... how can we do reasonable integration testing if we need a compute cluster with multiple nodes? This is where containerisation comes back to the rescue! Specifically, we use the Kubernetes in Docker (KinD) to do ... Docker inside Docker testing! Recall that a container simply encapsulates other programs. There is nothing stopping you from running more containers inside the existing container. KinD leverages this by spinning up a container for each simulated node in your cluster. These nodes are automatically connected together as if they were a compute cluster on real hardware. KinD therefore has two types of container: a control plane and a worker. The control plane is the K8 server, and the workers are the nodes. Starling wraps KinD with automatic functionality which labels workers as UAVs, allowing existing deployments to function identically to the real world. The only addition is that in place of the real world, we have our Gazebo digital double simulator instead. Crucially, the user interface between K8s on KinD is identical to that on the real vehicles. This means you can easily run deployments and networking as if you were in the real world. Voila! Integration testing!","title":"Integration Testing with KinD"},{"location":"multiuav_kubernetes/#running-the-multi-uav-integration-testing-stack","text":"Prerequisites: Getting Started","title":"Running the Multi-UAV Integration Testing Stack"},{"location":"multiuav_kubernetes/#installing-kind","text":"If you have got this far, you will also need to install the kind utility. This can be done through the starling CLI: starling install kind","title":"Installing KinD"},{"location":"multiuav_kubernetes/#running-the-multi-drone-cluster","text":"Start a cluster of 2 drones by running the following: starling start kind -n 2 Once the cluster has started, we can start the general UAV simulator. IMPORTANT : The simulator can potentially be resource heavy to run, w.r.t both CPU usage and RAM. Before going further, please ensure you have enough space on your primary drive (at least 30Gb to be safe - check your C drive on Windows). This is especially important if running multiple vehicles. We do not recommend you run more than 6 vehicles at a time. IMPORTANT : On windows machines running WSL2, it has been noted that machines with 16GB RAM can potentially slow down or run out of memory. This is due to WSL2 taking up slightly too much memory. It is recommended that you reduce the amount of memory from 8Gb to 6 or 7Gb. In particular by modifying your .wslconfig file. See this guide First, we should load or download the required simulation containers locally. We need to run the load command as we want to load the local container images into the KinD container. This saves the KinD containers from having to download the containers themselves during runtime. This is achieved by starting a local container registry (just like Docker Hub), loading our containers into there, and getting the KinD containers to look there first when looking for containers. This command can take as long as 30 minutes depending on your internet connection. It goes through the deployment files and downloads a couple of large containers e.g. the gazebo and sitl containers. If the container doesn't already exist locally, it will attempt to download it from Docker Hub Note: The --brl option automatically loads up the BRL flight arena simulated doubles starling simulator load --brl Once loading completes, you can then start the simulator using the start command: starling simulator start --brl # or both load and start at once starling simulator start --brl --load This should print the following output: Starting simulator Converting to use local registry at localhost:5001 deployment.apps/gazebo-v1 created Converting to use local registry at localhost:5001 daemonset.apps/starling-px4-sitl-daemon created Converting to use local registry at localhost:5001 daemonset.apps/starling-mavros-daemon created With any luck, this should again open up the simulator on localhost:8080 (the page will be empty as the UI has not been started though).","title":"Running the Multi-Drone Cluster"},{"location":"multiuav_kubernetes/#monitoring-the-cluster","text":"A dashboard can be started to monitor the state of your current cluster. starling start dashboard This will start up the Kubernetes dashboard . To access the dashboard, open up a browser and go to http://localhost:31771. Note the browser may grumble about the security but it is safe to access! Please click 'Advanced Options' and 'Continue to website' to proceed. The above command should show something like the following: The Dashboard is available at https://localhost:31771 You will need the dashboard token, to access it. Copy and paste the token from below -----BEGIN DASHBOARD TOKEN----- <LONG TOKEN> -----END DASHBOARD TOKEN----- Note: your browser may not like the self signed ssl certificate, ignore and continue for now To get the token yourself run: kubectl -n kubernetes-dashboard describe secret admin-user-token You will need the <LONG TOKEN> to log in. Copy and paste it into the Dashboard token. To get the access token again, run: starling utils get-dashboard-token For a more specific tutorial on the dashboard go to this page in the starling docs ! This web dashboard shows the status of everything in the simulated cluster. It may look overwhelming, but in this tutorial, you'll only need to interact with a few of the elements. Opening the dashboard takes you firstly to the Workloads page. This gives you an overview of everything that is running. If it's green, you're all good! You can see the nodes in the cluster by scrolling down on the left sidebar and clicking Nodes . Here we see the server (control plane) and 2 drones (workers). On the right sidebar the pods button brings you to a list of all the groups of containers (pods) currently running on the cluster. We can see 1 Gazebo pod, 2 px4 and 2 mavros, representing two drones and a simulator. Finally, you can click on any one of the pods to access that container's logs, as well as exec into them if you want to run stuff. Navigate and have a look at the running pods. See if you recognise some of the printouts from when you just ran docker-compose . Note: The dashboard is definitely overspecified for our needs, but it already existed and was a good resource. We have a upcoming project to building a similar, more customised replacement which better suits our needs. Finally, for very quick diagnostics, you can also monitor the system using: $ starling status # or to continually watch $ starling status --watch Number of vehicles: 2 Nodes: NAME STATUS ROLES AGE VERSION starling-cluster-control-plane Ready control-plane,master 38m v1.21.1 starling-cluster-worker Ready <none> 38m v1.21.1 starling-cluster-worker2 Ready <none> 38m v1.21.1 Pods: NAME READY STATUS RESTARTS AGE gazebo-v1-59d58485d8-pnt2g 1/1 Running 0 25m starling-mavros-daemon-cqjhr 1/1 Running 0 25m starling-mavros-daemon-nmptj 1/1 Running 0 25m starling-px4-sitl-daemon-fllq5 1/1 Running 0 25m starling-px4-sitl-daemon-gfxqs 1/1 Running 0 25m Deployments: NAME READY UP-TO-DATE AVAILABLE AGE gazebo-v1 1/1 1 1 25m StatefulSets: No resources found in default namespace. DaemonSets NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE starling-mavros-daemon 2 2 2 2 2 starling.dev/type=vehicle 25m starling-px4-sitl-daemon 2 2 2 2 2 starling.dev/type=vehicle 25m","title":"Monitoring the cluster"},{"location":"multiuav_kubernetes/#restarting-on-stopping-the-simulator","text":"To recap, there are two parts to our Starling integration test simulator. There is the cluster, and then there is our UAV simulation running within the cluster. If the UAV simulation seems broken or you have put it in an unrecoverable state, you can restart the UAV simulation without deleting the cluster by running the restart command on the simulator: starling simulator restart --brl Note: This will stop the simulator by deleting all deployments within the cluster, and then restart. You can remove all deployments using starling simulator stop . Note: Don't forget to include the --brl so it knows what to start up again. If you have finished testing for the day, something fundamental to the cluster has gone wrong (e.g. failed to connect to ports, networking etc), or you wish to change the number of drones in your cluster, you can stop and delete the cluster and everything in it by running: starling stop kind Note: This will remove all of the loaded internal images again, so you will need to load them in next time you start the cluster (alternatively, you can keep them by adding the argument --keep_registry ). Note: You will have to start everything up again after restarting - the dashboard, loading images, starting the brl simulator.","title":"Restarting on Stopping the Simulator"},{"location":"multiuav_kubernetes/#next-steps","text":"Good job on getting to the end! This is one of the denser sections in this tutorial. Hopefully you now have a basic understanding on why Starling goes to the complexity of using Kubernetes and the benefits it can bring. In addition, you have learnt what KinD is, and why and how we use it in conjunction with the Starling CLI for integration testing. Now you know how the integration test stack can be run, it's time to get your controllers in and see how they work with multiple vehicles!","title":"Next Steps"},{"location":"next_steps/","text":"Wrapping up and next steps \u00b6 Wrapping up and next steps Wrapping up the Tutorial What Next Wrapping up the Tutorial \u00b6 Congratulations on making it to the end of this intense tutorial! \ud83e\udd73\ud83e\udd73\ud83c\udf89\ud83c\udf89\ud83c\udf89 Through the Starling development workflow, you have sucessfully created your own Starling project and validated against local testing, our integration testing stack and on real vehicles. In the process, you have hopefully learnt about the basics of UAV Control and ROS2. Why we decided to use docker and containerisation. And finally why we extended to using Kubernetes and container orchestration for software deployment to the real world. What Next \u00b6 Now it's time for you to go do something awesome with your Starling projects! The cookiecutter templates are publically available and should cover most use cases - whether you are doing low level control testing or higher level planning. Feel free to continue playing around with the example application from this tutorial. The solution we devise is only one of an infinite number of possible solutions. In particular, I feel you could apply some sort of optimisation procedure for the server's method of finding optimal thetas for each vehicle. I would love to see what sort of improvements you all come up with! Finally, we share some more links for useful places to go to and other useful links. We could only cover so much in this tutorial (I know right...) and there are many nuances and details about all the tools and setups throughout all of Starling. For specific information, please visit our docs at https://docs.starlinguas.dev/ . There you will find more detailed information about the images and setup. There already exists an ecosystem of applications in our github repository at https://github.com/StarlingUAS . A couple of notable projects include: Syncrhonous position control which is a multi-vehicle trajectory follower which can follow paths submitted to a web interface. A useful setup for basic multi-vehicle path following. BRL Flight Arena is the source for the flight arena digital double and gives examples for how to create your own gazebo worlds, as well as include custom vehicles into your Starling containers. Example UI is the source for the very basic example user interface we use throughout this tutorial. As Docker cannot really run native GUI applications, a web based interface is the next best thing! And many others! We would love to hear about the projects you are developing! We would also love to receive contributions and Pull Requests for this project. This is a fully open source project, and in that spirit, if in using it you find issues with the core of Starling, please submit an issue or even fix it and submit a PR! We appreciate as much as help as we can get! I hope you have enjoyed going through tutorial, and have found it useful. I also hope that Starling becomes the right tool for you to do your research! If you have any questions or queries about this Tutorial or Starling, I will be more than happy to anwser them at mickey.li@bristol.ac.uk . Mickey Li , Bristol Robotics Laboratory, University of Bristol, University of West England Website: https://mickeyhl.li/ Email: mickey.li@bristol.ac.uk Github: https://github.com/mhl787156 LinkedIn: https://www.linkedin.com/in/mickeyhaolinli/","title":"11. Wrapping up and next steps"},{"location":"next_steps/#wrapping-up-and-next-steps","text":"Wrapping up and next steps Wrapping up the Tutorial What Next","title":"Wrapping up and next steps"},{"location":"next_steps/#wrapping-up-the-tutorial","text":"Congratulations on making it to the end of this intense tutorial! \ud83e\udd73\ud83e\udd73\ud83c\udf89\ud83c\udf89\ud83c\udf89 Through the Starling development workflow, you have sucessfully created your own Starling project and validated against local testing, our integration testing stack and on real vehicles. In the process, you have hopefully learnt about the basics of UAV Control and ROS2. Why we decided to use docker and containerisation. And finally why we extended to using Kubernetes and container orchestration for software deployment to the real world.","title":"Wrapping up the Tutorial"},{"location":"next_steps/#what-next","text":"Now it's time for you to go do something awesome with your Starling projects! The cookiecutter templates are publically available and should cover most use cases - whether you are doing low level control testing or higher level planning. Feel free to continue playing around with the example application from this tutorial. The solution we devise is only one of an infinite number of possible solutions. In particular, I feel you could apply some sort of optimisation procedure for the server's method of finding optimal thetas for each vehicle. I would love to see what sort of improvements you all come up with! Finally, we share some more links for useful places to go to and other useful links. We could only cover so much in this tutorial (I know right...) and there are many nuances and details about all the tools and setups throughout all of Starling. For specific information, please visit our docs at https://docs.starlinguas.dev/ . There you will find more detailed information about the images and setup. There already exists an ecosystem of applications in our github repository at https://github.com/StarlingUAS . A couple of notable projects include: Syncrhonous position control which is a multi-vehicle trajectory follower which can follow paths submitted to a web interface. A useful setup for basic multi-vehicle path following. BRL Flight Arena is the source for the flight arena digital double and gives examples for how to create your own gazebo worlds, as well as include custom vehicles into your Starling containers. Example UI is the source for the very basic example user interface we use throughout this tutorial. As Docker cannot really run native GUI applications, a web based interface is the next best thing! And many others! We would love to hear about the projects you are developing! We would also love to receive contributions and Pull Requests for this project. This is a fully open source project, and in that spirit, if in using it you find issues with the core of Starling, please submit an issue or even fix it and submit a PR! We appreciate as much as help as we can get! I hope you have enjoyed going through tutorial, and have found it useful. I also hope that Starling becomes the right tool for you to do your research! If you have any questions or queries about this Tutorial or Starling, I will be more than happy to anwser them at mickey.li@bristol.ac.uk . Mickey Li , Bristol Robotics Laboratory, University of Bristol, University of West England Website: https://mickeyhl.li/ Email: mickey.li@bristol.ac.uk Github: https://github.com/mhl787156 LinkedIn: https://www.linkedin.com/in/mickeyhaolinli/","title":"What Next"},{"location":"ros2_uav/","text":"An Introduction to ROS2 and UAV Control \u00b6 This tutorial gives a brief overview and background on UAV Control and ROS2. By the end you should have a brief understanding of how a UAV is controlled, how Starling treats a UAV and why and how we use ROS2 to communicate with a UAV. An Introduction to ROS2 and UAV Control A Brief Introduction to UAV Control What is a UAV or a Drone How do you control a UAV The Autopilot MAVLink and Autopilot communication A Brief Introduction to ROS Why does ROS exist? What is ROS ROS concepts through an example ROS2 for Starling MAVLINK and ROS with MAVROS Next Steps A Brief Introduction to UAV Control \u00b6 What is a UAV or a Drone \u00b6 A drone or unmanned aerial vehicle (UAV) is an unmanned \"robotic\" vehicle that can be remotely or autonomously controlled. Drones are used for many consumer, industrial, government and military applications (opens new window). These include (non exhaustively): aerial photography/video, carrying cargo, racing, search and surveying etc. Different types of drones exist for use in air, ground, sea, and underwater. These are (more formally) referred to as Unmanned Aerial Vehicles (UAV), Unmanned Aerial Systems (UAS), Unmanned Ground Vehicles (UGV), Unmanned Surface Vehicles (USV), Unmanned Underwater Vehicles (UUV). The \"brain\" of the drone is called an autopilot . It consists of flight stack software running on vehicle controller (\"flight controller\") hardware. A multi-rotor is a specific type of UAV which uses two of more lift-generating rotors to fly. One of the most common will be the Quadrotor which has 4 motors in an 'X' pattern. These UAVs provide much simpler flight control than other types of aerial vehicle. This tutorial focuses on the flight of a simple quadrotor, but Starling can be used to operate many different types of robot. From this point on in this tutorial, 'drone' or 'UAV' will refer to a multi-rotor UAV unless otherwise stated. How do you control a UAV \u00b6 Modified from ardupilot docs A multicopter is a mechanically simple aerial vehicle whose motion is controlled by speeding or slowing multiple downward thrusting motor/propeller units. Combining different thrusts on different rotors allows the vehicle to move in free space with 6 degrees of freedom. However, manually controlling the individual thrusts of each motor in order to move the UAV is incredibly difficult, most would say its impossible even. This instability means that an on-board computer is mandatory for stable flight, as the on-board controller can perform the extreme high-rate control required to keep the drone in the air. In this \"Fly by wire\" paradigm, if the computer isn't working, you aren't flying. This dedicated on-board controller is referred to as the autopilot . This is seperate from a companion computer which is often used to direct the autopilot to achieve higher level mission goals. The autopilot combines data from small on-board MEMs gyroscopes and accelerometers (the same as those found in smart phones) to maintain an accurate estimate of its orientation and position. The quadcopter shown above is the simplest type of multicopter, with each motor/propeller spinning in the opposite direction from the two motors on either side of it (i.e. motors on opposite corners of the frame spin in the same direction). A quadcopter can control its roll and pitch rotation by speeding up two motors on one side and slowing down the other two. So for example if the quadcopter wanted to roll left it would speed up motors on the right side of the frame and slow down the two on the left. Similarly if it wants to rotate forward it speeds up the back two motors and slows down the front two. The copter can turn (aka \u201cyaw\u201d) left or right by speeding up two motors that are diagonally across from each other, and slowing down the other two. Horizontal motion is accomplished by temporarily speeding up/slowing down some motors so that the vehicle is leaning in the direction of desired travel and increasing the overall thrust of all motors so the vehicle shoots forward. Generally the more the vehicle leans, the faster it travels. Altitude is controlled by speeding up or slowing down all motors at the same time. In order to automatically map higher level motions to the thrust of the rotors, a cascading set of PID controllers is designed and provided by the autopilot. These then allow the remote control flight of the vehicle from a transmitter in your pilots hands, or via messages sent by the companion computer The Autopilot \u00b6 There is no universal controller design of converting from user inputs to motor thrust. In the same way, there are numerous other functionalities that an autopilot can cover. These can range from running control loops for gimbals, cameras and other actuation, to high level mission following and safety features. These functionalities are bundled into specific autopilot firmwares which each offer a slightly different set of features, as well as differing user interfaces each with their advantages and drawbacks. The two current most common autopilot firmware's in use in research settings are Ardupilot which offers the Arducopter firmware, and PX4 which offers Multicopter firmware. Both these firmwares are very extensive and cover numerous use cases. However, for our purposes we will only cover enabling autonomous flight through observing the mode of the autpilot. Both Ardupilot and PX4 use the concept of flight modes, where each mode operates a supports different levels or types of flight stabilisation and/or autonomous functions. Traditionally this is for pilots to change between different controller layouts for different applications. It's necessary to change to the correct mode for safe and controllable flight. The following table shows the most often used flight modes within Starling. Ardupilot Mode PX4 Mode Functionality stabilized manual Full manual control with RC sticks being sent directly to control roll, pitch, yaw and height PosHold position UAV uses onboard sensing to stay in place, RC sticks used to translate position loiter auto.hold Automatic mode where UAV stays in the same location until further instructions given. land auto.land Automatic mode which attempts to land the UAV Guided offboard Navigates to setpoints sent to it by ground control or companion computer Our controllers will all ask the autopilot to switch into guided or offboard mode in order to control from the companion computer. Often they have safety elements build in which mean that the autopilot must receive instructions at a certain rate (2Hz) otherwise the autopilot will switch to loiter or land. As mentioned before, the firmware provides a given cascading PID controller for converting high level commands to motor thrusts. As a controller developer, it is also useful to understand the differences between the Ardupilot and PX4 controllers and what real world impacts that has. Thankfully in most of Starling's targeted applications we only require position control which works fairly consistently between the two firmwares. In our own work, it has generally been noted that Ardupilot seems to be more suitable for outdoor flight, and PX4 for indoor flight. For this tutorial we will be developing a controller for indoor multi-vehicle flight and so we will assume the use of PX4. If interested in outdoor flight with Ardupilot, check out this tutorial which uses Starling with Ardupilot to simulate outdoor drone flight over a volcano. MAVLink and Autopilot communication \u00b6 Once in guided or offboard mode, the autopilot expects communications using the MAVLINK protocol . Traditionally this would have been used for a ground control station (GCS) to send commands to a UAV over a telemetry link. However, now it has also developed into a protocol for commanding the autopilot from an onboard companion computer over a USB or serial connection too. In Starling, both methods of communication between GCS or companion computer are supported. The MAVLink protocol is a set of preset commands which compatible firmwares understand and react to. However, it is often verbose and not-intuitive to develop applications with, as well as requiring a lot of prior knowledge about the state of the system. For example, it is neccesary to send a number of specific messages in order to receive individual data streams on vehicle status, location, global location and so on. These are often missed and cause lots of headaches for developers. Starling aims to streamline this through the use of the Robot Operating System so users no longer need to interact with MAVLink and the autopilot directly. A Brief Introduction to ROS \u00b6 This section is adapted from this article ROS stands for the Robot Operating System, yet it isn't an actual operating system. It's a framework designed to expedite the development time of robot platforms. To understand what ROS is, we should understand why ROS exists in the first place. Why does ROS exist? \u00b6 In general, software developers avoid hardware like the plague. It's messy, doesn't have consistent behavior, and there's no ctrl-z in sight. Most beginner programmers think you have to have a deep knowledge of electronics and even mechanics to program robots. They think that the hardware and software are so tightly coupled, you have to know both in depth to build anything useful. Software developers became software developers for a reason, so they don't have to deal with hardware. For example, let's say you have to debug a faulty sensor. You first have to take out the sensor from the enclosure, test the sensor thoroughly with a multi meter and various test cases, document its behavior, then examine the hardware -level code to ensure that there were no bugs, and so on. That's a lot of interaction with the hardware that's not fun for someone who just wants to write some cool software. It's harder to attract good programmers if the programming is coupled deeply with hardware. This is where ROS comes into play. With ROS, you can completely abstract the hardware from software, and instead interact with an API that gives access to that data. You can forget about the hardware, and focus on developing the software that makes the robot do what you want. What is ROS \u00b6 ROS is essentially a framework that sits on top of an operating system which defines how particular ROS compatible programs communicate and share data with each other. Essentially ROS defines an interface between which compatible programs can communicate and interact with each other. Over the years that ROS has existed, many people have developed thousands of ROS compatible packages which can be used in a modular fashion. ROS concepts through an example \u00b6 To make it more concrete, imagine that on your drone you have a camera. There are also two processes which require, as inputs, that camera image. Say, a machine learning program, and a position estimation program. Traditionally, you would have to manually serialise (compress) and stream the image over a port which the other two programs could read from. But if the port changes or, say, the camera changes, lots of things have to be reconfigured. However, this sort of interaction can be made streamlined in ROS. Let us consider the programs we have as ROS nodes , i.e. a program which is responsible for one single modular purpose, with particular inputs or outputs: A camera image streaming node OUT: camera image A machine vision system for recognising objects IN: camera image OUT: list of recognised objects A simultaneous localisation and mapping system. IN: camera image OUT: vehicle position These outputs of a node define ROS topics , i.e. a single stream of one type of data. Each topic has a particular name which can be referred to. In our example, some of the topics might be: /drone/camera for the camera image /drone/recognised_objects for the machine vision system /drone/slam_position for the SLAM system Then, we see that there are two avenues of communication created from these node inputs and outputs. graph LR A[Camera] -->|out| node[drone/camera] node --in--> C[Machine Vision] node --in--> D[SLAM] style node fill:#f9f,stroke:#333,stroke-width:4px Now ROS follows a publisher/subscriber model of communication. What that means is that nodes publish data to topics as outputs. But that data is only sent across the network if a different nodes also subscribes to the same topic. So in our example we end up having A camera image streaming node OUT: publishing to /drone/camera A machine vision system for recognising objects IN: subscribed to /drone/camera OUT: publishing to /drone/recognised_objects A simultaneous localisation and mapping system. IN: subscribed to /drone/camera OUT: publishing to /drone/slam_position graph LR A[Camera] -->|out| node[drone/camera] node --in--> C[Vision] C -->|out| node1[drone/recognised_objects] node --in--> D[SLAM] D -->|out| node2[drone/slam_position] style node fill:#f9f,stroke:#333,stroke-width:4px style node1 fill:#f9f,stroke:#333,stroke-width:4px style node2 fill:#f9f,stroke:#333,stroke-width:4px Finally, the data that is sent is not just anything. The data or message is a specifically templated packet of data containing things specified for that paricular use case. In our example for /drone/slam_position topic, the message might be of type geometry_msgs/msg/Point.msg which is defined like so: # This contains the position of a point in free space float64 x float64 y float64 z In other words the message that the /drone/slam_position topic publishes must have a msg.x , msg.y and msg.z field, and the subscriber will only receivea message with those fields. There are a number of messages in the standard ROS library, but many libraries also define their own - as have we in some parts of Starling. This can be summarised in this diagram from the ROS tutorials demonstrates it very nicely: The bottom half of this shows how topics get sent from a publisher to a subscriber. Interestingly, if you put two topics together, you get some notion of two way communication. This is the basis of a service which can be seen in the top of the diagram. A service is made of a Request topic and a Response topic, but functions as a single communication type to the user. Similar to messages, a service has a defined request and response types (e.g. see std_srvs/srv/SetBool.srv ). A service request will often wait until a response is received before continuing. Note that everything happens asyncronously and in parallel, when a node subscribes or sends a requests, it doesn't know when the response will arrive. It only knows it will (hopefully) arrive at some point. When a packet is received the subscriber can then run a method - this method is usually known as a callback , but that will be covered in a later tutorial. Finally, each node is configured by a set of parameters which are broadcast to all other nodes. Parameters are often configuration values for particular methods in a node, and can sometimes be changed on startup (or dynamically through a service), to allow the node to provide adjustable functionality. For example the value of a timeout or frequency of a loop. So in summary, the key concepts and terminology are: Nodes Topics Publishers and Subscribers Messages Services Parameters ROS2 for Starling \u00b6 There are 2 versions of ROS: ROS1 and ROS2. ROS1, initially created in 2007 by Willow Garage, has become huge among the open source robotics community. However over the years they realised that there are a number of important features which are missing - and adding all of these would simply break ROS1. Also the most recent ROS1 distribution (ROS Noetic) is soon to reach the end of its supported life (EOL 2025) with no more ROS1 there after! (See this article for more details!) Therefore, to future proof the system, and to ensure all users get a well rounded experience that will hopefully translate to industry experience, Starling has been implemented in ROS2. Specifically, Starling uses the Foxy Fitzroy Long Term Support (LTS) distribution throughout. There are some interesting changes between ROS1 and ROS2, but the core elements described above remain identical. For those interested, ROS2 follows a much more decentralised paradigm, and does not require a central ROSnode as it uses the distributed DDS communication protocol for its internal communication. All nodes therefore broadcast their own topics allowing for easy decentralised discovery - perfect for multi-robot applications. Note: Main thing to be aware of is if you are debugging and searching for ROS questions on the internet, be aware that there are many existing questions for ROS1 which will no longer apply for ROS2. MAVLINK and ROS with MAVROS \u00b6 Coming back round to flying drones, we mentioned in that we wanted to use ROS to avoid having to manually communicate with the autopilot using MAVLINK. Starling uses the MAVROS ROS package to do exactly that. For the autpilot, it automatically sets up a connection and translates higher level ROS commands into MAVLINK commands. For controller developers, Mavros provides a known and consistent interface through a set of topics, services and parameters to interact with. These include high level actions such as requesting the vehicle's state, local position, gps position, as well as setting setpoints for the vehicle to visit. A couple of useful topics are in the following table: Name Topic Message Type Functionality State mavros/state mavros_msgs/msg/State Get's the current state and flight mode of the vehicle Local Position mavros/local_position/pose geometry_msgs/msg/PoseStamped Get the UAVs current coordinate position after sensor fusion GPS Position mavros/global_position/global sensor_msgs/msg/NavSatFix Get the UAVs current lat,long (if enabled) Position Setpoint mavros/setpoint_position/local geometry_msgs/msg/PoseStamped Send a target coordinate and orientation for the vehicle to fly to immediately Set Flight Mode mavros/set_mode mavros_msgs/srv/SetMode A service which sets the flight mode of the autopilot Set Data Stream Rate mavros/set_stream_rate mavros_msgs/srv/StreamRate A service which starts the data stream from the autopilot and sets its rate Sometimes, you may need to send raw MAVlink back to the Autopilot to enable some non-standard functionality. This can also be done through the MAVROS node too. As we are now utilising ROS, this allows us to make the most of the full ROS ecosystem in developing UAV applications. Next Steps \u00b6 Hopefully now you have a basic understanding of what a drone is and how they are controlled, the function and purpose of an autopilot, as well as how ROS functions can be used. If you want some early hands on experience with ROS before delving further into Starling, we highly recommend the offical ros2 tutorials . We have one more theory topic before you can start creating your own Starling projects, where we will be discussing how Starling uses and encapsulates ROS functionality.","title":"2. ROS2 and UAV Control"},{"location":"ros2_uav/#an-introduction-to-ros2-and-uav-control","text":"This tutorial gives a brief overview and background on UAV Control and ROS2. By the end you should have a brief understanding of how a UAV is controlled, how Starling treats a UAV and why and how we use ROS2 to communicate with a UAV. An Introduction to ROS2 and UAV Control A Brief Introduction to UAV Control What is a UAV or a Drone How do you control a UAV The Autopilot MAVLink and Autopilot communication A Brief Introduction to ROS Why does ROS exist? What is ROS ROS concepts through an example ROS2 for Starling MAVLINK and ROS with MAVROS Next Steps","title":"An Introduction to ROS2 and UAV Control"},{"location":"ros2_uav/#a-brief-introduction-to-uav-control","text":"","title":"A Brief Introduction to UAV Control"},{"location":"ros2_uav/#what-is-a-uav-or-a-drone","text":"A drone or unmanned aerial vehicle (UAV) is an unmanned \"robotic\" vehicle that can be remotely or autonomously controlled. Drones are used for many consumer, industrial, government and military applications (opens new window). These include (non exhaustively): aerial photography/video, carrying cargo, racing, search and surveying etc. Different types of drones exist for use in air, ground, sea, and underwater. These are (more formally) referred to as Unmanned Aerial Vehicles (UAV), Unmanned Aerial Systems (UAS), Unmanned Ground Vehicles (UGV), Unmanned Surface Vehicles (USV), Unmanned Underwater Vehicles (UUV). The \"brain\" of the drone is called an autopilot . It consists of flight stack software running on vehicle controller (\"flight controller\") hardware. A multi-rotor is a specific type of UAV which uses two of more lift-generating rotors to fly. One of the most common will be the Quadrotor which has 4 motors in an 'X' pattern. These UAVs provide much simpler flight control than other types of aerial vehicle. This tutorial focuses on the flight of a simple quadrotor, but Starling can be used to operate many different types of robot. From this point on in this tutorial, 'drone' or 'UAV' will refer to a multi-rotor UAV unless otherwise stated.","title":"What is a UAV or a Drone"},{"location":"ros2_uav/#how-do-you-control-a-uav","text":"Modified from ardupilot docs A multicopter is a mechanically simple aerial vehicle whose motion is controlled by speeding or slowing multiple downward thrusting motor/propeller units. Combining different thrusts on different rotors allows the vehicle to move in free space with 6 degrees of freedom. However, manually controlling the individual thrusts of each motor in order to move the UAV is incredibly difficult, most would say its impossible even. This instability means that an on-board computer is mandatory for stable flight, as the on-board controller can perform the extreme high-rate control required to keep the drone in the air. In this \"Fly by wire\" paradigm, if the computer isn't working, you aren't flying. This dedicated on-board controller is referred to as the autopilot . This is seperate from a companion computer which is often used to direct the autopilot to achieve higher level mission goals. The autopilot combines data from small on-board MEMs gyroscopes and accelerometers (the same as those found in smart phones) to maintain an accurate estimate of its orientation and position. The quadcopter shown above is the simplest type of multicopter, with each motor/propeller spinning in the opposite direction from the two motors on either side of it (i.e. motors on opposite corners of the frame spin in the same direction). A quadcopter can control its roll and pitch rotation by speeding up two motors on one side and slowing down the other two. So for example if the quadcopter wanted to roll left it would speed up motors on the right side of the frame and slow down the two on the left. Similarly if it wants to rotate forward it speeds up the back two motors and slows down the front two. The copter can turn (aka \u201cyaw\u201d) left or right by speeding up two motors that are diagonally across from each other, and slowing down the other two. Horizontal motion is accomplished by temporarily speeding up/slowing down some motors so that the vehicle is leaning in the direction of desired travel and increasing the overall thrust of all motors so the vehicle shoots forward. Generally the more the vehicle leans, the faster it travels. Altitude is controlled by speeding up or slowing down all motors at the same time. In order to automatically map higher level motions to the thrust of the rotors, a cascading set of PID controllers is designed and provided by the autopilot. These then allow the remote control flight of the vehicle from a transmitter in your pilots hands, or via messages sent by the companion computer","title":"How do you control a UAV"},{"location":"ros2_uav/#the-autopilot","text":"There is no universal controller design of converting from user inputs to motor thrust. In the same way, there are numerous other functionalities that an autopilot can cover. These can range from running control loops for gimbals, cameras and other actuation, to high level mission following and safety features. These functionalities are bundled into specific autopilot firmwares which each offer a slightly different set of features, as well as differing user interfaces each with their advantages and drawbacks. The two current most common autopilot firmware's in use in research settings are Ardupilot which offers the Arducopter firmware, and PX4 which offers Multicopter firmware. Both these firmwares are very extensive and cover numerous use cases. However, for our purposes we will only cover enabling autonomous flight through observing the mode of the autpilot. Both Ardupilot and PX4 use the concept of flight modes, where each mode operates a supports different levels or types of flight stabilisation and/or autonomous functions. Traditionally this is for pilots to change between different controller layouts for different applications. It's necessary to change to the correct mode for safe and controllable flight. The following table shows the most often used flight modes within Starling. Ardupilot Mode PX4 Mode Functionality stabilized manual Full manual control with RC sticks being sent directly to control roll, pitch, yaw and height PosHold position UAV uses onboard sensing to stay in place, RC sticks used to translate position loiter auto.hold Automatic mode where UAV stays in the same location until further instructions given. land auto.land Automatic mode which attempts to land the UAV Guided offboard Navigates to setpoints sent to it by ground control or companion computer Our controllers will all ask the autopilot to switch into guided or offboard mode in order to control from the companion computer. Often they have safety elements build in which mean that the autopilot must receive instructions at a certain rate (2Hz) otherwise the autopilot will switch to loiter or land. As mentioned before, the firmware provides a given cascading PID controller for converting high level commands to motor thrusts. As a controller developer, it is also useful to understand the differences between the Ardupilot and PX4 controllers and what real world impacts that has. Thankfully in most of Starling's targeted applications we only require position control which works fairly consistently between the two firmwares. In our own work, it has generally been noted that Ardupilot seems to be more suitable for outdoor flight, and PX4 for indoor flight. For this tutorial we will be developing a controller for indoor multi-vehicle flight and so we will assume the use of PX4. If interested in outdoor flight with Ardupilot, check out this tutorial which uses Starling with Ardupilot to simulate outdoor drone flight over a volcano.","title":"The Autopilot"},{"location":"ros2_uav/#mavlink-and-autopilot-communication","text":"Once in guided or offboard mode, the autopilot expects communications using the MAVLINK protocol . Traditionally this would have been used for a ground control station (GCS) to send commands to a UAV over a telemetry link. However, now it has also developed into a protocol for commanding the autopilot from an onboard companion computer over a USB or serial connection too. In Starling, both methods of communication between GCS or companion computer are supported. The MAVLink protocol is a set of preset commands which compatible firmwares understand and react to. However, it is often verbose and not-intuitive to develop applications with, as well as requiring a lot of prior knowledge about the state of the system. For example, it is neccesary to send a number of specific messages in order to receive individual data streams on vehicle status, location, global location and so on. These are often missed and cause lots of headaches for developers. Starling aims to streamline this through the use of the Robot Operating System so users no longer need to interact with MAVLink and the autopilot directly.","title":"MAVLink and Autopilot communication"},{"location":"ros2_uav/#a-brief-introduction-to-ros","text":"This section is adapted from this article ROS stands for the Robot Operating System, yet it isn't an actual operating system. It's a framework designed to expedite the development time of robot platforms. To understand what ROS is, we should understand why ROS exists in the first place.","title":"A Brief Introduction to ROS"},{"location":"ros2_uav/#why-does-ros-exist","text":"In general, software developers avoid hardware like the plague. It's messy, doesn't have consistent behavior, and there's no ctrl-z in sight. Most beginner programmers think you have to have a deep knowledge of electronics and even mechanics to program robots. They think that the hardware and software are so tightly coupled, you have to know both in depth to build anything useful. Software developers became software developers for a reason, so they don't have to deal with hardware. For example, let's say you have to debug a faulty sensor. You first have to take out the sensor from the enclosure, test the sensor thoroughly with a multi meter and various test cases, document its behavior, then examine the hardware -level code to ensure that there were no bugs, and so on. That's a lot of interaction with the hardware that's not fun for someone who just wants to write some cool software. It's harder to attract good programmers if the programming is coupled deeply with hardware. This is where ROS comes into play. With ROS, you can completely abstract the hardware from software, and instead interact with an API that gives access to that data. You can forget about the hardware, and focus on developing the software that makes the robot do what you want.","title":"Why does ROS exist?"},{"location":"ros2_uav/#what-is-ros","text":"ROS is essentially a framework that sits on top of an operating system which defines how particular ROS compatible programs communicate and share data with each other. Essentially ROS defines an interface between which compatible programs can communicate and interact with each other. Over the years that ROS has existed, many people have developed thousands of ROS compatible packages which can be used in a modular fashion.","title":"What is ROS"},{"location":"ros2_uav/#ros-concepts-through-an-example","text":"To make it more concrete, imagine that on your drone you have a camera. There are also two processes which require, as inputs, that camera image. Say, a machine learning program, and a position estimation program. Traditionally, you would have to manually serialise (compress) and stream the image over a port which the other two programs could read from. But if the port changes or, say, the camera changes, lots of things have to be reconfigured. However, this sort of interaction can be made streamlined in ROS. Let us consider the programs we have as ROS nodes , i.e. a program which is responsible for one single modular purpose, with particular inputs or outputs: A camera image streaming node OUT: camera image A machine vision system for recognising objects IN: camera image OUT: list of recognised objects A simultaneous localisation and mapping system. IN: camera image OUT: vehicle position These outputs of a node define ROS topics , i.e. a single stream of one type of data. Each topic has a particular name which can be referred to. In our example, some of the topics might be: /drone/camera for the camera image /drone/recognised_objects for the machine vision system /drone/slam_position for the SLAM system Then, we see that there are two avenues of communication created from these node inputs and outputs. graph LR A[Camera] -->|out| node[drone/camera] node --in--> C[Machine Vision] node --in--> D[SLAM] style node fill:#f9f,stroke:#333,stroke-width:4px Now ROS follows a publisher/subscriber model of communication. What that means is that nodes publish data to topics as outputs. But that data is only sent across the network if a different nodes also subscribes to the same topic. So in our example we end up having A camera image streaming node OUT: publishing to /drone/camera A machine vision system for recognising objects IN: subscribed to /drone/camera OUT: publishing to /drone/recognised_objects A simultaneous localisation and mapping system. IN: subscribed to /drone/camera OUT: publishing to /drone/slam_position graph LR A[Camera] -->|out| node[drone/camera] node --in--> C[Vision] C -->|out| node1[drone/recognised_objects] node --in--> D[SLAM] D -->|out| node2[drone/slam_position] style node fill:#f9f,stroke:#333,stroke-width:4px style node1 fill:#f9f,stroke:#333,stroke-width:4px style node2 fill:#f9f,stroke:#333,stroke-width:4px Finally, the data that is sent is not just anything. The data or message is a specifically templated packet of data containing things specified for that paricular use case. In our example for /drone/slam_position topic, the message might be of type geometry_msgs/msg/Point.msg which is defined like so: # This contains the position of a point in free space float64 x float64 y float64 z In other words the message that the /drone/slam_position topic publishes must have a msg.x , msg.y and msg.z field, and the subscriber will only receivea message with those fields. There are a number of messages in the standard ROS library, but many libraries also define their own - as have we in some parts of Starling. This can be summarised in this diagram from the ROS tutorials demonstrates it very nicely: The bottom half of this shows how topics get sent from a publisher to a subscriber. Interestingly, if you put two topics together, you get some notion of two way communication. This is the basis of a service which can be seen in the top of the diagram. A service is made of a Request topic and a Response topic, but functions as a single communication type to the user. Similar to messages, a service has a defined request and response types (e.g. see std_srvs/srv/SetBool.srv ). A service request will often wait until a response is received before continuing. Note that everything happens asyncronously and in parallel, when a node subscribes or sends a requests, it doesn't know when the response will arrive. It only knows it will (hopefully) arrive at some point. When a packet is received the subscriber can then run a method - this method is usually known as a callback , but that will be covered in a later tutorial. Finally, each node is configured by a set of parameters which are broadcast to all other nodes. Parameters are often configuration values for particular methods in a node, and can sometimes be changed on startup (or dynamically through a service), to allow the node to provide adjustable functionality. For example the value of a timeout or frequency of a loop. So in summary, the key concepts and terminology are: Nodes Topics Publishers and Subscribers Messages Services Parameters","title":"ROS concepts through an example"},{"location":"ros2_uav/#ros2-for-starling","text":"There are 2 versions of ROS: ROS1 and ROS2. ROS1, initially created in 2007 by Willow Garage, has become huge among the open source robotics community. However over the years they realised that there are a number of important features which are missing - and adding all of these would simply break ROS1. Also the most recent ROS1 distribution (ROS Noetic) is soon to reach the end of its supported life (EOL 2025) with no more ROS1 there after! (See this article for more details!) Therefore, to future proof the system, and to ensure all users get a well rounded experience that will hopefully translate to industry experience, Starling has been implemented in ROS2. Specifically, Starling uses the Foxy Fitzroy Long Term Support (LTS) distribution throughout. There are some interesting changes between ROS1 and ROS2, but the core elements described above remain identical. For those interested, ROS2 follows a much more decentralised paradigm, and does not require a central ROSnode as it uses the distributed DDS communication protocol for its internal communication. All nodes therefore broadcast their own topics allowing for easy decentralised discovery - perfect for multi-robot applications. Note: Main thing to be aware of is if you are debugging and searching for ROS questions on the internet, be aware that there are many existing questions for ROS1 which will no longer apply for ROS2.","title":"ROS2 for Starling"},{"location":"ros2_uav/#mavlink-and-ros-with-mavros","text":"Coming back round to flying drones, we mentioned in that we wanted to use ROS to avoid having to manually communicate with the autopilot using MAVLINK. Starling uses the MAVROS ROS package to do exactly that. For the autpilot, it automatically sets up a connection and translates higher level ROS commands into MAVLINK commands. For controller developers, Mavros provides a known and consistent interface through a set of topics, services and parameters to interact with. These include high level actions such as requesting the vehicle's state, local position, gps position, as well as setting setpoints for the vehicle to visit. A couple of useful topics are in the following table: Name Topic Message Type Functionality State mavros/state mavros_msgs/msg/State Get's the current state and flight mode of the vehicle Local Position mavros/local_position/pose geometry_msgs/msg/PoseStamped Get the UAVs current coordinate position after sensor fusion GPS Position mavros/global_position/global sensor_msgs/msg/NavSatFix Get the UAVs current lat,long (if enabled) Position Setpoint mavros/setpoint_position/local geometry_msgs/msg/PoseStamped Send a target coordinate and orientation for the vehicle to fly to immediately Set Flight Mode mavros/set_mode mavros_msgs/srv/SetMode A service which sets the flight mode of the autopilot Set Data Stream Rate mavros/set_stream_rate mavros_msgs/srv/StreamRate A service which starts the data stream from the autopilot and sets its rate Sometimes, you may need to send raw MAVlink back to the Autopilot to enable some non-standard functionality. This can also be done through the MAVROS node too. As we are now utilising ROS, this allows us to make the most of the full ROS ecosystem in developing UAV applications.","title":"MAVLINK and ROS with MAVROS"},{"location":"ros2_uav/#next-steps","text":"Hopefully now you have a basic understanding of what a drone is and how they are controlled, the function and purpose of an autopilot, as well as how ROS functions can be used. If you want some early hands on experience with ROS before delving further into Starling, we highly recommend the offical ros2 tutorials . We have one more theory topic before you can start creating your own Starling projects, where we will be discussing how Starling uses and encapsulates ROS functionality.","title":"Next Steps"},{"location":"simulation/","text":"Simulation and the Digital Double \u00b6 In this tutorial we will cover how a UAV simulation works and introduce Gazebo, the physics simulator that we use in Starling. By the end you should know the different parts of the simulator and how to run it locally. Simulation and the Digital Double UAV Simulation Software in the loop Gazebo BRL Digital Double Running the local simulator What is in the local simulation Inspecting the local simulation Next Steps UAV Simulation \u00b6 Often UAV Simulation is solely focused on trying to recreate the dynamics of UAV flight. In Starling however, we have decided to leave that to the physics simulator experts, and instead focus on the simulation of systems and architecture involved with UAV flight. This is with the goal to make transferring control from simulation to real hardware as streamlined and straight forward as possible. In the previous section on UAV control , we said that a core part of UAV control is the Autopilot . It's a physical computer which takes sensor inputs to create motor voltages to spin the motor. To recreate this as closely as possible, we'd like to simulate all of this to ensure that the operation of the UAV is as realistic as possible. Software in the loop \u00b6 Thankfully, both Ardupilot and SITL can be run as software in the loop or SITL , a simulation where the flight stack that would run on the autopilot, runs on your local computer. Simulators allow flight code to control a computer modelled vehicle in a simulated \"world\". You can interact with this vehicle just as you might with a real vehicle, using QGroundControl, an offboard API such as ROS, or a radio controller/gamepad. Simulation is a quick, easy, and most importantly, safe way to test changes to your controller before attempting to fly in the real world. It is also a good way to start flying when you haven't yet got a vehicle to experiment with or don't want to risk damaging it. From a Starling perspective, the MAVROS container does not distinguish between running on a real vehicle or running on SITL as both still speak the same version of MAVLINK. The MAVROS container internally handles connecting to the correct source. Gazebo \u00b6 Alongside the SITL, a physics engine is also required for it to run against. Together, the simulation is often performed in lockstep where the SITL will generate a motion in one step based on the simulator state, followed by the simulator advancing by one step based on that motion. In Starling, we primarily use the Gazebo physics and visualisation engine as it is one of the most commonly out there currently in the robotics space. Starling is designed with simulator modularity in mind, and it's hoped that in the future, other simulators will also be supported! Starling provides a number of containers which have Gazebo pre configured and installed, along with a web based interface for viewing the simulation in progress. In this tutorial, we will be using one container in particular. BRL Digital Double \u00b6 As well as simulating the vehicles themselves, it is also important to simulate the environment in which we are operating. For this tutorial we will be flying in the Bristol Robotics Laboratory (BRL) flight arena, and therefore we provide a digital double of that space here . It is contained in the following container: uobflightlabstarling/uobflightlabstarling/starling-sim-iris-px4-flightarena:latest This will place you into a space where the exact measurements match the real world version of the flight arena. Flight arena is 15.6m x 11.8m x 5m (x, y, z) tall, origin is offset by (0.5, 0.7, 0.0) from space center. The coordinate space is: x positive is up and y postive is left (w.r.t the ascii figure). _________________________________ | | | ^ | | |x | |_ <-- | |_| y | | | |__|____________ | |___|___|___|___| | | _____ _____| |_ _____ ______|_____|_____| Running the local simulator \u00b6 We can now run the full simulation of a single UAV in the flight arena locally on your machine. Go to your new Starling application, and you should see a deployment folder. Inside there is a docker-compose.yml file. A docker compose file is used to configure the running of multiple containers together, instead of having to run a bunch of them manually. To ensure that you have the latest containers, we should pull all of the used ones from Docker Hub: docker-compose -f deployment/docker-compose.yml pull This can take a while, especially if your internet connection is slow. Once downloaded, you can then run the simulator stack with the up command: docker-compose -f deployment/docker-compose.yml up If you have downloaded and installed the Starling CLI from Murmuration, you could also run the following (it does the same thing under the hood): starling deploy -f deployment/docker-compose.yml --pull start Note: depending on what you also have running, you may receive a port in use error. If it is the port for simhost (8080), rosbridge (9090) or the UI (3000), you can change the value of <local_port>:<container_port> in the docker-compose.yml file. Note: Stop the simulator with ctrl+c Once you have run the above command, you should see a lot of text fly by in the terminal! Hopefully none of it is red... To access the simulator, go to localhost:8080 . To access the simple UI, go to localhost:3000 . The UI contains a simple Go and Stop button which both send topics of /mission_start and /emergency_stop respectively. What is in the local simulation \u00b6 Awesome! You now have the local simulator running... but what have you actually run? Let's take you through the docker-compose file: uobflightlabstarling/starling-sim-iris-px4-flightarena : This is the Gazebo image which contains the model of the flying arena and the model of the UAV. On startup, it spawns the arena and spawns a single vehicle into it. uobflightlabstarling/starling-sim-px4-sitl : The container which runs the PX4 Software In The Loop mentioned earlier. Through the environment variables, it knows to connect to the gazebo container for physics, and then knows to expect the mavros container for offboard commands. uobflightlabstarling/starling-mavros : The container which runs mavros mentioned in a previous tutorial. It serves as the connection point between the SITL and your own controller code. uobflightlabstarling/rosbridge-suite : The gateway for web ros applications like the UI to connect to ROS. uobflightlabstarling/starling-ui-example : The example web application with a simple interface. Inspecting the local simulation \u00b6 To verify the functionality of the simulator, we can have a look at some of the ROS Topics that are being sent around. We do this by exec -ing into one of the containers: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ca5384b42f41 uobflightlabstarling/starling-mavros:nightly \"/ros_entrypoint.sh \u2026\" 8 seconds ago Up 7 seconds 0.0.0.0:5760->5760/tcp deployment_mavros_1 633d71686da7 uobflightlabstarling/starling-sim-px4-sitl:nightly \"/entrypoint.sh /bin\u2026\" 8 seconds ago Up 7 seconds 0.0.0.0:18570->18570/udp deployment_sitl_1 a462241ba16f uobflightlabstarling/starling-sim-iris-px4-flightarena:latest \"/entrypoint.sh ros2\u2026\" 9 seconds ago Up 8 seconds 7681/tcp, 11345/tcp, 0.0.0.0:8080->8080/tcp deployment_simhost_1 51adc525e085 uobflightlabstarling/starling-ui-example:latest \"/ros_entrypoint.sh \u2026\" 29 minutes ago Up 8 seconds 9090/tcp, 0.0.0.0:3001->3000/tcp deployment_starling-ui-example_1 f1208345c980 uobflightlabstarling/rosbridge-suite:latest \"/ros_entrypoint.sh \u2026\" 36 minutes ago Up 9 seconds 0.0.0.0:9090->9090/tcp deployment_rosbridge-suite_1 Choosing the starling-mavros container, we can exec into that and run the following: docker exec -it ca5384b42f41 bash root@ca5384b42f41:/ros_ws# . /opt/ros/foxy/setup.bash root@ca5384b42f41:/ros_ws# ros2 topic list /client_count /clock /connected_clients /emergency_stop /link_states /model_states /parameter_events /performance_metrics /rosout /vehicle_1/mavlink/from /vehicle_1/mavlink/to /vehicle_1/mavros/battery /vehicle_1/mavros/distance_sensor/hrlv_ez4_sonar /vehicle_1/mavros/distance_sensor/lidarlite_laser /vehicle_1/mavros/distance_sensor/rangefinder /vehicle_1/mavros/distance_sensor/temperature /vehicle_1/mavros/extended_state /vehicle_1/mavros/global_position/global /vehicle_1/mavros/image/camera_image /vehicle_1/mavros/imu/data /vehicle_1/mavros/local_position/accel /vehicle_1/mavros/local_position/odom /vehicle_1/mavros/local_position/pose /vehicle_1/mavros/local_position/pose_cov /vehicle_1/mavros/local_position/velocity_body /vehicle_1/mavros/local_position/velocity_body_cov /vehicle_1/mavros/local_position/velocity_local /vehicle_1/mavros/manual_control/control /vehicle_1/mavros/manual_control/send /vehicle_1/mavros/mission/reached /vehicle_1/mavros/mission/waypoints /vehicle_1/mavros/px4flow/ground_distance /vehicle_1/mavros/px4flow/raw/optical_flow_rad /vehicle_1/mavros/safety_area /vehicle_1/mavros/setpoint_accel/accel /vehicle_1/mavros/setpoint_attitude/attitude /vehicle_1/mavros/setpoint_attitude/cmd_vel /vehicle_1/mavros/setpoint_attitude/thrust /vehicle_1/mavros/setpoint_position/global /vehicle_1/mavros/setpoint_position/global_to_local /vehicle_1/mavros/setpoint_position/local /vehicle_1/mavros/setpoint_raw/attitude /vehicle_1/mavros/setpoint_raw/global /vehicle_1/mavros/setpoint_raw/local /vehicle_1/mavros/setpoint_velocity/cmd_vel_unstamped /vehicle_1/mavros/state /vehicle_1/mavros/vision_pose/pose /vehicle_1/mavros/vision_pose/pose_cov /vehicle_1/mavros/vision_speed/speed_twist /vehicle_1/mavros/vision_speed/speed_vector This lists a list of all the topics currently being broadcast onto the system. Similarly, we can inspect the current list of nodes: root@ca5384b42f41:/ros_ws# ros2 node list /gazebo /gazebo_vehicle_state_plugin /motion_tracker_sim /rosapi /rosapi /rosbridge_websocket /vehicle_1/estop /vehicle_1/ros_bridge and so on. We can also have a look at some of the topics. For example, if we wanted to look at the state of vehicle_1 , we would have a look at /vehicle_1/mavros/local_position/pose (Press ctrl+c to stop the stream). root@ca5384b42f41:/ros_ws# ros2 topic echo /vehicle_1/mavros/local_position/pose --- header: stamp: sec: 1655741007 nanosec: 589603584 frame_id: map pose: position: x: -0.010252323932945728 y: -0.025252731516957283 z: -0.019200336188077927 orientation: x: -0.0019689216589022533 y: -0.0020565663184938785 z: 0.0005801513697525905 w: -0.9999958103477264 --- header: stamp: sec: 1655741007 nanosec: 617603584 frame_id: map pose: position: x: -0.01022176630795002 y: -0.02509368769824505 z: -0.018872130662202835 orientation: x: -0.0019977603981865205 y: -0.0021082978655832646 z: 0.0006137002611672492 w: -0.9999956417603324 --- ... Have a play around and investigate the other topics! Finally to stop the simulator, you can simply run ctrl+c in the terminal running the simulator. Next Steps \u00b6 This tutorial should have introduced you to how UAV simulation works and the Gazebo simulator we use in Starling. It's also shown you how to run the simulator. You'll need to use this to test the controller you will be developing in the next section.","title":"5. Simulation and the Digital Double"},{"location":"simulation/#simulation-and-the-digital-double","text":"In this tutorial we will cover how a UAV simulation works and introduce Gazebo, the physics simulator that we use in Starling. By the end you should know the different parts of the simulator and how to run it locally. Simulation and the Digital Double UAV Simulation Software in the loop Gazebo BRL Digital Double Running the local simulator What is in the local simulation Inspecting the local simulation Next Steps","title":"Simulation and the Digital Double"},{"location":"simulation/#uav-simulation","text":"Often UAV Simulation is solely focused on trying to recreate the dynamics of UAV flight. In Starling however, we have decided to leave that to the physics simulator experts, and instead focus on the simulation of systems and architecture involved with UAV flight. This is with the goal to make transferring control from simulation to real hardware as streamlined and straight forward as possible. In the previous section on UAV control , we said that a core part of UAV control is the Autopilot . It's a physical computer which takes sensor inputs to create motor voltages to spin the motor. To recreate this as closely as possible, we'd like to simulate all of this to ensure that the operation of the UAV is as realistic as possible.","title":"UAV Simulation"},{"location":"simulation/#software-in-the-loop","text":"Thankfully, both Ardupilot and SITL can be run as software in the loop or SITL , a simulation where the flight stack that would run on the autopilot, runs on your local computer. Simulators allow flight code to control a computer modelled vehicle in a simulated \"world\". You can interact with this vehicle just as you might with a real vehicle, using QGroundControl, an offboard API such as ROS, or a radio controller/gamepad. Simulation is a quick, easy, and most importantly, safe way to test changes to your controller before attempting to fly in the real world. It is also a good way to start flying when you haven't yet got a vehicle to experiment with or don't want to risk damaging it. From a Starling perspective, the MAVROS container does not distinguish between running on a real vehicle or running on SITL as both still speak the same version of MAVLINK. The MAVROS container internally handles connecting to the correct source.","title":"Software in the loop"},{"location":"simulation/#gazebo","text":"Alongside the SITL, a physics engine is also required for it to run against. Together, the simulation is often performed in lockstep where the SITL will generate a motion in one step based on the simulator state, followed by the simulator advancing by one step based on that motion. In Starling, we primarily use the Gazebo physics and visualisation engine as it is one of the most commonly out there currently in the robotics space. Starling is designed with simulator modularity in mind, and it's hoped that in the future, other simulators will also be supported! Starling provides a number of containers which have Gazebo pre configured and installed, along with a web based interface for viewing the simulation in progress. In this tutorial, we will be using one container in particular.","title":"Gazebo"},{"location":"simulation/#brl-digital-double","text":"As well as simulating the vehicles themselves, it is also important to simulate the environment in which we are operating. For this tutorial we will be flying in the Bristol Robotics Laboratory (BRL) flight arena, and therefore we provide a digital double of that space here . It is contained in the following container: uobflightlabstarling/uobflightlabstarling/starling-sim-iris-px4-flightarena:latest This will place you into a space where the exact measurements match the real world version of the flight arena. Flight arena is 15.6m x 11.8m x 5m (x, y, z) tall, origin is offset by (0.5, 0.7, 0.0) from space center. The coordinate space is: x positive is up and y postive is left (w.r.t the ascii figure). _________________________________ | | | ^ | | |x | |_ <-- | |_| y | | | |__|____________ | |___|___|___|___| | | _____ _____| |_ _____ ______|_____|_____|","title":"BRL Digital Double"},{"location":"simulation/#running-the-local-simulator","text":"We can now run the full simulation of a single UAV in the flight arena locally on your machine. Go to your new Starling application, and you should see a deployment folder. Inside there is a docker-compose.yml file. A docker compose file is used to configure the running of multiple containers together, instead of having to run a bunch of them manually. To ensure that you have the latest containers, we should pull all of the used ones from Docker Hub: docker-compose -f deployment/docker-compose.yml pull This can take a while, especially if your internet connection is slow. Once downloaded, you can then run the simulator stack with the up command: docker-compose -f deployment/docker-compose.yml up If you have downloaded and installed the Starling CLI from Murmuration, you could also run the following (it does the same thing under the hood): starling deploy -f deployment/docker-compose.yml --pull start Note: depending on what you also have running, you may receive a port in use error. If it is the port for simhost (8080), rosbridge (9090) or the UI (3000), you can change the value of <local_port>:<container_port> in the docker-compose.yml file. Note: Stop the simulator with ctrl+c Once you have run the above command, you should see a lot of text fly by in the terminal! Hopefully none of it is red... To access the simulator, go to localhost:8080 . To access the simple UI, go to localhost:3000 . The UI contains a simple Go and Stop button which both send topics of /mission_start and /emergency_stop respectively.","title":"Running the local simulator"},{"location":"simulation/#what-is-in-the-local-simulation","text":"Awesome! You now have the local simulator running... but what have you actually run? Let's take you through the docker-compose file: uobflightlabstarling/starling-sim-iris-px4-flightarena : This is the Gazebo image which contains the model of the flying arena and the model of the UAV. On startup, it spawns the arena and spawns a single vehicle into it. uobflightlabstarling/starling-sim-px4-sitl : The container which runs the PX4 Software In The Loop mentioned earlier. Through the environment variables, it knows to connect to the gazebo container for physics, and then knows to expect the mavros container for offboard commands. uobflightlabstarling/starling-mavros : The container which runs mavros mentioned in a previous tutorial. It serves as the connection point between the SITL and your own controller code. uobflightlabstarling/rosbridge-suite : The gateway for web ros applications like the UI to connect to ROS. uobflightlabstarling/starling-ui-example : The example web application with a simple interface.","title":"What is in the local simulation"},{"location":"simulation/#inspecting-the-local-simulation","text":"To verify the functionality of the simulator, we can have a look at some of the ROS Topics that are being sent around. We do this by exec -ing into one of the containers: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ca5384b42f41 uobflightlabstarling/starling-mavros:nightly \"/ros_entrypoint.sh \u2026\" 8 seconds ago Up 7 seconds 0.0.0.0:5760->5760/tcp deployment_mavros_1 633d71686da7 uobflightlabstarling/starling-sim-px4-sitl:nightly \"/entrypoint.sh /bin\u2026\" 8 seconds ago Up 7 seconds 0.0.0.0:18570->18570/udp deployment_sitl_1 a462241ba16f uobflightlabstarling/starling-sim-iris-px4-flightarena:latest \"/entrypoint.sh ros2\u2026\" 9 seconds ago Up 8 seconds 7681/tcp, 11345/tcp, 0.0.0.0:8080->8080/tcp deployment_simhost_1 51adc525e085 uobflightlabstarling/starling-ui-example:latest \"/ros_entrypoint.sh \u2026\" 29 minutes ago Up 8 seconds 9090/tcp, 0.0.0.0:3001->3000/tcp deployment_starling-ui-example_1 f1208345c980 uobflightlabstarling/rosbridge-suite:latest \"/ros_entrypoint.sh \u2026\" 36 minutes ago Up 9 seconds 0.0.0.0:9090->9090/tcp deployment_rosbridge-suite_1 Choosing the starling-mavros container, we can exec into that and run the following: docker exec -it ca5384b42f41 bash root@ca5384b42f41:/ros_ws# . /opt/ros/foxy/setup.bash root@ca5384b42f41:/ros_ws# ros2 topic list /client_count /clock /connected_clients /emergency_stop /link_states /model_states /parameter_events /performance_metrics /rosout /vehicle_1/mavlink/from /vehicle_1/mavlink/to /vehicle_1/mavros/battery /vehicle_1/mavros/distance_sensor/hrlv_ez4_sonar /vehicle_1/mavros/distance_sensor/lidarlite_laser /vehicle_1/mavros/distance_sensor/rangefinder /vehicle_1/mavros/distance_sensor/temperature /vehicle_1/mavros/extended_state /vehicle_1/mavros/global_position/global /vehicle_1/mavros/image/camera_image /vehicle_1/mavros/imu/data /vehicle_1/mavros/local_position/accel /vehicle_1/mavros/local_position/odom /vehicle_1/mavros/local_position/pose /vehicle_1/mavros/local_position/pose_cov /vehicle_1/mavros/local_position/velocity_body /vehicle_1/mavros/local_position/velocity_body_cov /vehicle_1/mavros/local_position/velocity_local /vehicle_1/mavros/manual_control/control /vehicle_1/mavros/manual_control/send /vehicle_1/mavros/mission/reached /vehicle_1/mavros/mission/waypoints /vehicle_1/mavros/px4flow/ground_distance /vehicle_1/mavros/px4flow/raw/optical_flow_rad /vehicle_1/mavros/safety_area /vehicle_1/mavros/setpoint_accel/accel /vehicle_1/mavros/setpoint_attitude/attitude /vehicle_1/mavros/setpoint_attitude/cmd_vel /vehicle_1/mavros/setpoint_attitude/thrust /vehicle_1/mavros/setpoint_position/global /vehicle_1/mavros/setpoint_position/global_to_local /vehicle_1/mavros/setpoint_position/local /vehicle_1/mavros/setpoint_raw/attitude /vehicle_1/mavros/setpoint_raw/global /vehicle_1/mavros/setpoint_raw/local /vehicle_1/mavros/setpoint_velocity/cmd_vel_unstamped /vehicle_1/mavros/state /vehicle_1/mavros/vision_pose/pose /vehicle_1/mavros/vision_pose/pose_cov /vehicle_1/mavros/vision_speed/speed_twist /vehicle_1/mavros/vision_speed/speed_vector This lists a list of all the topics currently being broadcast onto the system. Similarly, we can inspect the current list of nodes: root@ca5384b42f41:/ros_ws# ros2 node list /gazebo /gazebo_vehicle_state_plugin /motion_tracker_sim /rosapi /rosapi /rosbridge_websocket /vehicle_1/estop /vehicle_1/ros_bridge and so on. We can also have a look at some of the topics. For example, if we wanted to look at the state of vehicle_1 , we would have a look at /vehicle_1/mavros/local_position/pose (Press ctrl+c to stop the stream). root@ca5384b42f41:/ros_ws# ros2 topic echo /vehicle_1/mavros/local_position/pose --- header: stamp: sec: 1655741007 nanosec: 589603584 frame_id: map pose: position: x: -0.010252323932945728 y: -0.025252731516957283 z: -0.019200336188077927 orientation: x: -0.0019689216589022533 y: -0.0020565663184938785 z: 0.0005801513697525905 w: -0.9999958103477264 --- header: stamp: sec: 1655741007 nanosec: 617603584 frame_id: map pose: position: x: -0.01022176630795002 y: -0.02509368769824505 z: -0.018872130662202835 orientation: x: -0.0019977603981865205 y: -0.0021082978655832646 z: 0.0006137002611672492 w: -0.9999956417603324 --- ... Have a play around and investigate the other topics! Finally to stop the simulator, you can simply run ctrl+c in the terminal running the simulator.","title":"Inspecting the local simulation"},{"location":"simulation/#next-steps","text":"This tutorial should have introduced you to how UAV simulation works and the Gazebo simulator we use in Starling. It's also shown you how to run the simulator. You'll need to use this to test the controller you will be developing in the next section.","title":"Next Steps"},{"location":"testing_with_docker_compose/","text":"Local Testing with Docker Compose \u00b6 In this section we will see how to do local development and testing with the local simulation environment using docker-compose. This forms the first step of the Starling workflow. By the end of this tutorial, you should understand how to run your controller against the simulation containers. Local Testing with Docker Compose Running the Controller and the Simulator Together Verify your controller Connect the simulator Developing with the Simulator Next Steps Running the Controller and the Simulator Together \u00b6 Bringing together the previous couple of tutorials, we can run our developed controller against the simulator. Verify your controller \u00b6 First, make sure you are in the root of your controller application. Now, let us verify that our own controller is at least compiling properly. We should get something like the following, and then stop it using ctrl+c : make run ... ---- controller base setup START ------------ VEHICLE_NAMESPACE not set, default to launchfile defaults ---- controller base setup END ------------ Sourcing local install setup.bash VEHICLE_MAVLINK_SYSID not set, default to 1 Running Onboard Controller [INFO] [launch]: All log files can be found below /root/.ros/log/2022-06-20-22-22-51-158267-9c4f7a240328-49 [INFO] [launch]: Default logging verbosity is set to INFO [INFO] [controller-1]: process started with pid [51] [controller-1] [INFO] [1655763771.265611400] [vehicle_1.controller]: Reset Internal Parameters and Trajectory Executor [controller-1] [INFO] [1655763771.265749100] [vehicle_1.controller]: Controller initialised [controller-1] [WARN] [1655763771.365796900] [vehicle_1.controller]: Waiting for vehicle state data [controller-1] [INFO] [1655763771.365888900] [vehicle_1.controller]: Initialisation Waiting on System Checks [controller-1] [WARN] [1655763771.465746400] [vehicle_1.controller]: Waiting for vehicle state data ... If you have syntax errors and the like, please go back and fix them before continuing, it will save you time in the long run! The controller is currently waiting on system checks and vehicle state data. This means that it is not receiving any data from drone ros topics. Understandable as we have not yet run the simulator and connected it up! Connect the simulator \u00b6 Similar to previously, we can run the simulation stack provided for testing: docker-compose -f deployment/docker-compose.yml up or if you have downloaded and installed the Starling CLI from Murmuration, you could also run the following (it does the same thing under the hood): starling deploy -f deployment/docker-compose.yml start # or to pull the images as well starling deploy -f deployment/docker-compose.yml start --pull To access the simulator, go to localhost:8080 , and to access the simple UI, go to localhost:3000 . In order for the controller to connect to the simulator, we need to find out which Docker network the simulator is running on. To view the current docker networks, in a second terminal run docker network ls NETWORK ID NAME DRIVER SCOPE 4c2a6932e455 bridge bridge local 681c73eec26a deployment_default bridge local 1059b63b6f59 host host local We are interested in the network named <something>_default and not named bridge and host which are Docker default networks. In our case deployment_default is the network created by docker compose when running the simulation stack. It should also be called deployment_default for you (the <something> is the parent folder of the docker compose file). Then re-run (close the previously running one with CTRL+C) your controller with this new network. You can use the NETWORK variable from the Makefile make NETWORK=deployment_default run ... [controller-1] [INFO] [1655765539.785786200] [vehicle_1.controller]: Initialisation Waiting on System Checks [controller-1] [INFO] [1655765539.816086500] [vehicle_1.controller]: Initial mavros state received [controller-1] [INFO] [1655765539.885724600] [vehicle_1.controller]: Initialisation Waiting on Mission Start [controller-1] [INFO] [1655765539.985731000] [vehicle_1.controller]: Initialisation Waiting on Mission Start ... You could also simply specify the --net=deployment_default option with normal docker run Success! It looks like the controller has received data from mavros and is currently waiting to start the mission! To advance the mission, you can try pressing the green mission start button on the web interface. The vehicle should then indicate it is trying to take off, and you should be able to see it move in the simulator interface! However you will notice that it gets stuck waiting for User Controller Ready. This is because it is waiting for a packet from the server with its initial location, but of course we have no server running so it never receives it! To remedy this, you can open up another terminal in order to run the server. As mentioned previously, this can be achieved by setting the environment variable OFFBOARD to true using the following syntax make NETWORK=deployment_default ENV=\"-e OFFBOARD=true\" run Repeating the previous steps to start the main controller on the network, we then get the following if we follow the instructions and press the go button every time the controller asks. Oh dear! It looks like this example is almost there, but starts flying off of the circle erratically. Hmm, how can I develop this container without having to stop and start everything...? Developing with the Simulator \u00b6 You may have noticed that we started the simulator, and your controller seperately as two distinct elements. You didn't have to modify any config files to add in your own controller either. This is one of the great benefits of our system as this designed separation allows the recreation of your user application without having to restart the main simulator! This holds as long as: Your application has been run on the same network as the simulator Your application is written in such a way that it can be attached to the simulator at any time Your application hasn't put the simulator in an unrecoverable state! e.g. Flipped the vehicle upside down. Otherwise it is quite simple to make some changes to your own application and re-run your container using make ... run again without having to exit the simulator . Note: This also applies to the terminal running the offboard node! Since its reactive, you dont need restart that either. ROS will simply patch the connection when your onboard controller is restarted. And now finding the bug in my smExecute function, my controller now does what I expect it to do - fly in a circle! Next Steps \u00b6 Congrats! \ud83e\udd73 You hopefully now have a working and tested Starling application. With luck, you now also have a better understanding of how to use Starling and its containers to quickly develop and prototype your controllers. However, we still have one part of the brief to go - the customer wanted a multi-drone application! In the next few tutorials we will take you through how to build, develop and test your application in a multi-drone setup which will take you closer to flying real drones at the BRL.","title":"7. Local testing with Docker-Compose"},{"location":"testing_with_docker_compose/#local-testing-with-docker-compose","text":"In this section we will see how to do local development and testing with the local simulation environment using docker-compose. This forms the first step of the Starling workflow. By the end of this tutorial, you should understand how to run your controller against the simulation containers. Local Testing with Docker Compose Running the Controller and the Simulator Together Verify your controller Connect the simulator Developing with the Simulator Next Steps","title":"Local Testing with Docker Compose"},{"location":"testing_with_docker_compose/#running-the-controller-and-the-simulator-together","text":"Bringing together the previous couple of tutorials, we can run our developed controller against the simulator.","title":"Running the Controller and the Simulator Together"},{"location":"testing_with_docker_compose/#verify-your-controller","text":"First, make sure you are in the root of your controller application. Now, let us verify that our own controller is at least compiling properly. We should get something like the following, and then stop it using ctrl+c : make run ... ---- controller base setup START ------------ VEHICLE_NAMESPACE not set, default to launchfile defaults ---- controller base setup END ------------ Sourcing local install setup.bash VEHICLE_MAVLINK_SYSID not set, default to 1 Running Onboard Controller [INFO] [launch]: All log files can be found below /root/.ros/log/2022-06-20-22-22-51-158267-9c4f7a240328-49 [INFO] [launch]: Default logging verbosity is set to INFO [INFO] [controller-1]: process started with pid [51] [controller-1] [INFO] [1655763771.265611400] [vehicle_1.controller]: Reset Internal Parameters and Trajectory Executor [controller-1] [INFO] [1655763771.265749100] [vehicle_1.controller]: Controller initialised [controller-1] [WARN] [1655763771.365796900] [vehicle_1.controller]: Waiting for vehicle state data [controller-1] [INFO] [1655763771.365888900] [vehicle_1.controller]: Initialisation Waiting on System Checks [controller-1] [WARN] [1655763771.465746400] [vehicle_1.controller]: Waiting for vehicle state data ... If you have syntax errors and the like, please go back and fix them before continuing, it will save you time in the long run! The controller is currently waiting on system checks and vehicle state data. This means that it is not receiving any data from drone ros topics. Understandable as we have not yet run the simulator and connected it up!","title":"Verify your controller"},{"location":"testing_with_docker_compose/#connect-the-simulator","text":"Similar to previously, we can run the simulation stack provided for testing: docker-compose -f deployment/docker-compose.yml up or if you have downloaded and installed the Starling CLI from Murmuration, you could also run the following (it does the same thing under the hood): starling deploy -f deployment/docker-compose.yml start # or to pull the images as well starling deploy -f deployment/docker-compose.yml start --pull To access the simulator, go to localhost:8080 , and to access the simple UI, go to localhost:3000 . In order for the controller to connect to the simulator, we need to find out which Docker network the simulator is running on. To view the current docker networks, in a second terminal run docker network ls NETWORK ID NAME DRIVER SCOPE 4c2a6932e455 bridge bridge local 681c73eec26a deployment_default bridge local 1059b63b6f59 host host local We are interested in the network named <something>_default and not named bridge and host which are Docker default networks. In our case deployment_default is the network created by docker compose when running the simulation stack. It should also be called deployment_default for you (the <something> is the parent folder of the docker compose file). Then re-run (close the previously running one with CTRL+C) your controller with this new network. You can use the NETWORK variable from the Makefile make NETWORK=deployment_default run ... [controller-1] [INFO] [1655765539.785786200] [vehicle_1.controller]: Initialisation Waiting on System Checks [controller-1] [INFO] [1655765539.816086500] [vehicle_1.controller]: Initial mavros state received [controller-1] [INFO] [1655765539.885724600] [vehicle_1.controller]: Initialisation Waiting on Mission Start [controller-1] [INFO] [1655765539.985731000] [vehicle_1.controller]: Initialisation Waiting on Mission Start ... You could also simply specify the --net=deployment_default option with normal docker run Success! It looks like the controller has received data from mavros and is currently waiting to start the mission! To advance the mission, you can try pressing the green mission start button on the web interface. The vehicle should then indicate it is trying to take off, and you should be able to see it move in the simulator interface! However you will notice that it gets stuck waiting for User Controller Ready. This is because it is waiting for a packet from the server with its initial location, but of course we have no server running so it never receives it! To remedy this, you can open up another terminal in order to run the server. As mentioned previously, this can be achieved by setting the environment variable OFFBOARD to true using the following syntax make NETWORK=deployment_default ENV=\"-e OFFBOARD=true\" run Repeating the previous steps to start the main controller on the network, we then get the following if we follow the instructions and press the go button every time the controller asks. Oh dear! It looks like this example is almost there, but starts flying off of the circle erratically. Hmm, how can I develop this container without having to stop and start everything...?","title":"Connect the simulator"},{"location":"testing_with_docker_compose/#developing-with-the-simulator","text":"You may have noticed that we started the simulator, and your controller seperately as two distinct elements. You didn't have to modify any config files to add in your own controller either. This is one of the great benefits of our system as this designed separation allows the recreation of your user application without having to restart the main simulator! This holds as long as: Your application has been run on the same network as the simulator Your application is written in such a way that it can be attached to the simulator at any time Your application hasn't put the simulator in an unrecoverable state! e.g. Flipped the vehicle upside down. Otherwise it is quite simple to make some changes to your own application and re-run your container using make ... run again without having to exit the simulator . Note: This also applies to the terminal running the offboard node! Since its reactive, you dont need restart that either. ROS will simply patch the connection when your onboard controller is restarted. And now finding the bug in my smExecute function, my controller now does what I expect it to do - fly in a circle!","title":"Developing with the Simulator"},{"location":"testing_with_docker_compose/#next-steps","text":"Congrats! \ud83e\udd73 You hopefully now have a working and tested Starling application. With luck, you now also have a better understanding of how to use Starling and its containers to quickly develop and prototype your controllers. However, we still have one part of the brief to go - the customer wanted a multi-drone application! In the next few tutorials we will take you through how to build, develop and test your application in a multi-drone setup which will take you closer to flying real drones at the BRL.","title":"Next Steps"},{"location":"testing_with_kind/","text":"Local Integration testing with KinD Digital Double \u00b6 In this tutorial, you will finally be flying your controller against multiple vehicles within the Starling Integration Test Stack using KinD. By the end, you will understand how to develop and test against our stack, ready for flying on real vehicles. Local Integration testing with KinD Digital Double Specifying your Deployments Deploying your controller to KinD Starting the KinD stack Deploying your controller Developing with the Multi-UAV Testing Stack Next Steps Specifying your Deployments \u00b6 In your Starling application deployment folder, you should also see a kubernetes.yaml file. This file contains the instructions to tell Kubernetes which containers should be deployed to which places. It should be automatically generated to point to your project, so the image names here will be different to yours. There are two configurations listed, one for the Onboard Controller, and one for the Offboard central controller, seperated by the --- . Breaking both down together briefly: # Onboard controllers apiVersion: apps/v1 kind: DaemonSet metadata: ... --- # Central monitor apiVersion: apps/v1 kind: Deployment metadata: ... In Starling we primarily make use of two types of deployment: the Deployment and the Daemonset . In general we use a deployment when we want a container to be deployed to a specific place, in our case the deployment of your applications offboard component into the central server. The Daemonset on the other hand is used for deploying something to any node which matches a given label, in our case, any drone on the network. # Onboard Controllers nodeSelector: # starling.dev/vehicle-class: rotary starling.dev/type: vehicle tolerations: - key: \"starling.dev/type\" operator: \"Equal\" value: \"vehicle\" effect: \"NoSchedule\" --- # Central monitor nodeSelector: name: master tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule A bit further down on each you will see the nodeSelector and tolerations. All we'll say about these is that they enable us to choose where the containers are deployed. So the onboard controller is deployed to any node with the starling.dev/type: vehicle label, and similarly with the name: master label for the central monitor. # Onboard Controllers containers: - name: onboard-controller image: starling123/starling-controller imagePullPolicy: Always volumeMounts: ... --- # Central Monitor containers: - name: offboard-controller image: starling123/starling-controller imagePullPolicy: Always env: - name: OFFBOARD value: \"true\" - name: starling-ui image: uobflightlabstarling/starling-ui-example:latest imagePullPolicy: Always ports: - containerPort: 3000 - name: rosbridge-suite image: uobflightlabstarling/rosbridge-suite:latest imagePullPolicy: Always ports: - containerPort: 9090 Here we list the container or containers that each each deployment is actually deploying. For the onboard controller, we specify the image that we have built as part of this starling project. For the offboard controller, we also specify our image, but we also add the UI into our deployment. This implies that our kubernetes Pod contains 3 images which is absolutely fine - its a good way to group together functionality. Here we want all 3 containers to be run on the central monitor, so we may as well group them. Here we also specify the ports Note: imagePullPolicy dictates if an image should be updated from the repository. Always means that on startup it will always pull the latest image to run. This is needed for local development in order to ensure you are running the latest controller. Optionally, imagePullPolicy can be set to IfNotPresent for the UI and rosbridge as they need only be pulled once. Note: see also that the onboard controller also volumeMounts the file /etc/starling/vehicle.config . This is a special file which containers running onboard a drone read to identify who they are and other useful individual information. This file exists on every drone and containers are given access to it by mounting the file into the container when running. This is part of the Starling architecture. Deploying your controller to KinD \u00b6 Starting the KinD stack \u00b6 First things first, we need to start up the testing stack. For more details, see the previous tutorial . Let's start it up with two drones within the BRL environment. # Start the kind stack starling start kind -n 2 # Start the dashboard for visualisation. Remember to grab the key and go to https://localhost:31771 starling start dashboard # Load the images into KinD and start the simulator starling simulator start --brl --load As usual once everything is loaded, you should be able to see the simulator on https://localhost:8080 . Note: If the simulator doesn't look like it's starting within 3 or 4 minutes, you can try and restart it by using restart instead of start . Deploying your controller \u00b6 First, ensure that you have built your controller container. Do so by running the following from the root directory: make Also ensure that the default deployment file has been set up correctly and uses your image. Then we can start, load and deploy your controller into the testing stack with the following command: starling deploy -f deployment/kubernetes.yaml --load start It may take a minute to load, but once it's done, you should see your new deployments on the Kubernetes dashboard. Going to the pods tab, you should see 3 new deployments - 2 onboard deployments, one to each drone, and 1 offboard deployment on the central node. Looking at the Node column, it should show that the two onboard deployments are on different KinD worker nodes. Let's check on the status of these controllers by looking at their logs. Click into one of the containers and press the View logs button in the top right. It looks like the controller is ready and just waiting for start button to be pressed, so let's do it! Oh no! Looks like the vehicles just go straight into each other and crash in a very ugly way. In the real world, this would have ended up with 2 broken drones in need of repair. These are the exact situations that integration testing is meant to catch. Note: Try and guess why they crashed, and see if you can figure out a method of solving it before we continue. Developing with the Multi-UAV Testing Stack \u00b6 In a similar vein to testing Docker-Compose, how do we make changes and develop against the KinD simulator? Again, the simulator or the cluster itself need not be restarted. Only the specific deployments related to your controller have to be updated. There are 3 steps involved: Rebuilding your container locally using make . Loading the updated image to the local repository so KinD has access to it. Restarting the deployment. This can be achieved in the following line: make && starling deploy -f deployment/kubernetes.yaml --load restart For the crash scenario above, this was caused by the automated numbering of the drones and how they need to move through each other to get to their assigned start locations. A simple solution is to add a 90 degree offset to theta, so the entire circle is rotated by 90 degrees. // In controller.hpp around line 71, I added const double theta_offset = M_PI/2.0; /// // In controller.cpp line 100 inside handleNotifyVehicles(..), I added that constant to this line // Used to be: double start_target_theta = 2 * M_PI * s->vehicle_id / s->total_vehicles; double start_target_theta = this->theta_offset + (2 * M_PI * s->vehicle_id / s->total_vehicles); Then we run the below command to rebuild and redeploy: make && starling deploy -f deployment/kubernetes.yaml --load restart Check again to make sure the controllers have restarted (check that the created time is small). Then try pressing Go again! Next Steps \u00b6 Congrats! \ud83c\udf89\ud83c\udf89\ud83c\udf89 You now have your very own Starling application controller running within the KinD Multi-UAV Integration Testing Stack. This is literally as close as you can get from a systems perspective to flying real drones in the flight arena. If it works here, the only thing left to contend with is the differences between simulated and real vehicle flight (this is obviously a massively difficult problem, but thankfully many cleverer people are working on that...). You should now have an idea of how to develop and test multi-UAV applications within the integration test framework, and how to deploy your own applications to it. Feel free to further develop your applications! Maybe make them do something even more interesting than flying around in a circle (hahaha). The final step to the Starling worflow is then to take your controller and deploy it into the real world!","title":"9. Local Integration testing with KinD Digital Double"},{"location":"testing_with_kind/#local-integration-testing-with-kind-digital-double","text":"In this tutorial, you will finally be flying your controller against multiple vehicles within the Starling Integration Test Stack using KinD. By the end, you will understand how to develop and test against our stack, ready for flying on real vehicles. Local Integration testing with KinD Digital Double Specifying your Deployments Deploying your controller to KinD Starting the KinD stack Deploying your controller Developing with the Multi-UAV Testing Stack Next Steps","title":"Local Integration testing with KinD Digital Double"},{"location":"testing_with_kind/#specifying-your-deployments","text":"In your Starling application deployment folder, you should also see a kubernetes.yaml file. This file contains the instructions to tell Kubernetes which containers should be deployed to which places. It should be automatically generated to point to your project, so the image names here will be different to yours. There are two configurations listed, one for the Onboard Controller, and one for the Offboard central controller, seperated by the --- . Breaking both down together briefly: # Onboard controllers apiVersion: apps/v1 kind: DaemonSet metadata: ... --- # Central monitor apiVersion: apps/v1 kind: Deployment metadata: ... In Starling we primarily make use of two types of deployment: the Deployment and the Daemonset . In general we use a deployment when we want a container to be deployed to a specific place, in our case the deployment of your applications offboard component into the central server. The Daemonset on the other hand is used for deploying something to any node which matches a given label, in our case, any drone on the network. # Onboard Controllers nodeSelector: # starling.dev/vehicle-class: rotary starling.dev/type: vehicle tolerations: - key: \"starling.dev/type\" operator: \"Equal\" value: \"vehicle\" effect: \"NoSchedule\" --- # Central monitor nodeSelector: name: master tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule A bit further down on each you will see the nodeSelector and tolerations. All we'll say about these is that they enable us to choose where the containers are deployed. So the onboard controller is deployed to any node with the starling.dev/type: vehicle label, and similarly with the name: master label for the central monitor. # Onboard Controllers containers: - name: onboard-controller image: starling123/starling-controller imagePullPolicy: Always volumeMounts: ... --- # Central Monitor containers: - name: offboard-controller image: starling123/starling-controller imagePullPolicy: Always env: - name: OFFBOARD value: \"true\" - name: starling-ui image: uobflightlabstarling/starling-ui-example:latest imagePullPolicy: Always ports: - containerPort: 3000 - name: rosbridge-suite image: uobflightlabstarling/rosbridge-suite:latest imagePullPolicy: Always ports: - containerPort: 9090 Here we list the container or containers that each each deployment is actually deploying. For the onboard controller, we specify the image that we have built as part of this starling project. For the offboard controller, we also specify our image, but we also add the UI into our deployment. This implies that our kubernetes Pod contains 3 images which is absolutely fine - its a good way to group together functionality. Here we want all 3 containers to be run on the central monitor, so we may as well group them. Here we also specify the ports Note: imagePullPolicy dictates if an image should be updated from the repository. Always means that on startup it will always pull the latest image to run. This is needed for local development in order to ensure you are running the latest controller. Optionally, imagePullPolicy can be set to IfNotPresent for the UI and rosbridge as they need only be pulled once. Note: see also that the onboard controller also volumeMounts the file /etc/starling/vehicle.config . This is a special file which containers running onboard a drone read to identify who they are and other useful individual information. This file exists on every drone and containers are given access to it by mounting the file into the container when running. This is part of the Starling architecture.","title":"Specifying your Deployments"},{"location":"testing_with_kind/#deploying-your-controller-to-kind","text":"","title":"Deploying your controller to KinD"},{"location":"testing_with_kind/#starting-the-kind-stack","text":"First things first, we need to start up the testing stack. For more details, see the previous tutorial . Let's start it up with two drones within the BRL environment. # Start the kind stack starling start kind -n 2 # Start the dashboard for visualisation. Remember to grab the key and go to https://localhost:31771 starling start dashboard # Load the images into KinD and start the simulator starling simulator start --brl --load As usual once everything is loaded, you should be able to see the simulator on https://localhost:8080 . Note: If the simulator doesn't look like it's starting within 3 or 4 minutes, you can try and restart it by using restart instead of start .","title":"Starting the KinD stack"},{"location":"testing_with_kind/#deploying-your-controller","text":"First, ensure that you have built your controller container. Do so by running the following from the root directory: make Also ensure that the default deployment file has been set up correctly and uses your image. Then we can start, load and deploy your controller into the testing stack with the following command: starling deploy -f deployment/kubernetes.yaml --load start It may take a minute to load, but once it's done, you should see your new deployments on the Kubernetes dashboard. Going to the pods tab, you should see 3 new deployments - 2 onboard deployments, one to each drone, and 1 offboard deployment on the central node. Looking at the Node column, it should show that the two onboard deployments are on different KinD worker nodes. Let's check on the status of these controllers by looking at their logs. Click into one of the containers and press the View logs button in the top right. It looks like the controller is ready and just waiting for start button to be pressed, so let's do it! Oh no! Looks like the vehicles just go straight into each other and crash in a very ugly way. In the real world, this would have ended up with 2 broken drones in need of repair. These are the exact situations that integration testing is meant to catch. Note: Try and guess why they crashed, and see if you can figure out a method of solving it before we continue.","title":"Deploying your controller"},{"location":"testing_with_kind/#developing-with-the-multi-uav-testing-stack","text":"In a similar vein to testing Docker-Compose, how do we make changes and develop against the KinD simulator? Again, the simulator or the cluster itself need not be restarted. Only the specific deployments related to your controller have to be updated. There are 3 steps involved: Rebuilding your container locally using make . Loading the updated image to the local repository so KinD has access to it. Restarting the deployment. This can be achieved in the following line: make && starling deploy -f deployment/kubernetes.yaml --load restart For the crash scenario above, this was caused by the automated numbering of the drones and how they need to move through each other to get to their assigned start locations. A simple solution is to add a 90 degree offset to theta, so the entire circle is rotated by 90 degrees. // In controller.hpp around line 71, I added const double theta_offset = M_PI/2.0; /// // In controller.cpp line 100 inside handleNotifyVehicles(..), I added that constant to this line // Used to be: double start_target_theta = 2 * M_PI * s->vehicle_id / s->total_vehicles; double start_target_theta = this->theta_offset + (2 * M_PI * s->vehicle_id / s->total_vehicles); Then we run the below command to rebuild and redeploy: make && starling deploy -f deployment/kubernetes.yaml --load restart Check again to make sure the controllers have restarted (check that the created time is small). Then try pressing Go again!","title":"Developing with the Multi-UAV Testing Stack"},{"location":"testing_with_kind/#next-steps","text":"Congrats! \ud83c\udf89\ud83c\udf89\ud83c\udf89 You now have your very own Starling application controller running within the KinD Multi-UAV Integration Testing Stack. This is literally as close as you can get from a systems perspective to flying real drones in the flight arena. If it works here, the only thing left to contend with is the differences between simulated and real vehicle flight (this is obviously a massively difficult problem, but thankfully many cleverer people are working on that...). You should now have an idea of how to develop and test multi-UAV applications within the integration test framework, and how to deploy your own applications to it. Feel free to further develop your applications! Maybe make them do something even more interesting than flying around in a circle (hahaha). The final step to the Starling worflow is then to take your controller and deploy it into the real world!","title":"Next Steps"}]}